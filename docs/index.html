<!doctype html><html lang="en"><head><meta charset="utf-8"><meta content="ie=edge" http-equiv="x-ua-compatible"><title>home — Who are we now?</title><meta name="title" content="Who Are We Now?"><meta name="description" content="From leading AI researcher Blaise Agüera y Arcas comes an exploration of how biology, ecology, sexuality, history, and culture have intertwined to create a dynamic “us” that can neither be called natural nor artificial."><meta name="viewport" content="width=device-width,initial-scale=1,minimum-scale=1"><link href="/assets/css/main.css" rel="stylesheet"><meta name="robots" content="noindex,nofollow"><meta name="theme-color" content="#ffffff"><link rel="icon" href="/assets/favicon/wawn_favicon.svg"><link rel="apple-touch-icon" sizes="180x180" href="/assets/favicon/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicon/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicon/favicon-16x16.png"><link rel="icon" href="/assets/favicon/wawn_favicon.svg" type="image/svg+xml"><meta name="msapplication-TileColor" content="#ffffff"><script src="https://d3js.org/d3.v7.min.js"></script><script src="/assets/js/bundle-script.js"></script></head><body id="home" class="home"><header><nav><div class="navlink"><div class="icon"><div class="icon_close"><svg width="17" height="17" viewBox="0 0 17 17" fill="none" xmlns="http://www.w3.org/2000/svg"><line x1="1.42893" y1="1.22183" x2="16.2782" y2="16.0711"/><line x1="15.9246" y1="1.57539" x2="1.07539" y2="16.4246"/></svg></div></div><div class="current-page"><a class="nav-home" href="/"><span class="nav-sitetitle">What is Intelligence?</span></a><div class="nav-title"><span class="marker"></span>home<svg width="11" height="10" viewBox="0 0 11 7" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M5.5 7L0.73686 0.25L10.2631 0.250001L5.5 7Z"/></svg></div></div></div><div class="info"><span class="open">●●●</span> <span class="close">✕</span></div><ul id="toc"></ul></nav></header><div id="summary-popup"></div><main><div class="home-cover"><div class="title"><h3>Blaise Agüera y Arcas</h3><h1>What is Life?</h1></div></div><article><section class="content"><h1><em>What is life?</em></h1><h1>Titlepage</h1><h1>Back cover</h1><p>Excerpted from <em>What Is Intelligence?</em> by Blaise Agüera y Arcas, serialized on the web from fall 2024 and available in print fall 2025</p><p>Compliments of Antikythera and MIT Press<br><a href="http://antikythera.org">antikythera.org</a><br><a href="http://mitpress.mit.edu">mitpress.mit.edu</a></p><p>Printed and bound in Belgium</p><p>ISBN 979-8-895-90084-0</p><h1>Contents</h1><p>Series preface<br>Foreword</p><p><strong>Abiogenesis</strong><br><strong>Symbiogenesis</strong><br><strong>Reproductive functions</strong><br><strong>Life as computation</strong><br><strong>Artificial life</strong><br><strong>Thermodynamics</strong><br><strong>Dynamic stability</strong><br><strong>Complexification</strong><br><strong>Virality</strong><br><strong>Compression</strong><br><strong>Embodiment</strong><br><strong>Élan vital</strong></p><p>Acknowledgments<br>About the author<br>Bibliography<br>Image credits<br>Note on the artwork<br>Note on the type</p><h1>Series preface</h1><p>Antikythera is a philosophy of technology research program reorienting planetary computation as a philosophical, technological, and geopolitical force.</p><p>It takes its name from the first known computer, the Antikythera mechanism, an ancient tool for orientation, navigation, planning, and prediction across planets.</p><p>Antikythera understands the future of computation as more than calculation. It is a technology to think with. It is an instrument for epistemological discovery.</p><p>Arguably computation was discovered as much as it was invented. It is part of how the universe works, including, as Blaise Agüera y Arcas will show, how life works.</p><p>That such a claim could be made is due in no small part to the creative and curious use of our computational tools—or what we might more precisely call <em>artificial</em> computation. With those tools we discover that some otherwise imperceivable building blocks of our reality and of our own flesh are themselves computational. Computation discovers itself through us.</p><p>The Antikythera book series, in collaboration with MIT Press, begins with this extraordinary little book that asks perhaps the most complex question of all: what is life?</p><p>The answers are surprising not only in themselves but also in how they reframe the question to include also <em>how</em> is life. As it turns out, <em>how</em> and <em>what</em> can be the same thing.</p><p>We are proud to launch this initiative by laying a cornerstone with the thoughts of my dear friend, Blaise.</p><p><strong>Benjamin Bratton</strong><br>La Jolla, California<br>September 2024</p><h1>Foreword</h1><hr><h2>Abiogenesis</h2><p>Despite his clear articulation of the principle of evolution, Charles Darwin (1809–1882) didn’t have a clue either. That’s why, in 1863, he wrote to his close friend Joseph Dalton Hooker that “it is mere rubbish, thinking, at present, of origin of life; one might as well think of origin of matter.”<span id="ft-1" class="reference"> <sup class="footnote-ref">1</sup></span></p><p>Today, we have more of a clue, although the details may forever be lost to deep time.</p><p>Today, those early conditions are most closely reproduced by black smokers. These form around hydrothermal vents on the mid-ocean ridges where tectonic plates are pulling apart and new crust is forming. In such places, seawater seeping down into the rock comes into contact with hot magma. Superheated water then boils back up, carrying hydrogen, carbon dioxide, and sulfur compounds, which precipitate out to build smoking undersea chimneys. Probes sent thousands of feet down to explore these otherworldly environments find them teeming with weird life forms of all kinds, attracted by warmth, nutrients, and each other. Some of the inhabitants may go a long, long way back.</p><p>Like lava rock, the chimneys are porous, and the pores are ideal little chambers for contained chemical reactions to take place—potentially powered by a handy energy source, since the hydrogen gas creates proton gradients across the thin walls between pores, making them act like batteries.<span id="ft-2" class="reference"> <sup class="footnote-ref">2</sup> </span>Given energy, iron sulfide minerals in the rock to act as catalysts, and carbon dioxide bubbling through, self-perpetuating loops of chemical reactions can sputter to life, like a motor turning over.</p><h2>Symbiogenesis</h2><p>It’s likely that bacteria are themselves the product of such symbiotic events—for instance, between RNA and metabolism.<span id="ft-3" class="reference"> <sup class="footnote-ref">3</sup> </span>RNA <em>could</em> replicate without help from proteins, and the metabolic motor <em>could</em> proliferate without help from genes, but when these systems cooperate, they do better. The looping chemical reaction networks in those black smokers can be understood as such an alliance in their own right, a set of reactions which, by virtue of catalyzing each other, can form a more robust, self-sustaining whole.</p><p>So in a sense, Darwin may have been right to say that “it is mere rubbish” to think about the origin of life, for life may have <em>had</em> no single origin, but rather, have woven itself together from many separate strands, the oldest of which look like ordinary chemistry. Intelligent design is not required for that weaving to take place; only the incontrovertible logic that sometimes an alliance creates something enduring, and that whatever is enduring … endures.</p><p>Often, <em>enduring</em> means both creating and occupying entirely new niches. Hence eukaryotes did not replace bacteria; indeed, they ultimately created many new niches for them. Likewise, the symbiotic emergence of multicellular life—another major evolutionary transition—did not supplant single-celled life. Like an ancient parchment overwritten by generations of scribes, our planet is a palimpsest, its many-layered past still discernible in the present. Even the black smokers, throwbacks to a Hadean sea billions of years ago, are still bubbling away in the depths. The self-catalyzing chemistry of proto-life may still be brewing down there, slowly, on the ocean floor.</p><p>The idea that evolution is driven by symbiotic mergers, the earliest of which preceded biology as we know it, has far-reaching implications. One is that the boundary between life and non-life is not well defined; symbiogenesis can involve any process that, one way or another, is self-perpetuating. Evolutionary dynamics are thus more like a physical law than a biological principle. <em>Everything</em> can be subject to evolution, whether we consider it to be “alive” or not.</p><p>The symbiogenetic view also renders the idea of distinct species, classified according to a Linnaean taxonomy, somewhat ill-defined—or at best, of limited applicability. Such taxonomies assume that only branching takes place, not merging. Bacteria, which promiscuously transfer genes even between “species,” already challenge this idea.<span id="ft-4" class="reference"> <sup class="footnote-ref">4</sup> </span>Taxonomies break down entirely when we try to apply them to even more fluid situations, like the possible proto-life in black smokers, or microbiomes, or the more complex symbioses we’ll explore later.</p><p>When one prokaryote ends up living inside another, though, or multiple cells band together to make a multicellular life form, the resulting composite organism is clearly more complex than its parts. Something genuinely new has arisen. The branching and fine-tuning of classical evolution can now start to operate on a whole different level, over a new space of combinatorial possibilities.</p><p>Classical evolution isn’t <em>wrong</em>; it just misses half of the story—the more rapid, more creative half. One could say that evolution’s other half is <em>re</em>volution, and that revolutions occur through symbiosis.</p><p>It’s equally meaningful to talk about ancient life forms, like bacteria and archaea, co-existing alongside recent and far more complex ones, like humans—while recognizing that humans are, in a sense, nothing more than complex colonies of bacteria and archaea that have undergone a cascade of symbiotic mergers.</p><h2>Reproductive functions</h2><p><strong>While most biochemists have focused on understanding the particular history and workings of life on Earth, a more general understanding of life has come from an unexpected quarter: computer science.</strong> The theoretical foundations of this surprising connection date back to two of the field’s founding figures: Alan Turing (1912–1954) and John von Neumann (1903–1957).</p><div class="img-wrapper figarea" id="turing"><div class="text-img turing-text">Interest in Turing’s life and work has surged in the past decade, in part because of an AI thought experiment he posed in a 1950 paper, “Computing Machinery and Intelligence.”[^16] In that paper, Turing proposed that the *appearance* of intelligence under human questioning and the *reality* of intelligence could not justifiably be separated; sustained and successful imitation *was* the real thing. Hence the “Imitation Game,” now called the “Turing Test” in his honor.<p>Turing’s most important contribution to computer science came fifteen years earlier, though. After earning a degree in mathematics at Cambridge in 1935, he focused on one of the fundamental outstanding problems of the day: the <em>Entscheidungsproblem</em> (German for “decision problem”), which asked whether there exists an algorithm for determining the validity of an arbitrary mathematical statement. The answer turned out to be “no,” but the way Turing went about proving it ended up being far more important than the result itself.<span id="ft-5" class="reference"> <sup class="footnote-ref">5</sup></span></p></div><div class="figure image" id="turing-fig"><figure class="" id="turing-img"><img src="/assets/images/chapter-14/Alan_Turing_Aged_16-Enhanced + Noise.webp" alt="Studio portrait of Alan Turing. " title="Studio portrait of Alan Turing. " id="Alan_Turing_Aged_16-Enhanced + Noise.webp"><figcaption>Alan Turing at age 16, ca. 1928.</figcaption></figure></div><div class="text-img turing-text"></div></div><p></p><p>In real life, though, the brain is not an abstract machine, but part of the body, and the body is part of the physical world. How can one speak in purely computational terms about the <em>function</em> of a living organism, when it must physically grow and reproduce?</p><p>It’s possible for a trivially simple structure, like a seed crystal, to “reproduce” merely by acting as a template for more of the same stuff to crystallize around it. But a complex machine—one with any internal parts, for example—can’t serve as its own template. And if you <em>are</em> a complex machine, then, on the face of it, manufacturing something just as complex as you yourself are has a whiff of paradox, like lifting yourself up by your own bootstraps. However, von Neumann showed that it is not only possible, but straightforward, using a generalization of the Universal Turing Machine.</p><p>He envisioned a “machine A” that would read a tape containing sequential assembly instructions based on a limited catalog of parts, and carry them out, step by step. Then, there would be a “machine B” whose function was to copy the tape—assuming the tape itself was also made of available parts. If instructions for building machines A and B are <em>themselves</em> encoded on the tape, then <em>voilà</em>—you would have a replicator.<span id="ft-6" class="reference"> <sup class="footnote-ref">6</sup></span></p><p>Instructions for building any additional non-reproductive machinery could also be encoded on the tape, so it would even be possible for a replicator to build something <em>more</em> complex than itself.<span id="ft-7" class="reference"> <sup class="footnote-ref">7</sup> </span>A seed, or a fertilized egg, illustrates the point. Even more fundamentally, encoding the instructions to build oneself in a form that is itself replicated (the tape) is the key to open-ended evolvability, meaning the ability for evolution to select for an arbitrary design change, and for that change to be inherited by the next generation.</p><p>Remarkably, von Neumann described these requirements for an evolvable, self-replicating machine before the discovery of DNA’s structure and function.<span id="ft-8" class="reference"> <sup class="footnote-ref">8</sup> </span>Nonetheless, he got it exactly right. For life on Earth, DNA is the tape; DNA polymerase, which copies DNA, is “machine B”; and ribosomes, which build proteins by following the sequentially encoded instructions on DNA, are “machine A.” Ribosomes and DNA polymerase are made of proteins whose sequences are, in turn, encoded in our DNA and manufactured by ribosomes. That is how life lifts itself up by its own bootstraps.</p><h2>Life as computation</h2><p><strong>Although this is seldom fully appreciated, von Neumann’s insight established a profound link between life and computation.</strong> Remember, machines A and B are Turing Machines. They must execute instructions that affect their environment, and those instructions must run in a loop, starting at the beginning and finishing at the end. That requires branching, such as “<em>if</em> the next instruction is the codon CGA <em>then</em> add an arginine to the protein under construction,” and “<em>if</em> the next instruction is UAG <em>then</em> STOP.” It’s not a metaphor to call DNA a “program”—that is literally the case.</p><p>Of course, there are meaningful differences between biological computing and the kind of digital computing done by the ENIAC or your smartphone. DNA is subtle and multilayered, including phenomena like epigenetics and gene proximity effects. Cellular DNA is nowhere near the whole story, either. Our bodies contain (and continually swap) countless bacteria and viruses, each running their own code.</p><p>Parallelism, too, is increasingly fundamental to computing today. Modern AI, for instance, depends on both massive parallelism <em>and</em> randomness—as in the parallelized “stochastic gradient descent” (SGD) algorithm, used for training most of today’s neural nets, the “temperature” setting used in chatbots to introduce a degree of randomness into their output, and the parallelism of Graphics Processing Units (GPUs), which power most AI in data centers.</p><p>Traditional digital computing, which relies on the centralized, sequential execution of instructions, was a product of technological constraints. The first computers needed to carry out long calculations using as few parts as possible. Originally, those parts were flaky, expensive vacuum tubes, which had a tendency to burn out and needed frequent replacement by hand. The natural design, then, was a minimal “Central Processing Unit” (CPU) operating on sequences of bits ferried back and forth from an external memory. This has come to be known as the “von Neumann architecture.”</p><p>Nonetheless, we should keep in mind what these two pioneers understood so clearly: computing doesn’t have to be done with a central processor, logic gates, binary arithmetic, or sequential programs. One can compute in infinitely many ways. Turing and his successors have shown that they are all equivalent, one of the greatest accomplishments of theoretical computer science.</p><p>It’s just as possible, though similarly slow, for a serial computer to emulate a neural network, heir to Turing’s “unorganized machine.” That’s why it wasn’t practical to run really big neural nets like those in Transformer-based chatbots until recently, thanks to ongoing progress in the miniaturization, speed, and parallelism of digital computers.</p><h2>Artificial life</h2><p><strong>Von Neumann’s work on self-reproducing automata shows us that, in a universe whose physical laws did not allow for computation, it would be impossible for life to evolve.</strong> Luckily, the physics of our universe <em>do</em> allow for computation, as proven by the fact that we can build computers—and that we’re here at all.</p><p>Now we’re in a position to ask: in a universe capable of computation, <em>how often</em> will life arise? Clearly, it happened here. Was it a miracle, an inevitability, or somewhere in between?</p><p>A few collaborators and I set out to explore this question in late 2023.<span id="ft-9" class="reference"> <sup class="footnote-ref">9</sup> </span>Our first experiments made use of an esoteric programming language invented thirty years earlier by a Swiss physics student and amateur juggler, Urban Müller. I’m afraid he called this language … Brainfuck. Please direct all naming feedback his way.</p><p>However, the shoe fits; it <em>is</em> a beast to program in. Here, for instance, is a Brainfuck program that prints “helloworld”—and good luck making any sense of it:</p><p>++++++[−&gt;+++++&lt;]&gt;−[&gt;[++++&gt;]++++[&lt;]&gt;−]&gt;&gt;&gt;&gt;.&gt;+.&lt;&lt;…&lt;−.&lt;+++.&gt;.+++.&gt;.&gt;&gt;−.</p><p>The upside of Brainfuck is its utter minimalism. It’s not quite a single-instruction language, like SUBLEQ, but as you can see, it includes only a handful of operations. Like a Turing Machine, it specifies a read/write head that can step left (the “&lt;” instruction) or right (the “&gt;” instruction) along a tape. The “+” and “−” instructions increment and decrement the byte at the current position on the tape.<span id="ft-10" class="reference"> <sup class="footnote-ref">10</sup> </span>The “,” and “.” instructions input a byte from the console, or output a byte to it (you can count ten “.” instructions in the code above, one to print each letter of “helloworld”). Finally, the “[” and “]” instructions implement looping: “[” will skip forward to its matching “]” if the byte at the current position is zero, and “]” will jump back to its matching “[” if the byte is <em>non</em>zero. That’s it!</p><p>It’s hard to believe that Brainfuck could be used to fully implement, say, the Windows operating system, but—it <em>is</em> “Turing complete.” Here that means: given enough time and memory (that is, a long enough tape), it can emulate any other computer and compute anything that <em>can</em> be computed.</p><p>In our version, which we call bff, there’s a “soup” containing thousands of tapes, each of which includes both code <em>and</em> data. This is key: in “classic” Brainfuck, the code is separate from the tape, whereas in bff, we wanted the code to be able to modify itself. That can only happen if the code itself is on the tape, as Turing originally envisioned.</p><p>Bff tapes are of fixed length—64 bytes, just one byte longer than the cryptic “helloworld” program above. They start off filled with random bytes. Then, they interact at random, over and over. In an interaction, two randomly selected tapes are stuck end to end, and this combined 128 byte–long tape is run, potentially modifying itself. The 64 byte–long halves are then pulled back apart and dropped back into the soup. Once in a while, a byte value is randomized, as cosmic rays do to DNA.</p><p>Since bff has only 7 instructions (represented by the characters “&lt;&gt;+−,[]”) and there are 256 possible byte values, following random initialization only 7/256, or 2.7%, of the bytes in a given tape will contain valid instructions; any non-instructions are simply skipped over.<span id="ft-11" class="reference"> <sup class="footnote-ref">11</sup> </span>Thus, at first, not much comes of interactions between tapes. Once in a while, a valid instruction will modify a byte, and this modification will persist in the soup. On average, though, only a couple of computational operations take place per interaction, and usually, they have no effect. In other words, while any kind of computation is theoretically <em>possible</em> in this toy universe, precious little of it actually takes place—at first. Random mutation may alter a byte here and there. Even when a valid instruction causes a byte to change, though, the alteration is arbitrary and purposeless.</p><p>Let’s pause and take stock of why this is so remarkable.</p><p>On an intuitive level, one doesn’t expect function or purposiveness to emerge spontaneously. To be sure, we’ve known for a long time that a modest degree of <em>order</em> can emerge from initially random conditions; for instance, the lapping of waves can approximately sort the sand on a beach, creating a gradient from fine to coarse. But if we were to begin with sand on a beach subject to random wave action, and came back after a few hours to find a poem written there, or the sand grains fused into a complex electronic circuit, we would assume someone was messing with us.</p><p>The extreme improbability of complex order arising spontaneously is generally understood to follow from thermodynamics, the branch of physics concerned with the statistical behavior of matter subject to random thermal fluctuations—that is, of all matter, since above absolute zero, <em>everything</em> is subject to such randomness. Matter subject to random forces is supposed to become more random, not less. Yet by growing, reproducing, evolving, and indeed by existing at all, life seems to violate this principle.</p><p>The violation is only apparent, for life requires an input of free energy, allowing the forces of entropy to be kept at bay. Still, the seemingly spontaneous emergence and “complexification” of living systems has appeared to be, if not strictly disallowed by physical laws, at least unexplained by them. That’s why the great physicist Erwin Schrödinger (1887–1961) wrote, in an influential little book he published in 1944 entitled <em>What Is Life?</em>,<span id="ft-12" class="reference"> <sup class="footnote-ref">12</sup></span></p><p>“[L]iving matter, while not eluding the ‘laws of physics’ as established up to date, is likely to involve ‘other laws of physics’ hitherto unknown, which, however, once they have been revealed, will form just as integral a part of this science as the former.”</p><h2>Thermodynamics</h2><p><strong>Before turning to those “other laws of physics,” it’s helpful to take a closer look at the original ones, and especially the Second Law of thermodynamics.</strong></p><p>These are deep waters. While the fundamental ideas date back to the groundbreaking work of nineteenth-century mathematical physicist Ludwig Boltzmann (1844–1906), we can understand their essence without math. Nonetheless, Boltzmann’s conceptually challenging ideas flummoxed many of his fellow scientists, and their implications continue to stir controversy even today. Much has been made of Einstein turning our everyday notions of space and time inside-out with his theory of relativity, developed in its initial form in 1905—just a year before Boltzmann, struggling with bipolar disorder, ended his own life. Arguably, though, Boltzmann’s earlier ideas disrupt our intuitions about time, cause, and effect even more radically than Einstein’s theory of relativity.<span id="ft-13" class="reference"> <sup class="footnote-ref">13</sup> </span>Let’s dive in.</p><p>The Second Law of thermodynamics holds that any closed system will rise in entropy over time, becoming increasingly disordered. A hand-powered lawn mower, for example, starts off as a beautifully polished machine with sharp helical blades, round wheels, and toothed gears, all coupled together on smoothly rotating bearings. If left out in the elements, the bearings will seize up, the blades will dull, and oxidation will set in. After enough time, only a heap of rust will remain.</p><p>Similarly, if you were to take a dead bacterium (which, though a lot smaller, is far more complicated than a push mower) and drop it into a beaker of water, its cell membrane would eventually degrade, its various parts would spill out, and after a while only simple molecules would remain, dispersed uniformly throughout the beaker.</p><p>The Second Law gives time its arrow, because the fundamental laws of physics in our universe are very nearly time-reversible.<span id="ft-14" class="reference"> <sup class="footnote-ref">14</sup> </span>Strange, but true: Newton’s equations (classical dynamics), Maxwell’s equations (electromagnetism), Schrödinger’s equations (quantum physics), Einstein’s equations (special and general relativity)—all of these physical laws would work the same way if time ran in reverse. The difference between the past and the future is <em>statistical</em>.</p><p>Theoretically, nothing prevents the exact series of collisions from happening that would result in all of the energy being transferred to a single ball while leaving the others arrayed in a perfect triangle; but statistically, it’s vanishingly unlikely for such an ordered state to arise out of disorder—unless, perhaps, some mastermind set the balls in motion just <em>so</em>.</p><p>Although key thermodynamic concepts weren’t developed until the nineteenth century, an Enlightenment-era belief in a God who set the universe in motion just so arises intuitively from the apparent impossibility of order arising spontaneously out of disorder.<span id="ft-15" class="reference"> <sup class="footnote-ref">15</sup> </span>In a mechanical, billiard-table universe where the laws of physics are inviolable and the laws of statistics seem to inexorably degrade any pre-existing order over time, it seems absurd that anything as complicated as life <em>could</em> arise spontaneously without some supernatural agent acting as “prime mover.” Only a God with exquisite foresight could have “initialized” the Big Bang such that, in the Earth’s oceans billions of years ago, simple organic molecules floating around apparently at random could coalesce into a working bacterium—an improbability many, many orders of magnitude less likely than fifteen out of sixteen whizzing billiard balls spontaneously coalescing into an unmoving triangle.</p><p>The billiard ball universe I’ve just described may seem abstract or arbitrary, but nineteenth-century theorists like Boltzmann had become interested in this problem for the most practical of reasons: it was the physics behind steam power, hence the entire Industrial Revolution. Engineering had preceded theory, as it often does.</p><p>However, even as coal-powered engines transformed the Victorian landscape—both figuratively and literally, for the pollution was dire—nobody understood them at a deep level. What <em>was</em> heat, and how could it be converted into physical work? For a time, the leading theory held that heat was a kind of invisible, weightless fluid, “caloric,” that could flow spookily into and through other matter.</p><p>Before moving beyond classical thermodynamics, let’s add a bit more realism to our billiard-ball universe. We know that balls bouncing around a billiard table don’t <em>actually</em> go on bouncing forever. They encounter friction, slowing down as they roll. And when they bounce off each other, the collisions are slightly “inelastic,” meaning that after the collision, they’re moving a bit slower than before. After a little while, they stop rolling.</p><p>How can that be? At a microscopic level, the laws of physics are reversible. Momentum is supposed to be conserved. And the amount of matter and energy also remains constant, whether we run time forward or in reverse. That’s the <em>First</em> Law of thermodynamics!</p><p>Zooming in will reveal that, on a real billiard table, balls aren’t the smallest elements that bump against one other. Each billiard ball consists of lots of vibrating molecules bound together, and collisions between these individual molecules are what really cause the balls to bounce off each other—or, for that matter, cause a ball to roll across the felt rather than falling right through it.<span id="ft-16" class="reference"> <sup class="footnote-ref">16</sup> </span>In each case, momentum is transferred between molecules. Every time this happens, the distribution of molecular momenta becomes a bit more random, that is, a bit less correlated with which ball the molecule happens to be in, or indeed whether it is in a ball at all, or in the felt underneath.</p><p>In the most random distribution of molecular velocities, there would be no more correlation between the velocities of two molecules in one ball than in the velocities of molecules in different balls. Every ball would be imperceptibly jiggling in place, with each of its constituent molecules contributing minutely to the dance. We call that random jiggling “heat.” When all correlated motion has been converted into uniformly distributed heat, we’ve reached a stable equilibrium.</p><p>While the balls are still rolling, the correlations between the velocities of their molecules are by no means all equal; the distribution is far from random. This is <em>not</em> a stable equilibrium. Hence, the inevitability of friction and the inelasticity of collisions are statistical phenomena—just more symptoms of the inexorable Second Law.</p><p>Going forward, then, we can zoom back out and imagine once more that the billiard balls are indivisible particles, not bound collections of molecules. In that case, all collisions would have to be elastic, all motion frictionless, and disordered, randomly colliding balls would be the equilibrium.</p><p>Once a system has reached equilibrium, it will stay that way forever—an end state Lord Kelvin called “heat death.”<span id="ft-17" class="reference"> <sup class="footnote-ref">17</sup> </span>This seemingly trivial observation has some profound consequences. One is that the arrow of time will lose its meaning; any two consecutive moments <em>A</em>, <em>B</em> could just as likely have been ordered <em>B</em>, <em>A</em>. Nothing, therefore, can be said to be a cause, versus an effect.</p><p>Relatedly, no <em>work</em> can be done. If the system were out of equilibrium—for instance, if all of the whizzing balls were on one side of the billiard table—then we could put a movable barrier down between the empty and occupied sides, attached to a loaded crankshaft. As they bounce around, the balls would then nudge the barrier, doing work. What I’ve just described is, of course, a piston, like that of a steam engine.</p><p>But if the balls were equally likely to be anywhere, then no matter how fast they whizz and bounce, there’s nowhere to put the barrier that would result in any net force. The piston wouldn’t move because it would be buffeted equally from all sides. This idea can be generalized: work can only be done by a system in disequilibrium, for instance, when the pressure or temperature is high in one place, and low in another. That’s why Newcomen’s engine needed both hot steam <em>and</em> cold water.</p><p>I’ve already used the term <em>free energy</em>, but now we can define it. The free energy of a system is the amount of work it can be made to do. Far from equilibrium, when the entropy is low, much of the kinetic energy in the billiard balls is “free”; it can be used to move pistons, raise weights, produce electric currents, carry out computations, or drive metabolic processes. But at equilibrium, the entropy is maximized, and the free energy is zero. This insight into the relationship between energy, entropy, and work lies at the heart of thermodynamics—and life.</p><h2>Dynamic stability</h2><p><strong>Recall that life seemed deeply weird to Schrödinger because living things appear to violate the Second Law.</strong> If the bacterium we drop into a beaker of water is alive rather than dead, and free energy is available in a form the bacterium can use, and the water contains simple molecules suitable for building more bacteria, then over time we will see the very opposite of an increase in disorder. After a while, the beaker will be <em>full</em> of bacteria, reproducing, cooperating, and competing with each other.</p><p>They will even be evolving. If the beaker is sufficiently large—the size of a planet, for instance—and we wait a few billion years, then eventually beings as complicated as us may be in there, along with cities, advanced technologies, and perhaps plans to colonize the next beaker.</p><p>None of these processes can occur without free energy. For us, it comes, ultimately, from the sun. Thermodynamics tells us that even if the Second Law appears to be violated locally, it still holds when we zoom out. Order created in one place comes at the expense of increased disorder elsewhere. Hence, pollution, the finite lifetime of the sun, and the eventual heat death of the universe.</p><p>What concerns us here isn’t this big picture, but its apparent local violations, and the way they seem to become increasingly transgressive over time. The puzzle isn’t only that bacteria exist, but that the more time passes, the more complex life on Earth seems to become: from prokaryotes to eukaryotes; from eukaryotes to multicellular animals; from simple multicellular animals to ones with nervous systems; from brainy animals to complex societies; from horses and plows to space travel and AI.</p><p>Is there any general principle behind that complexification process, a kind of “however” or “yes, and” to the dismal Second Law? And could it account not only for evolution and complexification, but also for abiogenesis?</p><p>Yes, and yes. Bff can offer us a highly simplified model system for understanding that principle, just as an idealized billiard table gives us a model for understanding basic thermodynamics.</p><p>Replicators arise in bff because an entity that reproduces is more “dynamically stable” than one that doesn’t. In other words, if we start with one tape that <em>can</em> reproduce and one that <em>can’t</em>, then at some later time we’re likely to find many copies of the one that can reproduce, but we’re unlikely to find the other at all, because it will have been degraded by noise or overwritten.</p><p>Addy Pross, a professor emeritus of chemistry at Ben Gurion University of the Negev, describes the same phenomenon using the bulkier phrase “dynamic kinetic stability” (DKS).<span id="ft-18" class="reference"> <sup class="footnote-ref">18</sup> </span>I’ll drop “kinetic,” since the idea also applies beyond Pross’s field of “chemical kinetics” (describing the rates at which chemical reactions take place). In bff, for example, dynamic stability can just as well apply to programs or program fragments.</p><p>As Pross points out, a population of molecules capable of replicating can be more stable than even the hardiest of passive materials. A passive object may be fragile, like a soap bubble, or robust, like a stone sculpture. The sculpture might endure for longer, but, in the end, it’s still ephemeral. Every encounter it has with anything else in the world will cause its composition or structure to degrade, its individual identity to blur. For a sculpture, it’s all downhill. That’s the Second Law at work, as usual.</p><p>A self-reproducing molecule—like the DNA inside a living bacterium—is another matter. It is thermodynamically fragile, especially if we consider its identity to consist not only of a general structure but of a long sequence of specific nucleotides. However, its <em>pattern</em> is not just robust, but “antifragile.”<span id="ft-19" class="reference"> <sup class="footnote-ref">19</sup> </span>As long as DNA is able to reproduce—an inherently dynamic process—that pattern can last, essentially, forever. A bit of environmental stress or adversity can even help DNA maintain or improve its functionality. This is how order overcomes disorder.</p><p>In fact, Darwinian selection is <em>equivalent</em> to the Second Law, once we expand our notion of stability to include populations of replicators. Through a thermodynamic lens, Darwin’s central observation was that a more effective replicator is more stable than a less effective one. As Pross puts it,</p><p>“[M]atter […] tends to become transformed […] from less stable to more stable forms. […] [T]hat is what chemical kinetics and thermodynamics is all about […]. And what is the central law that governs such transformations? The Second Law. […] In both [the static and kinetic] worlds chemical systems tend to become transformed into more stable ones […]—thermodynamic stability in the ‘regular’ chemical world, dynamic kinetic stability in the replicator world.”<span id="ft-20" class="reference"> <sup class="footnote-ref">20</sup></span></p><p>As a chemist, Pross is sensitive to the close relationships between energy, entropy, and stability, whether static or dynamic. However, he does not explicitly make a connection to the theory of computing.</p><p>It now seems clear that by unifying thermodynamics with the theory of computation, we should be able to understand life as the predictable outcome of a statistical process, rather than regarding it uneasily as technically permitted, yet mysterious. Our artificial life experiments demonstrate that, when computation is possible, it will be a “dynamical attractor,” since replicating entities are more dynamically stable than non-replicating ones; and, as von Neumann showed, replicators are inherently computational.</p><p>Bff has no concept of energy, but in our universe, replicators require an energy source. This is because, in general, computation involves irreversible steps—otherwise known as causes and effects—and thus, computing consumes free energy. That’s why the chips in our computers draw power and generate heat when they run. (And why my computer heats up when it runs bff.) Life must draw power and generate heat for the same reason: it is inherently computational.</p><h2>Complexification</h2><p><strong>When we pick a tape out of the bff soup after millions of interactions, once replicators have taken over, we often see a level of complexity in the program on that tape that seems unnecessarily—even implausibly—high.</strong> A working replicator <em>could</em> consist of just a handful of instructions in a single loop, requiring a couple of hundred operations to run. Instead, we often see instructions filling up a majority of the 64 bytes, multiple and complex nested loops, and thousands of operations per interaction.</p><p>Where did all this complexity come from? It certainly doesn’t look like the result of simple Darwinian selection operating on the random text generated by a proverbial million monkeys typing on a million typewriters.<span id="ft-21" class="reference"> <sup class="footnote-ref">21</sup> </span>In fact, such complexity emerges even with <em>zero</em> random mutation—that is, given only the initial randomness in the soup, which works out to fewer bytes than the text of this short book. Hardly a million monkeys—and far too few random bytes to contain more than a few consecutive instructions, let alone a whole working program.</p><p>The answer recalls Lynn Margulis’s great insight: the central role of symbiosis in evolution, rather than random mutation and selection. When we look carefully at the quiescent period before tapes begin replicating, we notice a steady rise in the amount of computation taking place. We are observing the rapid emergence of <em>imperfect</em> replicators—very short bits of code that, in one way or another, have some nonzero probability of generating more code. Even if the code produced is not like the original, it’s still code, and <em>only</em> code can produce more code; non-code can’t produce anything!</p><p>Thus, a selection process is at work from the very beginning, wherein code begets code. This inherently creative, self-catalyzing process is far more important than random mutation in generating novelty. When bits of proliferating code combine to form a replicator, it’s a symbiotic event: by working together, these bits of code generate more code than they could separately, and the code <em>they</em> generate will in turn produce <em>more</em> code that does the same, eventually leading to whole-tape replication and an exponential takeoff.</p><p>However, evolution’s creative work is not done yet. After the takeoff of a fully functional tape replicator, we often see yet further symbiotic events. From a classical Darwinian standpoint, this seems puzzling, since there should be no reason for further evolution to take place once whole tapes are replicating reliably. How could “fitness” possibly improve further, once a tape copies itself in its entirety every time it interacts with another tape?</p><p>We must consider that since the instructions for whole-tape replication don’t occupy all 64 bytes, there’s extra space on the tape that could be dedicated to … anything. That’s the point of von Neumann–style replication—it allows for open-ended evolution precisely because the tape can contain additional information, beyond the code needed for replication itself.<span id="ft-22" class="reference"> <sup class="footnote-ref">22</sup></span></p><p>Any extra replicated bytes could, of course, be random—just passive, purposeless information cargo hitchhiking from one generation to the next. But if these bytes contain instructions, those instructions can run. And if they can run, they can replicate <em>themselves</em>, too. Thus, the symbiogenetic process can continue to operate, creating additional replicators <em>within</em> an already replicating tape. Sometimes these sub-replicators even produce multiple copies of themselves in a single interaction.</p><p>Sub-replicators can interact with their host in many ways. They can “kill” the host by damaging <em>its</em> replication code, which is generally catastrophic for the sub-replicator, as it thereby destroys the environment within which it can run. Sub-replicators can be neutral, leaving the host’s replication machinery alone. Or, they can be symbiotic, for instance by conferring resistance to mutational damage via redundant copying of the host’s code. The overall tendency is toward symbiosis, since that is the most dynamically stable.</p><p>Over time, code colonizes a large proportion of the 64 bytes. Code is more dynamically stable than non-code, and its dynamic stability increases through symbiosis with yet more code—in particular, when code fragments find ways to work in functional tandem.</p><p>In a way, symbiosis is the very essence of functionality. When we talk about a kidney’s function only making sense <em>in context</em>, we mean that it is in symbiosis with other functions—like those of the liver (breaking ammonia down into urea), the heart (pumping blood), and so on. Each of these functions is <em>purposive</em> precisely because its inputs are the outputs of others, its outputs are inputs to others, and thus they form a network of dynamically stable cycles.</p><p>The same is true of larger, planetary-scale interrelationships. The “purpose” of plants, from the perspective of animal life, is to produce oxygen and sugar, which we breathe and eat. The “purpose” of animals, from a plant’s perspective, is to turn the oxygen back into carbon dioxide, and provide compost and pollination. Our growing understanding of life as a self-reinforcing dynamical process boils down not to <em>things</em>, but to networks of mutually beneficial <em>relationships</em>. At every scale, life is an ecology of functions.</p><p>Because functions can be expressed computationally, we could also say that life is code, and code is life. Individual computational instructions are the irreducible quanta of life—the minimal replicating set of entities, however immaterial and abstract they may seem, that come together to form bigger, more stable, and more complex replicators, in ever-ascending symbiotic cascades.</p><p>In the toy universe of bff, the elementary instructions are the seven special characters “&lt;&gt;+−,[]”. On the primordial sea floor, geothermally-driven chemical reactions that could catalyze further chemical reactions likely played the same role. Under other conditions, on another planet, or in another universe, many different elementary interactions could do the same—as long as they are Turing complete, enabling them to make the leap from autocatalytic sets to true replication.</p><h2>Virality</h2><p><strong>Although bff is only a toy universe, it can serve as a simplified model for life and evolution, just as a Newtonian billiard-ball universe can serve as a simplified model for the thermodynamics of ideal gases.</strong> As we’ve seen, some of bff’s predictions are quite different from those of classical Darwinian theory:</p><ol><li>Bff suggests that symbiogenesis is a more important driver of evolutionary innovation than random mutation.</li><li>Since symbiogenesis must involve combinations of pre-existing dynamically stable entities, we should expect complex replicating entities to emerge after (and be made of) simpler ones.</li><li>As a result, zooming in on sub-replicators within a larger replicator should allow us to peer back in evolutionary time.<span id="ft-23" class="reference"> <sup class="footnote-ref">23</sup></span></li></ol><p>These phenomena should sound familiar! They’re all consistent with Lynn Margulis’s observations, which flew in the face of twentieth-century biological orthodoxy, but are now, if not mainstream, at least gaining respectability.</p><p>But wait, there’s more:</p><ol start="4"><li>Due to the instability of the imperfect replicators leading up to the first true replicator, we should expect this first true replicator to be a historical “event horizon,” becoming the template for what follows and erasing independent traces of what came before.</li></ol><p>This is what we see on Earth too. Although the first chemical steps toward proto-life may still be taking place in environments like black smokers, we don’t see the missing links. Where are the kind of imperfect replicators that fused together to form the simplest life forms today?</p><p>We likely don’t see them on their own because, as in bff, their instability made them ephemeral, quickly displaced or absorbed by the first stably replicating cell—which might already have been recognizably kin to today’s bacteria and archaea. (Evolutionary biologists call this the “Last Universal Common Ancestor” or LUCA.) Still, we can assume that many of the component <em>parts</em> of the most ancient surviving life forms—like the reverse Krebs cycle and RNA replication—are fossilized fragments of earlier imperfect replicators.</p><p>In the same vein:</p><ol start="5"><li>Evolved code should not only include instructions for replicating itself as a whole, but also be rife with sub-sequences that contain instructions for independently replicating <em>them</em>selves.</li><li>If symbiosis among these parts generated the novelty driving evolution of the whole, we should see evidence in the genome of many “broken” or incomplete sub-replicators.</li><li>Code that evolved through such hierarchical symbiotic replication should also contain many sequences that are repetitive, or are copies of other parts.</li></ol><p>We can find all of these features in our own genetic code—and they don’t correspond to what we would expect to see if our genomes had evolved primarily through mutation and selection.</p><p>The reproductive cycle of viruses is an often-told story. When traveling between cells, a virus looks like a bit of DNA or RNA packaged into a protein “envelope” capable of binding to a target cell and injecting its genetic payload. Once inside the cell, the viral code hijacks cellular resources to begin replicating, both copying its genetic material and manufacturing its envelope proteins. These assemble into more viruses. Maniacally cranking out viral proteins, the cell may eventually burst, releasing a flood of virus particles to repeat the cycle.</p><p>“Retroviruses” like HIV (the Human Immunodeficiency Virus, which causes AIDS) include additional “reverse transcription” machinery for permanently incorporating their genetic material into the cell’s DNA. This makes them a lot harder for the host to clear. The key enzyme, “reverse transcriptase,” wasn’t characterized until 1970,<span id="ft-24" class="reference"> <sup class="footnote-ref">24</sup> </span>but Barbara McClintock (1902–1992), working at Cold Spring Harbor Lab on Long Island, had made an earlier discovery that turned out to be closely related.</p><p>Retroviruses are unsettlingly … <em>intimate</em>. HIV specifically targets immune cells, but if a retrovirus infects an egg or sperm cell, it can insert its code into an organism’s germ line, becoming a permanent part not only of that cell, but of an entire species. In a 2006 publication in the prestigious journal <em>Nature</em>, researchers at the University of Queensland in Australia reported catching a retrovirus in this act of becoming “endogenous” for the first time.<span id="ft-25" class="reference"> <sup class="footnote-ref">25</sup> </span>An epidemic of leukemia in koalas had first been traced to a retrovirus, then this retrovirus was found to have invaded the koala germ line over the previous century, causing the disease to become heritable.</p><p>Does this mean the end of koalas? Probably not.</p><p>The human genome is rife with signs that the same process has taken place many times in the history of our own species. At least 8% of our genome consists of endogenized retroviruses, the remnants of such retroviral invasions.<span id="ft-26" class="reference"> <sup class="footnote-ref">26</sup> </span>Remember, 8% is several times more DNA than codes for our “own” genes!</p><p>We usually think of viruses as mere disease agents, opportunistically parasitizing our cells to reproduce, since they have no reproductive machinery of their own. The reality may be very different, though. As many of us know from our recent experience with COVID,<span id="ft-27" class="reference"> <sup class="footnote-ref">27</sup> </span>viruses (and pathogens in general) tend to evolve into forms less lethal to their hosts over time, for obvious reasons—a dead host is a dead end for the pathogen, too. There’s mounting evidence that the relationship between virus and host can go even further, to become symbiotic. Retroviral code in our genome, for instance, has become fundamental to the formation of the placenta, the immune system, cell differentiation, and brain function.<span id="ft-28" class="reference"> <sup class="footnote-ref">28</sup></span></p><p>Moreover, endogenous retroviruses are only the tip of an even larger iceberg. Nearly half of our genome consists of transposable elements of one kind or another. Some were probably once retroviruses, or vice versa. Fully sequenced genomes are often rife with lengthy stretches of highly repetitive sequences, from long and complex to mere alternations of two or three symbols—evidence of sub-replicators running amok.</p><p>Our genomes, in other words, are not only reproduced as a whole, but include working reproductive sub-sequences at many scales. Some are new and can still cause disease; others are older and may have lost the ability to make viral envelopes or the other machinery needed to become infectious; and yet others have integrated themselves so deeply into our own code that they are no longer distinct. Some of this code is even serving critical functions in our bodies. It’s obvious that, at least by this last stage of the process, complete symbiosis has been established: neither the host nor the sub-replicator could survive, let alone reproduce, on its own.</p><p>In his 2009 book <em>Virolution</em>,<span id="ft-29" class="reference"> <sup class="footnote-ref">29</sup> </span>author and physician Frank Ryan goes further, arguing that viruses may have been symbionts all along. Plague viruses like HIV don’t come from nowhere; they are species jumpers. We know that HIV was originally SIV, the Simian Immunodeficiency Virus, variants of which are endemic to Old World primates including African green monkeys, sooty mangabeys, mandrills, and chimpanzees. Yet many of these viruses don’t sicken their original hosts.<span id="ft-30" class="reference"> <sup class="footnote-ref">30</sup></span></p><p>We also know that if a virus finds itself inside an organism whose physiology is <em>too</em> different from that of its original host, it can’t gain purchase—a lucky thing for you, if you’ve ever swallowed a mouthful of seawater, which likely contained about a billion virus particles! (Most would have targeted single-celled marine life.) The greatest danger seems to come from viruses adapted to a different but closely related species. Perhaps, when it kills, such a virus is doing its job: wiping out rivals who have invaded the original host’s territory.</p><p>Viruses could, in other words, work like an out-of-body immune system. Within our bodies, our immune systems seek out and destroy cells that are recognized as “not-us.” Outside our bodies, “our” viruses could be similarly seeking out and destroying whole animals who are recognized as “not-us.” Once a virus becomes endemic to a new population, though—even if it initially kills many—it will differentiate, co-adapt, and perhaps eventually go native.</p><p>One could consider bacterial pathogens through a similar lens; hence the well-documented plagues of smallpox that European colonists brought to the Americas, decimating Native populations, and the virulent (though less deadly) syphilis epidemic believed to have been brought back to Europe by Columbus.<span id="ft-31" class="reference"> <sup class="footnote-ref">31</sup> </span>Unlike bacteria, though, retroviruses don’t just take up residence in our environment or in our bodies, but fuse into our very genomes, becoming inextricably part of us—especially when they alter the germ line.</p><p>By sheer volume, our DNA appears to be made primarily of the layered remnants of many such past fusions. It seems clear that transposable elements and “endogenous viral elements” or EVEs have done much more editing of our genome in recent evolutionary history than mutation has.<span id="ft-32" class="reference"> <sup class="footnote-ref">32</sup> </span>And they have been at this for a long, long time. Based on the best available evidence, viruses are at least as old as the Last Universal Common Ancestor, if not older.<span id="ft-33" class="reference"> <sup class="footnote-ref">33</sup></span></p><p>In this light, random point mutation can even be seen as something like a minimal abiogenesis event, creating a tiny parasitic “life form” within the genome. On its own, it would of course be unable to reproduce, since it possesses no independent reproductive machinery;<span id="ft-34" class="reference"> <sup class="footnote-ref">34</sup> </span>then again, neither does a virus. So, like a virus, a mutation <em>can</em> reproduce—using the host’s resources, which will copy it along with everything else. When introduced into the genome of a sophisticated existing organism, such a tiny, random entity is unlikely to be friendly, though, as with any larger invasion, it will either kill its host (and itself, in the bargain) or achieve dynamic stability, either by being neutral or (occasionally) helpful.</p><p>Hence, just as replicator thermodynamics encompasses classical thermodynamics as a special case, evolution via symbiogenesis can encompass classical Darwinian theory as a special case. Point mutation is unlikely to be the main driver of evolution once life has taken off because it’s so much weaker and slower on its own than higher-order symbiogenesis. Unlike point mutation, a chunk of code that has already circulated, jumping around in the genome or even between species, isn’t random. It necessarily includes real functionality. And at least in some settings, that functionality has been under evolutionary pressure to help, or at least not kill, its host. Evolution picks up steam over time, with major evolutionary transitions becoming more frequent precisely because increasingly high orders of symbiogenesis become possible.</p><h2>Compression</h2><p><strong>When code evolves through symbiogenesis, it will develop a curious statistical structure: parts of it will be copies (or near-copies) of other parts, and as those parts establish symbiosis, they’ll form a larger aggregate which will <em>also</em> copy itself as a unit.</strong> This is reminiscent of (though not the same as) a “fractal”: a structure that resembles itself at a cascade of ever-finer scales. Let’s take a short detour through fractals and their relationship to biology so that we can then consider the implications of evolution <em>itself</em> exhibiting certain fractal-like properties.</p><p>Is life in general a kind of fractal, then? No. A rhyme by British mathematician Augustus De Morgan<span id="ft-35" class="reference"> <sup class="footnote-ref">35</sup> </span>is often invoked in describing fractals:</p><p><em>Great fleas have little fleas upon their backs to bite ’em,</em><br><em>And little fleas have lesser fleas, and so</em> ad infinitum*.*<span id="ft-36" class="reference"> <sup class="footnote-ref">36</sup></span></p><p>The poem is funny precisely because it is absurd: unlike an idealized fractal coastline, living systems are, in general, profoundly <em>dis</em>similar across scales.<span id="ft-37" class="reference"> <sup class="footnote-ref">37</sup> </span>While there are rare instances of the kind De Morgan describes—such as hyperparasitoid wasps, tiny parasites that lay their eggs inside bigger wasps—one does not generally zoom in on a flea to discover a smaller flea, let alone <em>ad infinitum</em>.</p><p>Similarly, although genomes are always replicated, and are made out of other genomes that are themselves replicated, every whole is different from its parts, just as an integrated circuit is different from a transistor. How, then, would one go about quantifying this multifractal-like property in a genome?</p><p>The answer is closely related to data compression. Consider bff. In its initial state, the tapes consist of random bytes; no repetitive structure exists. If we were reading through the tapes one byte at a time, the next byte would have an equal probability of assuming any value, from 0 to 255, independent of any of the previous bytes. Therefore, the sequence is entirely unpredictable, which means that if you were to try compressing the soup with file compression software, like ZIP, the compressor wouldn’t be able to squeeze the file size at all. (This is, harkening back to thermodynamics, a working definition of a completely disordered state.)</p><p>Data are redundant—that is, compressible—precisely to the degree that they are predictable, or, equivalently, exhibit order. Compression algorithms like those in ZIP work by looking for patterns in the data stream so far and exploiting those patterns to encode subsequent data using as few bits as possible. The usual trick is to incrementally build a dictionary or “phrase book” out of the source material, and to substitute sections of the text for pointers into this dictionary whenever the pointer can be encoded in fewer bits than the original text. The dictionary is, in effect, a predictive model, and since the compressor builds that model incrementally as it compresses, the decompressor is able to incrementally reconstruct an identical copy of the model as it <em>de</em>compresses.</p><p>Absent any prior knowledge about how to model a long sequence, describing it in terms of previously encountered parts of itself is a good strategy. The full text of this book ZIPs down to about 35% of its original size as a raw text string, since some letters occur more often than others, there are a lot of repeated words, and those words often combine into stock phrases.<span id="ft-38" class="reference"> <sup class="footnote-ref">38</sup></span></p><p>When bff undergoes its sharp transition to whole-tape replication, the tapes suddenly become highly compressible; they squeeze down to just 5% of their original size. Interestingly, many regions of the human genome are highly compressible too. The reason these data streams compress so well is that, at any given point in the sequence, one can often make a pretty good guess as to what the next letter will be, simply by looking for the longest previous sequence that matches the current context.</p><p>Such matches arise due to replication. In the human genome, we’re not talking about replication at the level of the individual, but, rather, at the level of transposable elements (or their fossil remnants) <em>within</em> our genome. Similarly, even a <em>single</em> bff tape is highly compressible, because it formed through a symbiotic fusion of smaller replicators … and these replicators are themselves likely to be either copies of each other or related, having formed out of yet smaller imperfect replicators … which are themselves either copies or related.</p><p>Like fractals, sequences of symbols constructed by repeatedly copying sub-sequences of all lengths exhibit power-law scaling—in this case, between the lengths of repeated sequences and their frequency. For instance, a replicated sequence twice the length of another might be found half as often—which is pretty often! (These statistics would be dramatically different for random sequences, where increasing the sequence length would cause a much faster <em>exponential</em> decline in expected frequency.<span id="ft-39" class="reference"> <sup class="footnote-ref">39</sup> </span>) Sequences constructed according to a fixed self-copying rule are, in a sense, infinitely compressible, for they contain only as much information as it would take to write down the recipe, no matter how long the sequence.</p><p>By contrast, in a complex replicating system like bff—let alone the genome—the <em>way</em> any particular set of replicating sub-sequences combine to form a larger replicating sequence will always be specific. It will depend on the functional particulars of how those parts come together to make a working whole. Therefore there is novelty, or information, in each such combination. However, that information will be much less than would be needed to specify an arbitrary symbol sequence of the same length.</p><p>When we look for this property in bff and in human genome data, that’s just what we find! Not only do both compress very well; they also compress better and better the longer the stream of data gets. For instance, a single bff tape compresses somewhat, but the whole soup compresses better, and as the size of the soup grows, the compression ratio continues to improve—though no matter how much has already been seen, the remainder is never fully predictable.</p><p>Similarly, while a single stretch of a human genome already compresses well, the whole genome compresses better. If you compress it in the statistical context of many other human genomes, so much of the information becomes redundant that a compressed version of <em>your</em> genome would be small enough to send as an email attachment.<span id="ft-40" class="reference"> <sup class="footnote-ref">40</sup> </span>The pattern continues if we zoom yet farther out to consider genomes across species. Hence the famous statistic that the human genome is 98% identical to the chimpanzee genome … and 60% similar to that of the fruit fly!</p><p>While common ancestry alone can explain many of the similarities across species (though not all, as BovB illustrates), such classical Darwinian arguments can’t explain why the genome of a single individual is also so repetitive. That only makes sense when we begin to consider genomes to be <em>made out of</em> smaller genomes.</p><p>DNA and bff tapes, in other words, are both systems that evolve through what we could call “multifractal symbiosis.” Our genomes are aggregates of cooperating replicators, all the way down. That’s why they are so compressible. But it’s also why wonderful new kinds of complexity emerge at every scale—and therefore why, in biology, we can always learn something new by zooming in or out.</p><h2>Embodiment</h2><p>This mechanism is vastly more powerful, general, and evolvable than merely replicating some “build a rib” code. It allows for code reuse, just as a programmer would do: invoking the same “build a rib” function a hundred times instead of copying and pasting it a hundred times. Thus, tweaking rib flexibility or curvature involves making one change, not a hundred.</p><p>The smoking gun, though, is the growth of self-similar structures in the body. Compositionality and recursion are what allow genetic code to build a many-tiered fractal like the circulatory system. Code for building ribs or nautilus segments could, in theory, just be copied a couple of hundred times, but that’s not possible for arteries, veins, or capillaries, where the number of segments and branches becomes astronomically large. The blood vessel branching code <em>must</em> get reused. And with relatively minor tweaks, it must be possible for the parameters of that code to be adjusted so that the branching stops at the appropriate size for a shrew, or goes on to construct something the size of a blue whale, since shrews and whales are, in the grand scheme of things, close relatives.</p><p>From an evolutionary perspective, compositionality implies a hierarchical network of symbiotic relationships. The bacteria that became mitochondria and the archaea that engulfed them each started with the code necessary to reproduce themselves. When they merged into a eukaryote, they still needed to retain the instructions for their own reproduction, but they also needed to evolve additional functionality for mutual regulation. When eukaryotes became multicellular, the same needed to happen again; our cells still know how to reproduce individually, and, indeed, cellular reproduction is a fundamental operation involved in the larger-scale growth and reproduction of a whole animal.</p><p>What is true of evolution is also true of development.<span id="ft-41" class="reference"> <sup class="footnote-ref">41</sup> </span>Blood vessels, for instance, aren’t just Euclidean line segments, but tubes made of layers of smooth muscle cells. Each of those cells contains a complement of organelles, and each mitochondrion in each of those cells contains its own membranes and loop of bacterial DNA. A living organism is a compositional structure <em>par excellence</em>. It could only be built computationally, through the composition of many functions. And life could only have evolved as the hierarchical composition of those functions—that is, through symbiogenesis.</p><h2>Élan vital</h2><p><strong>Nowadays, we interact with human-engineered (or, one could say, “artificial”) computers constantly: the phones in our pockets and purses, our laptops and tablets, data centers and AI models.</strong> We’ve begun asking whether AI models are intelligent. We could ask an even more jarring question: are computers, whether they’re running AI or not, <em>alive</em>?<span id="ft-42" class="reference"> <sup class="footnote-ref">42</sup></span></p><p>They are certainly purposive, or we couldn’t talk about them being broken or buggy. But hardware and software are, in general, unable to reproduce, grow, heal, or evolve on their own, because engineers learned long ago that self-modifying code (like bff, or DNA) is hard to understand and debug.<span id="ft-43" class="reference"> <sup class="footnote-ref">43</sup> </span>Thus, phones don’t make baby phones. Apps don’t write new versions of themselves.</p><p>And yet: there are more phones in the world this year than last year; apps acquire new features, become obsolete, and eventually reach end-of-life, replaced by new ones; and AI models are improving from month to month. Electronic components and computer code also exhibit the same kind of compositionality we’ve seen in bff and DNA. It certainly <em>looks</em> as if technology is reproducing and evolving! Debating its aliveness is thus a bit like the debate over whether viruses (which also can’t reproduce on their own) are alive.</p><p>If we zoom out, though, putting technology and humans in the frame together, we can see that this larger, symbiotic “us” is certainly reproducing, growing, and evolving. The emergence of technology, and the mutually beneficial—if sometimes fraught—relationship between people and tech is nothing more or less than our own most recent major evolutionary transition. Technology, then, is not distinct from nature or biology, but merely its most recent evolutionary layer.</p><p>And what about that age-old inanimate stuff—rocks and rivers, mountains and beaches, clouds and storms? Water molecules in themselves are clearly not capable of general computation, and yet, in the context of the hydrologic cycle, clouds, rainstorms, and rivers certainly serve critical ecological functions, and are profoundly shaped by life. Likewise, our planet’s metal and sand get shaped into steam engines and computer chips. All of these are part of that grand network of interdependency we call Earth. Why do we draw boundaries around certain networks of functions and insist that they are “alive,” while the surrounding functions are not?</p><p>This way lies vitalism, a view espoused in various forms by a long line of philosophers from Posidonius of Apameia (circa 135–51 BCE, and undoubtedly reflecting a much older tradition) to Henri Bergson (1859–1941). Some modern thinkers, too, defend the vitalist position, such as Jane Bennett:</p><p>“The quarantines of matter and life encourage us to ignore the vitality of matter and the lively powers <em>of</em> material formations […]. By ‘vitality’ I mean the capacity of things—edibles, commodities, storms, metals—not only to impede or block the will and designs of humans but also to act as quasi agents or forces with trajectories […] or tendencies of their own. [… Our] analyses of political events might change if we gave the force of things more due.”<span id="ft-44" class="reference"> <sup class="footnote-ref">44</sup></span></p><p>We resist such ideas because we tend to reserve the notion of agency only for ourselves. The idea of agency in a molecule or a storm, let alone an abstraction like money, seems especially far-fetched. We also tend to think in terms of a hierarchy in which “we” (for whatever value of “we”) are at the top, and agency must surely diminish for anything “lower”—a view reminiscent of the medieval Great Chain of Being. When we (hesitantly) extend “agency” to the nonhuman, we tend to do so only for things that act obviously, individually, and on fast timescales, rather than in the aggregate and on slower, more evolutionary ones. It might be time to re-examine these ideas more holistically.</p><p>My purpose here is not to follow in Bennett’s footsteps—though I do find her project worth taking seriously. Language is, necessarily, imprecise, no matter what definitions we pick. This doesn’t mean that words are useless, though. When our language can become more rigorous and scientifically grounded, and when we use it to describe patterns across a wide range of phenomena, we can start to see through ideological thickets.</p><p>I hope I have explained both clearly and rigorously how the phenomena that give rise to the complexifying dynamics of life apply much more broadly than to the entities we normally think of as “alive” or “agential.” Accordingly, we could expand our definitions of these existing words, or adopt new ones, or do a bit of each. Personally, I would find some broadening of the old everyday words helpful.</p><p>That would hardly break new ground. Many traditional, nominally “prescientific” worldviews embrace notions of aliveness, agency, and even personhood that are far broader than the modern Western ones. This seems a likely case of convergent evolution in languages and ideas, motivated by the common need among traditional societies to take symbiosis seriously to secure their own survival, and to flourish. It’s practical as much as it is spiritual: encouraging richer modeling of agency in “nature” enhances a society’s dynamic stability, since all things in “nature,” ourselves included, are so mutually interdependent.</p><p>Thus it can be useful to take the view of an animal, plant, or river at times, even if they can’t take ours, the better to care for them—and for ourselves. That, ultimately, is the best reason to consider adopting, or at least adapting, a more inclusive view of the animate. Potawatomi writer and biologist Robin Wall Kimmerer makes this case eloquently in her book <em>Braiding Sweetgrass</em>.<span id="ft-45" class="reference"> <sup class="footnote-ref">45</sup></span></p><h1>Acknowledgments</h1><p>Although this is a small book, it (appropriately enough) nestles into a tangled heterarchy of larger projects, owing its existence to a great many people and several institutions—especially Google, Antikythera, the Berggruen Institute, the Santa Fe Institute, the Mila-Quebec AI Institute, and MIT Press. Many of the people I’ll thank below are affiliated with more than one of these.</p><p>As a designed object, this book’s co-creator is James Goggin of Practise, in Auckland. Our third collaboration, <em>What Is Life?</em> further develops an approach to simultaneously physical and digitally native media we’ve established with our first two projects, <em>Ubi Sunt</em> and <em>Who Are We Now?</em> (both published by Hat &amp; Beard Press, with warm thanks to JC Gabel).</p><p>Clea Agüera-Arcas, Loraine Agüera-Arcas, and Johan Michalove have helped research, edited painstakingly, offered line-by-line critique, chased down sources and permissions, coded workflows, wrangled spreadsheets, and in short dedicated an immense effort over many months to making the book as beautiful, readable, fair, and accurate as we could. Brian Sholis did the final editing and proofreading. However, I take sole responsibility for any remaining errors or omissions, and all opinions, mistaken or not, are my own.</p><p>In collaboration with James Goggin, Minkyoung Kim and Marie Otsuka designed and implemented the web version, which includes a good deal of video and interactive content. The simulations owe a heavy debt to Alex Mordvintsev (also the inventor of neural cellular automata), and his elegant SwissGL library.</p><p>Close readings of the text and detailed editorial input, which improved the final result significantly, came from Benjamin Bratton, Stephanie Sherman, Adrienne Fairhall, Anselm Agüera y Arcas, Eliot Agüera y Arcas, David LeBrun, Ben Laurie, Luca Versari, David Wolpert, and Emily French. Warm thanks also to Patricia Churchland, Walter Fontana, N. Katherine Hayles, Reid Hoffman, Michael Levin, Johan Liedgren, Charles Mudede, Addy Pross, Carl Schoonover, Terry Sejnowski, Justin Smith-Ruiu, Dan Sperber, Korina Stark, John Thornhill, Sara Walker, and Ren Weschler. Thank you, Margaret Levi and Bob Kaplan, for connecting me with Papunya Tula Artists in Australia’s Western Desert, and thank you, Spike Mafford, for the beautiful photography. Yalti Napangati’s artwork, which envelopes this book, is the most eloquent expression of symbiogenesis.</p><p>At Google, I owe deep thanks to James Manyika and Sundar Pichai for giving my team, Paradigms of Intelligence (PI), the freedom and resources to pursue interdisciplinary basic research. I’m grateful to Demis Hassabis and Yossi Matias for their support of internal collaboration with Google DeepMind and Google Research, respectively, and to Yul Kwon for his deft co-leadership of PI. A big thank you to PI teammates and collaborators: Jyrki Alakuijala, Kenric Allado-McDowell, Travis Beals, Sami Boukourtt, Martin Bruse, Iulia Comșa, Yiğit Demirag, Moritz Firsching, Thomas Fischbacher, Alice Guan, Florian Hartmann, Anthony House, Geoff Keeling, Evgenii Kliuchnikov, Seijin Kobayashi, Marcin Kowalczyk, Rachelle Lacroix, Mira Lane, Alison Lentz, Brittni Maekawa, Kaitlin Maile, Delaney McMillen, Alexander Meulemans, Alex Mordvintsev, Eyvind Niklasson, Peter Norvig, Robert Obryk, Ettore Randazzo, Esteban Real, João Sacramento, Mark Sandler, Rif Saurous, Nino Scherrer, Anoop Sinha, Oliver Siy, Winnie Street, Zoltan Szabadka, Luca Versari, Sarah de Haas, and Johannes von Oswald. Visiting faculty James Evans, Guillaume Lajoie, and Blake Richards have been wonderful friends and colleagues, and have all made intellectual contributions to the material presented here.</p><p>Time spent at the Santa Fe Institute over the past two years has profoundly influenced my perspective on life, complexity, and intelligence. I have also met a number of new collaborators, fellow travelers, and constructive critics (often a bit of each) there, including Kevin Berger, Sean Carroll, David Chalmers, Ted Chiang, Michael Hersch, Chris Kempes, David Krakauer, John Krakauer, Gary Lupyan, Brice Ménard, Melanie Mitchell, Carlo Rovelli, Zenna Tavares, Geoffrey West, and David Wolpert.</p><p><em>What Is Life?</em> and its mothership <em>What Is Intelligence?</em> are among the first long-form publications of the Antikythera program, under the direction of Benjamin Bratton. Benjamin has instigated many of my major writing projects in recent years, including these books, and has been a loyal friend and frequent collaborator. Warm thanks also to Haley Albert, Nicolay Boyadjiev, Nils Gilman, Emily Knapp, Dawn Nakagawa, Estela Oliva, Tobias Rees, and Claire Webb; my gratitude, also, to Nicolas Berggruen for his intellectual friendship and support, and to the Berggruen Institute.</p><p>Finally, warm thanks to Noah Springer of MIT Press, for believing in this project and for helping us bend the rules of traditional academic publishing.</p><h1>About the author</h1><p>Blaise Agüera y Arcas is a VP and Fellow at Google, where he is the CTO of Technology &amp; Society and founder of Paradigms of Intelligence (PI). PI is an organization working on basic research in AI and related fields, especially the foundations of neural computing, active inference, sociality, evolution, and Artificial Life. In 2008, Blaise was awarded MIT’s TR35 prize. During his tenure at Google, he has innovated on-device machine learning for Android and Pixel, invented Federated Learning (an approach to decentralized model training that avoids sharing private data), and founded the Artists and Machine Intelligence program. A frequent public speaker, he has given multiple TED talks and keynoted NeurIPS. He has also authored numerous papers, essays, op-eds, and chapters, as well as two previous books, <em>Who Are We Now?</em> and <em>Ubi Sunt</em>. <em>What Is Life?</em> is Part I of the larger book <em>What Is Intelligence?</em>, forthcoming from Antikythera and MIT Press in 2025.</p><h1>Image credits</h1><p>Every reasonable attempt has been made to locate copyright owners and ensure accuracy of crediting. Errors or omissions will be corrected in future editions.</p><p><strong>Jacket</strong>: Figure 2 from Turing, A.M. “The Chemical Basis of Morphogenesis.” <em>Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences</em> 237, no. 641 (1952): 37–72. Slightly edited by James Goggin, 2024; <strong>Front and back covers:</strong> © Blaise Agüera y Arcas, 2024; <strong>Endpapers</strong>: Painting associated with the rockhole and soakage water site of Marrapinti by Yalti Napangati, one of the “Pintupi Nine” from Australia’s Western Desert; collection of Margaret Levi and Bob Kaplan.</p><p><strong>Foreword</strong> 7: © 2020 Raptis Rare Books.</p><p><strong>Abiogenesis</strong> 10: Claude Duret, 1605; 12–13: MARUM—Zentrum für Marine Umweltwissenschaften, Universität Bremen; 14: Ivan Petrovich Vtorov, 2012; 16: Aaron Cavosie, John Valley Extracted and re-arranged by Gretarsson, 2014; 18: © Blaise Agüera y Arcas, Johan Michalove, James Goggin, 2024; 21: Guy Viner / Alamy Stock Photo.</p><p><strong>Symbiogenesis</strong> 24: Robert M. Hunt, 1975; 27: John Gould, 1845; 29: Drawing by Eva Koch, reproduced with permission of Bjarne Grønnow.</p><p><strong>Reproductive functions</strong> 34: Unknown photographer, 1939; 36: von Neumann, J. High Speed Computing. Undated, 1940s. American Philosophical Society Library, Philadelphia, PA, USA. Herman Heine Goldstine Papers, Box 49; 37, 38–39: Unless otherwise indicated, this information has been authored by an employee or employees of the Los Alamos National Security, LLC (LANS), operator of the Los Alamos National Laboratory under Contract No. DE-AC52-06NA25396 with the U.S. Department of Energy. The U.S. Government has rights to use, reproduce, and distribute this information. The public may copy and use this information without charge, provided that this Notice and any statement of authorship are reproduced on all copies. Neither the Government nor LANS makes any warranty, express or implied, or assumes any liability or responsibility for the use of this information; 40: Turing, A. M. “The Chemical Basis of Morphogenesis.” <em>Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences</em> 237, no. 641 (1952): 37–72.</p><p><strong>Life as computation</strong> 46: © 2024 Center for Molecular Biology of RNA; 48–49: University of Manchester School of Computer Science; 50: Turing, A.M. “Intelligent Machinery: A Report.” National Physical Laboratory (1948); 51: Neumann, John von and Arthur W. Burks. <em>Theory Of Self-Reproducing Automata.</em> (1967); 53: Original automaton: Renato Nobili and Umberto Pesavento, screenshot by Ferkel, 2008; 55: Mordvintsev et al. “Growing Neural Cellular Automata.” Distill (2020).</p><p><strong>Artificial life</strong> 60–61, 63: © Blaise Agüera y Arcas, 2024; 65: © Alex Mordvintsev, 2024. See also Arcas, Blaise Agüera y, Jyrki Alakuijala, James Evans, Ben Laurie, Alexander Mordvintsev, Eyvind Niklasson, E. Randazzo and Luca Versari. “Computational Life: How Well-formed, Self-replicating Programs Emerge from Simple Interaction.” <em>ArXiv</em> abs/2406.19108 (2024).</p><p><strong>Thermodynamics</strong> 72: SuwanPhoto / iStock; 76–77: Black, Newton Henry, and Harvey N. Davis. 1913. <em>Practical Physics for Secondary Schools; Fundamental Principles and Applications to Daily Life.</em> New York: The Macmillan Company.</p><p><strong>Complexification</strong> 92–93: © Blaise Agüera y Arcas.</p><p><strong>Virality</strong> 104: Serra, F. (2012). <em>Informational, ecological, and system approaches for complete genome analysis</em> (Doctoral dissertation, Universitat de València). Design by James Goggin; 106: Smithsonian Institution/Science Service; Restored by Adam Cuerden, 1947; 111: Ivancevic, A.M., Kortschak, R.D., Bertozzi, T. <em>et al</em>. Horizontal transfer of BovB and L1 retrotransposons in eukaryotes. <em>Genome Biol</em> 19, 85 (2018); Ivica Letunic, Peer Bork, Interactive Tree of Life (iTOL) v6: recent updates to the phylogenetic tree display and annotation tool, Nucleic Acids Research, Volume 52, Issue W1, 5 July 2024, Pages W78–W82, <a href="https://doi.org/10.1093/nar/gkae268">https://doi.org/10.1093/nar/gkae268</a>; 113: Giovanni Battista Tebaldini, “Marine monster,” 1642, Medical Historical Library, Harvey Cushing/John Hay Whitney Medical Library, Yale University.</p><p><strong>Compression</strong> 118–119: Tveness, 2021 and Blaise Agüera y Arcas and Johan Michalove, 2024; 122: West, Geoffrey B., James H. Brown, and Brian J. Enquist. “A General Model for the Origin of Allometric Scaling Laws in Biology.” <em>Science</em> 276, no. 5309 (1997); 124–25: Mandelbrot, Benoît. “How Long Is the Coast of Britain? Statistical Self-Similarity and Fractional Dimension.” <em>Science</em> 156, no. 3775 (1967): 636–38.</p><p><strong>Embodiment</strong> 134: Lydekker (ed.), <em>The Royal Natural History</em>, 1893–1896; 135: Turner, F.R. and Mahowald, A.P. (1979). “Scanning electron microscopy of Drosophila melanogaster embryogenesis. III. Formation of the head and caudal segments.” <em>Dev. Biol.</em> 68: 96-109; 137: 1896 skiagraph of a <em>N. pompilius</em> by James Green &amp; James H. Gardiner, from <em>Proceedings of the Malacological Society of London</em>, Vol. II, Pl. XV, p. 178.</p><p><strong>Élan vital</strong> 146: Nasher, <a href="https://w.wiki/BGzW">https://w.wiki/BGzW</a> (2013).</p><h1>Note on the artwork</h1><p>The front and back endpapers of this book feature details of an artwork by Yalti Napangati, born around 1970 in Australia’s Great Sandy Desert. She is one of the “Pintupi Nine,” a traditional family who remained unaware of European colonization until 1984, when they made contact with relatives near Kiwirkurra. This painting depicts designs associated with the rockhole and soakage water site of Marrapinti, west of Kiwirrkurra. During ancestral times a large group of women gathered at this site during their travels toward the east. While at the site the women made nose bones, also known as marrapinti, which are worn through a hole made in the nasal septum. These nose bones were originally used by both men and women but are now only inserted by the older generation on ceremonial occasions. Upon completion of the ceremonies at Marrapinti the women continued their travels east to Ngaminya and then onto Wilkinkarra (Lake Mackay). The shapes in the painting represent geographical features of the landscape and bush foods the women collected as they traveled.</p><h1>Note on the type</h1><p>This book, both print and web editions, is typeset in Exposure, a variable typeface designed between 2019 and 2022 by Federico Parra Barrios at the Atelier National de Recherche Typographique in Nancy, France. Variable fonts are an OpenType technology enabling parameters like weight, slant, and width to vary continuously. Instead of traditional type weight, Exposure uses the new technology to simulate an obsolete one, producing the eroded or blown-out effects of under- or over-exposure in phototypesetting.</p><h1>Bibliography</h1><p><a href="http://paperpile.com/b/iJBGNj/6Ou0">Adami, Chris, and C. Titus Brown. 1994. “Evolutionary Learning in the 2D Artificial Life System ‘Avida.’” <em>arXiv [adap-Org]</em>. arXiv.</a> <a href="https://arxiv.org/pdf/adap-org/9405003">https://arxiv.org/pdf/adap-org/9405003</a><a href="http://paperpile.com/b/iJBGNj/6Ou0">.</a><br><a href="http://paperpile.com/b/iJBGNj/I1PA">Agüera y Arcas, Blaise. 2023. <em>Who Are We Now?</em> Los Angeles: Hat &amp; Beard, LLC.</a><br><a href="http://paperpile.com/b/iJBGNj/2mU4q">Agüera y Arcas, Blaise, Jyrki Alakuijala, James Evans, Ben Laurie, Alexander Mordvintsev, Eyvind Niklasson, Ettore Randazzo, and Luca Versari. 2024. “Computational Life: How Well-Formed, Self-Replicating Programs Emerge from Simple Interaction.” <em>arXiv [cs.NE]</em>. arXiv.</a> <a href="http://arxiv.org/abs/2406.19108">http://arxiv.org/abs/2406.19108</a><a href="http://paperpile.com/b/iJBGNj/2mU4q">.</a><br><a href="http://paperpile.com/b/iJBGNj/sdOr">Bagrov, Andrey A., Ilia A. Iakovlev, Askar A. Iliasov, Mikhail I. Katsnelson, and Vladimir V. Mazurenko. 2020. “Multiscale Structural Complexity of Natural Patterns.” <em>Proceedings of the National Academy of Sciences of the United States of America</em> 117 (48): 30241–51.</a><br><a href="http://paperpile.com/b/iJBGNj/AvEV">Bakoulis, Stylianos, Robert Krautz, Nicolas Alcaraz, Marco Salvatore, and Robin Andersson. 2022. “Endogenous Retroviruses Co-Opted as Divergently Transcribed Regulatory Elements Shape the Regulatory Landscape of Embryonic Stem Cells.” <em>Nucleic Acids Research</em> 50 (4): 2111–27.</a><br><a href="http://paperpile.com/b/iJBGNj/zwxh">Baltimore, David. 1970. “Viral RNA-Dependent DNA Polymerase: RNA-Dependent DNA Polymerase in Virions of RNA Tumour Viruses.” <em>Nature</em> 226 (5252): 1209–11.</a><br><a href="http://paperpile.com/b/iJBGNj/cKjJ">Barricelli, Nils Aall. 1957. “Symbiogenetic Evolution Processes Realized by Artificial Methods.” <em>Methodos</em> 9 (35–36): 143–82.</a><br><a href="http://paperpile.com/b/iJBGNj/jZ9KK">Bennett, Jane. 2010. <em>Vibrant Matter: A Political Ecology of Things</em>. Durham, NC and London: Duke University Press.</a><br><a href="http://paperpile.com/b/iJBGNj/tKw5R">Buchanan, Bon B., and Daniel I. Arnon. 1990. “A Reverse Krebs Cycle in Photosynthesis: Consensus at Last.” <em>Photosynthesis Research</em> 24 (1): 47–53.</a><br><a href="http://paperpile.com/b/iJBGNj/SRYzg">Carroll, Sean B., Jennifer K. Grenier, and Scott D. Weatherbee. 2013. <em>From DNA to Diversity: Molecular Genetics and the Evolution of Animal Design</em>. EPUB. 2nd ed. Hoboken, NJ: Wiley-Blackwell.</a><br><a href="http://paperpile.com/b/iJBGNj/Ph38o">Christley, Scott, Yiming Lu, Chen Li, and Xiaohui Xie. 2009. “Human Genomes as Email Attachments.” <em>Bioinformatics</em> 25 (2): 274–75.</a><br><a href="http://paperpile.com/b/iJBGNj/lnm7">Chuong, Edward B. 2018. “The Placenta Goes Viral: Retroviruses Control Gene Expression in Pregnancy.” <em>PLoS Biology</em> 16 (10): e3000028.</a><br><a href="http://paperpile.com/b/iJBGNj/kD8C">Crosby, Alfred W. 2003. <em>The Columbian Exchange: Biological and Cultural Consequences of 1492, 30th Anniversary Edition</em>. New York: Praeger.</a> <a href="https://books.google.com/books?hl=en&amp;lr=&amp;id=SXvCEAAAQBAJ&amp;oi=fnd&amp;pg=PT15&amp;dq=The+Columbian+Exchange:+Biological+and+Cultural+Consequences+of+1492&amp;ots=tQcdcNH-ru&amp;sig=-tY3njlfbvWNcvjeKuhBCvBRnGc">https://books.google.com/books?hl=en&amp;lr=&amp;id=SXvCEAAAQBAJ&amp;oi=fnd&amp;pg=PT15&amp;dq=The+Columbian+Exchange:+Biological+and+Cultural+Consequences+of+1492&amp;ots=tQcdcNH-ru&amp;sig=-tY3njlfbvWNcvjeKuhBCvBRnGc</a><a href="http://paperpile.com/b/iJBGNj/kD8C">.</a><br><a href="http://paperpile.com/b/iJBGNj/y5S44">Dawkins, Richard. 1986. <em>The Blind Watchmaker</em>. New York: W.W. Norton.</a><br><a href="http://paperpile.com/b/iJBGNj/2F9YB">De Morgan, Augustus, and Sophia Elizabeth De Morgan. 1872. <em>A Budget of Paradoxes</em>. London: Longmans, Green.</a><br><a href="http://paperpile.com/b/iJBGNj/nCFk">Evans, Michael C., Bob B. Buchanan, and Daniel I. Arnon. 1966. “A New Ferredoxin-Dependent Carbon Reduction Cycle in a Photosynthetic Bacterium.” <em>Proceedings of the National Academy of Sciences of the United States of America</em> 55 (4): 928–34.</a><br><a href="http://paperpile.com/b/iJBGNj/DS1xJ">Feschotte, Cédric, and Clément Gilbert. 2012. “Endogenous Viruses: Insights into Viral Evolution and Impact on Host Biology.” <em>Nature Reviews. Genetics</em> 13 (4): 283–96.</a><br><a href="http://paperpile.com/b/iJBGNj/KJwB">Fontana, Walter. 1990. “Algorithmic Chemistry,” no. LA-UR-90-1959 (June).</a> <a href="https://www.santafe.edu/research/results/working-papers/algorithmic-chemistry-a-model-for-functional-self-">https://www.santafe.edu/research/results/working-papers/algorithmic-chemistry-a-model-for-functional-self-</a><a href="http://paperpile.com/b/iJBGNj/KJwB">.</a><br><a href="http://paperpile.com/b/iJBGNj/qISP">Harper, Kristin N., Paolo S. Ocampo, Bret M. Steiner, Robert W. George, Michael S. Silverman, Shelly Bolotin, Allan Pillay, Nigel J. Saunders, and George J. Armelagos. 2008. “On the Origin of the Treponematoses: A Phylogenetic Approach.” <em>PLoS Neglected Tropical Diseases</em> 2 (1): e148.</a><br><a href="http://paperpile.com/b/iJBGNj/9X3am">Horita, Nobuyuki, and Takeshi Fukumoto. 2023. “Global Case Fatality Rate from COVID-19 Has Decreased by 96.8% during 2.5 Years of the Pandemic.” <em>Journal of Medical Virology</em> 95 (1): e28231.</a><br><a href="http://paperpile.com/b/iJBGNj/MqQWR">Kauffman, Stuart A. 1971. “Cellular Homeostasis, Epigenesis and Replication in Randomly Aggregated Macromolecular Systems.” <em>Journal of Cybernetics</em> 1 (1): 71–96.</a><br><a href="http://paperpile.com/b/iJBGNj/l1qj">Kimmerer, Robin. 2013. <em>Braiding Sweetgrass: Indigenous Wisdom, Scientific Knowledge and the Teachings of Plants</em>. Minneapolis, MN: Milkweed Editions.</a><br><a href="http://paperpile.com/b/iJBGNj/PD5o">Kleene, Stephen Cole. 1938. “On Notation for Ordinal Numbers.” <em>Journal of Symbolic Logic</em> 3 (4): 150–55.</a><br><a href="http://paperpile.com/b/iJBGNj/exIX">Konstantinidis, Konstantinos T., Alban Ramette, and James M. Tiedje. 2006. “The Bacterial Species Definition in the Genomic Era.” <em>Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences</em> 361 (1475): 1929–40.</a><br><a href="http://paperpile.com/b/iJBGNj/z0z75">Krebs, Hans Adolf, and William Arthur Johnson. 1937. “The Role of Citric Acid in Intermediate Metabolism in Animal Tissues.” <em>Enzymologia</em> 4 (1): 148–56.</a><br><a href="http://paperpile.com/b/iJBGNj/VTm8">Lander, Eric S., L. M. Linton, B. Birren, C. Nusbaum, M. C. Zody, J. Baldwin, K. Devon, et al. 2001. “Initial Sequencing and Analysis of the Human Genome.” <em>Nature</em> 409 (6822): 860–921.</a><br><a href="http://paperpile.com/b/iJBGNj/SRNH">Lanier, Kathryn A., Anton S. Petrov, and Loren Dean Williams. 2017. “The Central Symbiosis of Molecular Biology: Molecules in Mutualism.” <em>Journal of Molecular Evolution</em> 85 (1-2): 8–13.</a><br><a href="http://paperpile.com/b/iJBGNj/Zfmef">Mandelbrot, Benoît. 1967. “How Long Is the Coast of Britain? Statistical Self-Similarity and Fractional Dimension.” <em>Science</em> 156 (3775): 636–38.</a><br><a href="http://paperpile.com/b/iJBGNj/fCgz">———. 1989. “Multifractal Measures, Especially for the Geophysicist.” In <em>Fractals in Geophysics</em>, 5–42. Basel: Birkhäuser Basel.</a><br><a href="http://paperpile.com/b/iJBGNj/2aBSk">McClintock, Barbara. 1950. “The Origin and Behavior of Mutable Loci in Maize.” <em>Proceedings of the National Academy of Sciences</em> 36 (6): 344–55.</a><br><a href="http://paperpile.com/b/iJBGNj/Lups">Michod, Richard E. 2000. <em>Darwinian Dynamics: Evolutionary Transitions in Fitness and Individuality</em>. Princeton, NJ: Princeton University Press.</a><br><a href="http://paperpile.com/b/iJBGNj/42tF">Mordvintsev, Alexander, Ettore Randazzo, Eyvind Niklasson, and Michael Levin. 2020. “Growing Neural Cellular Automata.” <em>Distill</em> 5 (2): e23.</a><br><a href="http://paperpile.com/b/iJBGNj/EmaD">Murray, Connor S., Yingnan Gao, and Martin Wu. 2021. “Re-Evaluating the Evidence for a Universal Genetic Boundary among Microbial Species.” <em>Nature Communications</em> 12 (1): 4059.</a><br><a href="http://paperpile.com/b/iJBGNj/Eybne">Nasir, Arshan, and Gustavo Caetano-Anollés. 2015. “A Phylogenomic Data-Driven Exploration of Viral Origins and Evolution.” <em>Science Advances</em> 1 (8): e1500527.</a><br><a href="http://paperpile.com/b/iJBGNj/8oAok">Naville, Magali, Ian A. Warren, Zofia Haftek-Terreau, Domitille S. Chalopin, Frédéric G. Brunet, Perrine Levin, Delphine Galiana, and Jean Nicholas Volff. 2016. “Not so Bad after All: Retroviruses and Long Terminal Repeat Retrotransposons as a Source of New Genes in Vertebrates.” <em>Clinical Microbiology and Infection: The Official Publication of the European Society of Clinical Microbiology and Infectious Diseases</em> 22 (4): 312–23.</a><br><a href="http://paperpile.com/b/iJBGNj/duT1R">Neumann, John von. 1945. “First Draft of a Report on the EDVAC.” University of Pennsylvania. https://doi.org/</a><a href="http://dx.doi.org/10.1109/85.238389">10.1109/85.238389</a><a href="http://paperpile.com/b/iJBGNj/duT1R">.</a><br><a href="http://paperpile.com/b/iJBGNj/hRXHY">Neumann, John von, and Arthur W. Burks. 1966. <em>Theory of Self-Reproducing Automata</em>. Urbana and London: University of Illinois Press.</a><br><a href="http://paperpile.com/b/iJBGNj/H4xh">Pastuzyn, Elissa D., Cameron E. Day, Rachel B. Kearns, Madeleine Kyrke-Smith, Andrew V. Taibi, John McCormick, Nathan Yoder, et al. 2018. “The Neuronal Gene Arc Encodes a Repurposed Retrotransposon Gag Protein That Mediates Intercellular RNA Transfer.” <em>Cell</em> 173 (1): 275.</a><br><a href="http://paperpile.com/b/iJBGNj/oW314">Peretó, Juli, Jeffrey L. Bada, and Antonio Lazcano. 2009. “Charles Darwin and the Origin of Life.” <em>Origins of Life and Evolution of the Biosphere: The Journal of the International Society for the Study of the Origin of Life</em> 39 (5): 395–406.</a><br><a href="http://paperpile.com/b/iJBGNj/UlMre">Pesavento, Umberto. 1995. “An Implementation of von Neumann’s Self-Reproducing Machine.” <em>Artificial Life</em> 2 (4): 337–54.</a><br><a href="http://paperpile.com/b/iJBGNj/AjJl">Prigogine, Ilya, and Isabelle Stengers. 1984. <em>Order out of Chaos: Man’s New Dialogue with Nature</em>. London: William Heinemann.</a><br><a href="http://paperpile.com/b/iJBGNj/iXQT3">Pross, Addy. 2012. <em>What Is Life?: How Chemistry Becomes Biology</em>. Oxford, UK: Oxford University Press.</a><br><a href="http://paperpile.com/b/iJBGNj/RdfDo">Raup, David M., and Stephen Jay Gould. 1974. “Stochastic Simulation and Evolution of Morphology-Towards a Nomothetic Paleontology.” <em>Systematic Biology</em> 23 (3): 305–22.</a><br><a href="http://paperpile.com/b/iJBGNj/5uHZ">Ray, Thomas S. 1991. “An Approach to the Synthesis of Life.” In <em>Artificial Life II, Santa Fe Institute Studies in the Sciences of Complexity, Vol. XI</em>, edited by C. Langton, C. Taylor, J. D. Farmer, and S. Rasmussen, 371–408. Redwood City, CA: Addison-Wesley.</a><br><a href="http://paperpile.com/b/iJBGNj/9udzk">Reichenbach, Hans. 1956. <em>The Direction of Time</em>. Edited by Maria Reichenbach. Berkeley, CA: University of California Press.</a><br><a href="http://paperpile.com/b/iJBGNj/GdGZv">Robertson, Michael P., and Gerald F. Joyce. 2012. “The Origins of the RNA World.” <em>Cold Spring Harbor Perspectives in Biology</em> 4 (5). https://doi.org/</a><a href="http://dx.doi.org/10.1101/cshperspect.a003608">10.1101/cshperspect.a003608</a><a href="http://paperpile.com/b/iJBGNj/GdGZv">.</a><br><a href="http://paperpile.com/b/iJBGNj/N9LOm">Rovelli, Carlo. 2018. <em>The Order of Time</em>. Translated by Erica Segre and Simon Carnell. New York: Riverhead Books.</a><br><a href="http://paperpile.com/b/iJBGNj/1vX88">Russell, Michael J., and William Martin. 2004. “The Rocky Roots of the Acetyl-CoA Pathway.” <em>Trends in Biochemical Sciences</em> 29 (7): 358–63.</a><br><a href="http://paperpile.com/b/iJBGNj/hMUQ">Russ, Eric, and Sergey Iordanskiy. 2023. “Endogenous Retroviruses as Modulators of Innate Immunity.” <em>Pathogens</em> 12 (2). https://doi.org/</a><a href="http://dx.doi.org/10.3390/pathogens12020162">10.3390/pathogens12020162</a><a href="http://paperpile.com/b/iJBGNj/hMUQ">.</a><br><a href="http://paperpile.com/b/iJBGNj/cTbw9">Ryan, Frank. 2009. <em>Virolution</em>. London: Collins.</a><br><a href="http://paperpile.com/b/iJBGNj/ijKop">Sagan, Lynn. 1967. “On the Origin of Mitosing Cells.” <em>Journal of Theoretical Biology</em> 14 (3): 255–74.</a><br><a href="http://paperpile.com/b/iJBGNj/asO1A">Schrödinger, Erwin. 1944. <em>What Is Life? The Physical Aspect of the Living Cell</em>. Cambridge University Press.</a><br><a href="http://paperpile.com/b/iJBGNj/YRi9y">Shapiro, Robert. 2006. “Small Molecule Interactions Were Central to the Origin of Life.” <em>The Quarterly Review of Biology</em> 81 (2): 105–25.</a><br><a href="http://paperpile.com/b/iJBGNj/DLa7P">Sharp, Paul M., and Beatrice H. Hahn. 2011. “Origins of HIV and the AIDS Pandemic.” <em>Cold Spring Harbor Perspectives in Medicine</em> 1 (1): a006841.</a><br><a href="http://paperpile.com/b/iJBGNj/NsDjj">She, Jianqi, Minghao Du, Zhanzhan Xu, Yueqi Jin, Yu Li, Daoning Zhang, Changyu Tao, Jian Chen, Jiadong Wang, and Ence Yang. 2022. “The Landscape of hervRNAs Transcribed from Human Endogenous Retroviruses across Human Body Sites.” <em>Genome Biology</em> 23 (1): 231.</a><br><a href="http://paperpile.com/b/iJBGNj/SWlI">Smil, Vaclav. 2008. <em>Energy in Nature and Society: General Energetics of Complex Systems</em>. London and Cambridge, MA: MIT Press.</a><br><a href="http://paperpile.com/b/iJBGNj/yGSxJ">Szathmáry, Eörs, and John Maynard Smith. 1995. “The Major Evolutionary Transitions.” <em>Nature</em> 374 (6519): 227–32.</a><br><a href="http://paperpile.com/b/iJBGNj/BTTV">Taleb, Nassim Nicholas. 2014. <em>Antifragile: Things That Gain from Disorder</em>. New York: Random House.</a><br><a href="http://paperpile.com/b/iJBGNj/9fOiA">Tarlinton, Rachael E., Joanne Meers, and Paul R. Young. 2006. “Retroviral Invasion of the Koala Genome.” <em>Nature</em> 442 (7098): 79–81.</a><br><a href="http://paperpile.com/b/iJBGNj/55Kf">Thomas, Dylan. 1934. <em>18 Poems by Dylan Thomas</em>. London: Fortune Press.</a><br><a href="http://paperpile.com/b/iJBGNj/JvJv">Thomson, William. 1857. “On a Universal Tendency in Nature to the Dissipation of Mechanical Energy.” <em>Proceedings of the Royal Society of Edinburgh</em> 3: 139–42.</a><br><a href="http://paperpile.com/b/iJBGNj/bcOGJ">———. 1871. “Inaugural Address before the British Association at Edinburgh, August 2d.” <em>American Journal of Science, and Arts</em> s3-2 (October): 269–94.</a><br><a href="http://paperpile.com/b/iJBGNj/8saZ8">Turing, Alan Mathison. 1937. “On Computable Numbers, with an Application to the Entscheidungsproblem.” <em>Proceedings of the London Mathematical Society. Third Series</em> s2-42 (1): 230–65.</a><br><a href="http://paperpile.com/b/iJBGNj/NmrxS">———. 1948. “Intelligent Machinery: A Report.” <em>London: National Physical Laboratory</em>, 27.</a><br><a href="http://paperpile.com/b/iJBGNj/Jjk4i">———. 1950. “Computing Machinery and Intelligence.” <em>Mind; a Quarterly Review of Psychology and Philosophy</em> 59 (236): 433–60.</a><br><a href="http://paperpile.com/b/iJBGNj/QeZ1Q">———. 1952. “The Chemical Basis of Morphogenesis.” <em>Bulletin of Mathematical Biology</em> 52 (1): 153–97.</a><br><a href="http://paperpile.com/b/iJBGNj/O6xpg">———. (1951) 2000. “Alan Turing’s Manual for the Ferranti Mk. I (transcribed by Robert S. Thau).” infoamerica.org. February 13, 2000.</a> <a href="https://www.infoamerica.org/documentos_pdf/turing02.pdf">https://www.infoamerica.org/documentos_pdf/turing02.pdf</a><a href="http://paperpile.com/b/iJBGNj/O6xpg">.</a><br><a href="http://paperpile.com/b/iJBGNj/9hvK">Walker, Sara. 2023. “AI Is Life.” <em>Noema Magazine</em>, April.</a> <a href="https://www.noemamag.com/ai-is-life/">https://www.noemamag.com/ai-is-life/</a><a href="http://paperpile.com/b/iJBGNj/9hvK">.</a><br><a href="http://paperpile.com/b/iJBGNj/L7DKX">Watson, James D., and Francis H. Crick. 1953. “Molecular Structure of Nucleic Acids; a Structure for Deoxyribose Nucleic Acid.” <em>Nature</em> 171 (4356): 737–38.</a><br><a href="http://paperpile.com/b/iJBGNj/BAqLl">West, Geoffrey B. 2017. <em>Scale: The Universal Laws of Life, Growth, and Death in Organisms, Cities, and Companies</em>. New York: Penguin.</a><br><a href="http://paperpile.com/b/iJBGNj/pguCN">West, Geoffrey B., James H. Brown, and Brian J. Enquist. 1997. “A General Model for the Origin of Allometric Scaling Laws in Biology.” <em>Science</em> 276 (5309): 122–26.</a><br><a href="http://paperpile.com/b/iJBGNj/d9Qm1">Woese, Carl R. 2002. “On the Evolution of Cells.” <em>Proceedings of the National Academy of Sciences</em> 99 (13): 8742–47.</a><br><a href="http://paperpile.com/b/iJBGNj/Gz3o">Wolpert, David H., and William Macready. 2007. “Using Self‐dissimilarity to Quantify Complexity.” <em>Complexity</em> 12 (3): 77–85.</a><br><a href="http://paperpile.com/b/iJBGNj/4vXpF">Yinusa, Ayoola R., and Chrystopher L. Nehaniv. 2011. “Study of Inheritable Mutations in von Neumann Self-Reproducing Automata Using the GOLLY Simulator.” In <em>2011 IEEE Symposium on Artificial Life (ALIFE)</em>, 211–17.</a><br><a href="http://paperpile.com/b/iJBGNj/eZbeB">Yong, Ed. 2013. “How a Quarter of the Cow Genome Came from Snakes.” <em>National Geographic</em>, January.</a> <a href="https://www.nationalgeographic.com/science/article/how-a-quarter-of-the-cow-genome-came-from-snakes">https://www.nationalgeographic.com/science/article/how-a-quarter-of-the-cow-genome-came-from-snakes</a><a href="http://paperpile.com/b/iJBGNj/eZbeB">.</a></p><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p><a href="https://paperpile.com/c/iJBGNj/oW314">Peretó, Bada, and Lazcano 2009</a>.</p></li><li id="fn2" class="footnote-item"><p>Remember, from chemistry class, that since hydrogen (H) consists of a single proton bound to a single electron, a positively charged hydrogen ion with its electron stripped off (H+) is just a proton. When proton concentration varies over space, the ensuing flow of ions generates an electric current.</p></li><li id="fn3" class="footnote-item"><p><a href="https://paperpile.com/c/iJBGNj/d9Qm1">Woese 2002</a>. In this book, I’ll use the terms <em>symbiosis</em> and <em>symbiogenesis</em> in broader ways than most biologists do, to include cooperation and eventual interdependence among entities of all kinds—in the spirit of molecular biologists who have framed the origins of life as symbiosis among “molecules in mutualism,” per <a href="https://paperpile.com/c/iJBGNj/SRNH">Lanier, Petrov, and Williams 2017</a>.</p></li><li id="fn4" class="footnote-item"><p><a href="https://paperpile.com/c/iJBGNj/exIX+EmaD">Konstantinidis, Ramette, and Tiedje 2006; Murray, Gao, and Wu 2021</a>.</p></li><li id="fn5" class="footnote-item"><p><a href="https://paperpile.com/c/iJBGNj/8saZ8">Turing 1937</a>.</p></li><li id="fn6" class="footnote-item"><p>In a more abstract form, mathematician Stephen Kleene had proven this result years earlier, a result known today as Kleene’s Second Recursion Theorem; <a href="https://paperpile.com/c/iJBGNj/PD5o">Kleene 1938</a>.</p></li><li id="fn7" class="footnote-item"><p>I’m using the term “complex” here in a colloquial sense; according to at least one technical definition (Kolmogorov complexity), if the instructions within the “simple” entity fully describe how to make the “more complex” one, they are actually of equal complexity.</p></li><li id="fn8" class="footnote-item"><p><a href="https://paperpile.com/c/iJBGNj/L7DKX">Watson and Crick 1953</a>.</p></li><li id="fn9" class="footnote-item"><p><a href="https://paperpile.com/c/iJBGNj/2mU4q">Agüera y Arcas et al. 2024</a>. This work draws inspiration from classic work in ALife, especially <a href="https://paperpile.com/c/iJBGNj/cKjJ+KJwB+5uHZ+6Ou0">Barricelli 1957; Fontana 1990; Ray 1991; Adami and Brown 1994</a>.</p></li><li id="fn10" class="footnote-item"><p>Decrementing 0 wraps around to 255, the largest possible value for a byte, and incrementing 255 wraps around to 0.</p></li><li id="fn11" class="footnote-item"><p>You might have noticed that the original Brainfuck had 8 instructions, including “.” for “print” and “,” for “input.” Bff uses only “,” because instead of reading and writing to an external terminal or console, the tape reads and writes to <em>itself</em>. Thus only a single instruction is needed for copying a byte from one location to another. In our first paper describing bff, we included instructions “{” and “}” for moving the console pointer, but a stripped-down alternative, used here, simply initializes the data and console pointers with the first two bytes on the tape.</p></li><li id="fn12" class="footnote-item"><p><a href="https://paperpile.com/c/iJBGNj/asO1A">Schrödinger 1944</a>.</p></li><li id="fn13" class="footnote-item"><p><a href="https://paperpile.com/c/iJBGNj/9udzk+N9LOm">H. Reichenbach 1956; Rovelli 2018</a>.</p></li><li id="fn14" class="footnote-item"><p>The “very nearly” qualifier arises from the deep mathematical structure of relativistic quantum mechanics. A number of near-symmetries in physics, such as between positive or negative charge, left or right-handedness, and time reversal, are not quite exact in quantum field theory, though according to the CPT theorem—the letters stand for charge, parity, time—reversing all three at once <em>does</em> yield an exact symmetry.</p></li><li id="fn15" class="footnote-item"><p>The development of clocks and other complex machines in the Middle Ages set the scene, per <a href="https://paperpile.com/c/iJBGNj/AjJl">Prigogine and Stengers 1984</a>: “The clock world is a metaphor suggestive of God the Watchmaker, the rational master of a robot-like nature.” Newtonian dynamics reinforced the idea that the universe’s dynamics were deterministic and knowable, hence “robot-like.”</p></li><li id="fn16" class="footnote-item"><p>More precisely, these are repulsive interactions between the electron orbitals of the molecules.</p></li><li id="fn17" class="footnote-item"><p><a href="https://paperpile.com/c/iJBGNj/JvJv">Thomson 1857</a>.</p></li><li id="fn18" class="footnote-item"><p><a href="https://paperpile.com/c/iJBGNj/iXQT3">Pross 2012</a>.</p></li><li id="fn19" class="footnote-item"><p><a href="https://paperpile.com/c/iJBGNj/BTTV">Taleb 2014</a>.</p></li><li id="fn20" class="footnote-item"><p>In the language of dynamical systems theory, this asserts that thermodynamic stability is a fixed point, while DKS is a limit cycle.</p></li><li id="fn21" class="footnote-item"><p><a href="https://paperpile.com/c/iJBGNj/y5S44">Dawkins 1986</a>.</p></li><li id="fn22" class="footnote-item"><p><a href="https://paperpile.com/c/iJBGNj/4vXpF">Yinusa and Nehaniv 2011</a>.</p></li><li id="fn23" class="footnote-item"><p>This is not an absolute rule, since new parts can also evolve within an existing whole.</p></li><li id="fn24" class="footnote-item"><p><a href="https://paperpile.com/c/iJBGNj/zwxh">Baltimore 1970</a>.</p></li><li id="fn25" class="footnote-item"><p><a href="https://paperpile.com/c/iJBGNj/9fOiA">Tarlinton, Meers, and Young 2006</a>.</p></li><li id="fn26" class="footnote-item"><p><a href="https://paperpile.com/c/iJBGNj/NsDjj">She et al. 2022</a>.</p></li><li id="fn27" class="footnote-item"><p><a href="https://paperpile.com/c/iJBGNj/9X3am">Horita and Fukumoto 2023</a>.</p></li><li id="fn28" class="footnote-item"><p><a href="https://paperpile.com/c/iJBGNj/lnm7+AvEV+hMUQ">Chuong 2018; Bakoulis et al. 2022; Russ and Iordanskiy 2023</a>. Knocking out the “Arc” retrotransposon, likely of viral origin, renders lab mice unable to form new long-term memories, per <a href="https://paperpile.com/c/iJBGNj/H4xh">Pastuzyn et al. 2018</a>.</p></li><li id="fn29" class="footnote-item"><p><a href="https://paperpile.com/c/iJBGNj/cTbw9">Ryan 2009</a>.</p></li><li id="fn30" class="footnote-item"><p><a href="https://paperpile.com/c/iJBGNj/DLa7P">Sharp and Hahn 2011</a>.</p></li><li id="fn31" class="footnote-item"><p><a href="https://paperpile.com/c/iJBGNj/kD8C+qISP">Crosby 2003; Harper et al. 2008</a>.</p></li><li id="fn32" class="footnote-item"><p><a href="https://paperpile.com/c/iJBGNj/DS1xJ+8oAok">Feschotte and Gilbert 2012; Naville et al. 2016</a>.</p></li><li id="fn33" class="footnote-item"><p><a href="https://paperpile.com/c/iJBGNj/Eybne">Nasir and Caetano-Anollés 2015</a>.</p></li><li id="fn34" class="footnote-item"><p>Though earlier, we similarly considered individual bff instructions as minimal or “atomic” replicating entities.</p></li><li id="fn35" class="footnote-item"><p>Incidentally, De Morgan was also computing pioneer Ada Lovelace’s math tutor. Charles Babbage conceived the Analytical Engine, a steampunk computer that, had it been built, would have predated the ENIAC by a century; Lovelace wrote presciently about the power of general-purpose computing—and arguably wrote the first computer program—in 1843.</p></li><li id="fn36" class="footnote-item"><p><a href="https://paperpile.com/c/iJBGNj/2F9YB">De Morgan and De Morgan 1872</a>.</p></li><li id="fn37" class="footnote-item"><p><a href="https://paperpile.com/c/iJBGNj/Gz3o+sdOr">Wolpert and Macready 2007; Bagrov et al. 2020</a>.</p></li><li id="fn38" class="footnote-item"><p>If I were a fancier writer and used fewer stock phrases, the book wouldn’t ZIP so efficiently. Using the same compression algorithm, James Joyce’s <em>Ulysses</em> can only be squeezed down to 40% of its raw size!</p></li><li id="fn39" class="footnote-item"><p>In math: for a random string of symbols that can assume <em>K</em> values, a string of length <em>L</em> would occur with frequency <em>f</em>=<em>K</em>−<em>L</em>, while with replication occurring at all scales, string frequency scales like <em>f</em>~<em>L</em>−<em>b</em>.</p></li><li id="fn40" class="footnote-item"><p><a href="https://paperpile.com/c/iJBGNj/Ph38o">Christley et al. 2009</a>.</p></li><li id="fn41" class="footnote-item"><p><a href="https://paperpile.com/c/iJBGNj/SRYzg">Carroll, Grenier, and Weatherbee 2013</a>.</p></li><li id="fn42" class="footnote-item"><p><a href="https://paperpile.com/c/iJBGNj/9hvK">Walker 2023</a>.</p></li><li id="fn43" class="footnote-item"><p>Computer viruses are a notable exception.</p></li><li id="fn44" class="footnote-item"><p><a href="https://paperpile.com/c/iJBGNj/jZ9KK">Bennett 2010</a>.</p></li><li id="fn45" class="footnote-item"><p><a href="https://paperpile.com/c/iJBGNj/l1qj">Kimmerer 2013</a>.</p></li></ol></section><div class="indicators"><div class="fixed-indicator"></div><div class="figure-indicators"></div></div></section><div id="footnote-popup" class="footnote-text"></div></article></main></body></html>