<!doctype html><html lang="en"><head><meta charset="utf-8"><meta content="ie=edge" http-equiv="x-ua-compatible"><title>home — Who are we now?</title><meta name="title" content="Who Are We Now?"><meta name="description" content="From leading AI researcher Blaise Agüera y Arcas comes an exploration of how biology, ecology, sexuality, history, and culture have intertwined to create a dynamic “us” that can neither be called natural nor artificial."><meta name="viewport" content="width=device-width,initial-scale=1,minimum-scale=1"><link href="/assets/css/main.css" rel="stylesheet"><meta name="robots" content="noindex,nofollow"><meta name="theme-color" content="#ffffff"><link rel="icon" href="/assets/favicon/wawn_favicon.svg"><link rel="apple-touch-icon" sizes="180x180" href="/assets/favicon/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicon/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicon/favicon-16x16.png"><link rel="icon" href="/assets/favicon/wawn_favicon.svg" type="image/svg+xml"><meta name="msapplication-TileColor" content="#ffffff"><script src="https://d3js.org/d3.v7.min.js"></script><script src="/assets/js/bundle-script.js"></script></head><body id="home" class="home"><header><nav><div class="navlink"><div class="icon"><div class="icon_close"><svg width="17" height="17" viewBox="0 0 17 17" fill="none" xmlns="http://www.w3.org/2000/svg"><line x1="1.42893" y1="1.22183" x2="16.2782" y2="16.0711"/><line x1="15.9246" y1="1.57539" x2="1.07539" y2="16.4246"/></svg></div></div><div class="current-page"><a class="nav-home" href="/"><span class="nav-sitetitle">What is Intelligence?</span></a><div class="nav-title"><span class="marker"></span>home<svg width="11" height="10" viewBox="0 0 11 7" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M5.5 7L0.73686 0.25L10.2631 0.250001L5.5 7Z"/></svg></div></div></div><div class="info"><span class="open">●●●</span> <span class="close">✕</span></div><ul id="toc"></ul></nav></header><div id="summary-popup"></div><main><div class="home-cover"><div class="title"><h3>Blaise Agüera y Arcas</h3><h1>What is<br>Intelligence?</h1><h2>Lessons from AI about Evolution, Computation, and Consciousness</h2></div></div><article><section class="content"><div id="preface"><h1>Preface</h1><p>AI is probably the biggest story of our lifetimes. Its rapid development, starting in the early 2020s, has generated a mixed outpouring of excitement, anxiety, and denial.</p><p>Everyone wants to weigh in. Even authors writing about history, language, biology, sociology, economics, the arts, and psychology feel the need to add a chapter about AI to the end of their books. And why not? AI will surely affect all of these far-flung domains, and many more—though exactly <em>how</em>, nobody can say with any confidence.</p><p>This book is a bit different. It’s less about the future of AI than it is about what we have learned in the present. At least as of 2024, few mainstream authors claim that AI is “real” intelligence.[^1] I do. Gemini, Claude, and ChatGPT aren’t powered by the same machinery as the human brain, of course, but intelligence is “multiply realizable,” meaning that, just as a computer algorithm can run on any kind of computer, intelligence can “run” on many physical substrates. In fact, although our brains aren’t much like the kinds of digital computers we have today, I think the substrate for intelligence <em>is</em> computation, which implies that a sufficiently powerful general-purpose computer can, by definition, implement intelligence. All it takes is the right code.</p><p>I will argue that, thanks to recent conceptual breakthroughs in AI development, we now know, at least at a high level, what that code <em>does</em>. We understand the essence of an incredibly powerful trick, although we’re still in the early days of making it work. Our implementations are neither complete, nor reliable, nor efficient—a bit like where we were with general computing when the ENIAC first powered up, in 1945, or where we were with aviation when the Wright brothers made their first powered flight, in 1903.</p><p>It’s an old cliché in AI that airplanes and birds can both fly, but do so by different means.[^2] This truism has at times been used to motivate misguided approaches to AI. Still, the point stands. Birdflight is a biological marvel, which in some respects remains poorly understood, even today; and to engineer small drones, we still have much to learn from insects.[^3] However, we figured out the basic physics of flight—not <em>how</em> animals fly, but how it’s <em>possible</em> for them to—in the eighteenth century, with the discovery of Bernoulli’s Equation. Working airplanes took another century and a half to evolve.</p><p>Similarly, while there is still a great deal about the brain that we don’t understand, the fundamental principle behind intelligence—<em>prediction</em>—was first theorized by German polymath Hermann von Helmholtz in the 1860s.[^4] Many computational neuroscientists and AI researchers have elaborated on Helmholtz’s insight since then, and built limited models implementing aspects of the idea,[^5] but only recently has it become plausible to imagine that prediction really is the whole story. I will argue that, understood in full, the prediction principle may explain not only intelligence, but life itself.[^6]</p><p>Furthermore, it explains why recent large AI models really <em>are</em> intelligent; it’s not “anthropomorphic” to say so. This doesn’t mean that AI models are necessarily human-like, or lesser than us, or greater than us. In fact, understanding the curiously self-similar and self-referential nature of prediction will let us see that intelligence isn’t really a “thing.” It can’t exist in isolation, either in the three pounds of neural tissue in your head, or in the racks of computer chips running large models in datacenters. Intelligence is defined by networks, and by networks of networks. We can only understand what intelligence really is by changing how we think about it—by adopting a perspective that centers dynamic, symbiotic relationships rather than isolated minds.</p><p>This book takes on that project. Doing so requires weaving together insights from many different disciplines. As we go along, I’ll introduce concepts in probability, machine learning, physics, chemistry, biology, computer science, and other fields. When they’ve been most relevant to shaping our (sometimes mistaken) beliefs, I’ll also briefly review the intellectual histories of key ideas, from seventeenth century “mechanical philosophy” to debates about the origin of life, and from cybernetics to neuroscience.</p><p>You, dear reader, may be an expert in one or more of these fields, or in none. Few people are expert in all of them (I’m certainly not), so no specialized prior knowledge is assumed. On the other hand, even if you’re an AI researcher or neuroscientist with little patience for pop science, I hope you will find new and surprising ideas in this book. A general grasp of mathematical concepts like functions and variables will be helpful (with bonus points for knowing about vectors and matrices), but there will be no equations. (Well … <em>almost</em> none.) A general understanding of how computer programming works will be useful in a few places, but isn’t required. If you find understanding intelligence interesting enough to still be reading, rest assured: you are my audience.</p><p>The <strong>Introduction</strong> describes the recent emergence of “real” AI, sketching the hypothesis that prediction <em>is</em> intelligence, and pointing out some of the big questions that raises. The rest of the book consists of about a hundred bite-sized chapters that attempt to answer those questions, organized into the following ten parts:</p><ol><li><strong>Origins</strong> begins with “abiogenesis,” the emergence of life on Earth some four billion years ago. Darwin struggled to understand how life could have arisen. “Artificial life” experiments let us make more progress today, and suggest that life may be inevitable in a world capable of supporting computation (like ours). Understanding the deep role computation plays in our universe, and the way it links the seemingly disparate fields of physics, chemistry, and biology, both sheds new light on evolutionary theory and sets the stage for understanding the computational nature of intelligence.</li><li><strong>Survival</strong> considers the predictive intelligence hypothesis from the perspective of a tiny, simple organism capable of rudimentary computation: a bacterium. Being alive in the world is inherently social (even for bacteria), but this part imagines life as a one-player game, and considers what it takes to keep playing—which, since life is an infinite game, is the only prize there is.<br><strong>Interlude: The prehistory of computing</strong> offers a historical perspective on the origins and founding assumptions of “traditional” computer science, from its roots in Enlightenment thinking and the Industrial Revolution to the development of the first electronic computers at the close of the Second World War.</li><li><strong>Cybernetics</strong> traces an alternative history of computing, which has recently re-emerged as modern AI, back to <em>its</em> foundations in the mid-twentieth century, describing how Norbert Wiener’s biologically-inspired theory of feedback lets us understand the connections between the predictive intelligence hypothesis and the development of artificial neural nets.</li><li><strong>Learning</strong> connects more recent advances in machine learning with our growing understanding of computational neuroscience and the evolution of nervous systems.</li><li><strong>Other minds</strong> explores how, as multiplayer life becomes complex, the main job of a mind becomes modeling other minds. This leads to a mutual modeling arms race, resulting in the kind of “intelligence explosion” that has produced humanity.</li><li><strong>Many worlds</strong> describes the way both long-term planning and short-term unpredictability (otherwise known as “free will”) emerge as consequences of social modeling, especially when applied to ourselves.</li><li><strong>Ourselves</strong> both explains and deconstructs consciousness in light of the above, asking: are we really as coherent a “self” as we believe? Answering will involve combining conceptual insights, experimental findings, and a high-level overview of what we know about the brain’s functional organization.</li><li><strong>Transformer</strong> chronicles the development of large language models and their multimodal successors. Do these AI models understand concepts? Are they intelligent? Can they reason?</li><li><strong>Generality</strong> explains both similarities and differences between Transformers and brains, shedding light on how Transformers achieve their generality and where gaps remain in their functionality. It also poses the most fraught question: do AI models have subjective experiences? Finally,</li><li><strong>Evolutionary transition</strong> zooms out and looks ahead. The emergence of AI probably won’t bring either rapture or apocalypse, but it does resemble earlier major symbiotic transitions on Earth, including those that led to eukaryotes, multicellular life, and photosynthesis. As in these earlier (and momentous) transitions, mutual prediction will generate unprecedented new levels of complexity and diversity. It will also require us to revise our political and economic assumptions, and even to rethink human identity.</li></ol><p>The ideas in this book came together first gradually, over the course of decades as a software engineer and occasional computational neuroscientist, and then quickly, when my colleagues and I at Google found ourselves at the crest of AI’s “great wave” in the early 2020s.</p><p>Here’s my story, in brief. I’ve been obsessed with both brains and computers since childhood. In the late 1990s, as I was finishing a BA in Physics at Princeton, I began working with physicist and computational neuroscientist Bill Bialek on simulations to explore the relationship between what neurons actually do, which we have understood at a biophysical level since the 1950s, and what they compute.[^7] After I graduated, Bill asked if I would help set up the computers for a course he had been invited to co-direct that summer in Woods Hole, a small town on the elbow of Cape Cod. It was a wonderful opportunity to audit a course I wouldn’t otherwise have gotten into, and the experience proved life-changing.</p><p>The Marine Biological Laboratory in Woods Hole, founded in 1888, is at once ramshackle and illustrious. More than sixty Nobel Prize winners have been associated with it at one time or another. The summer courses are legendary, attracting visiting lecturers from all over the world. Old class photos from the course Bill had inherited, <em>Methods in Computational Neuroscience</em>, looked like a who’s who of the field twenty years later. They still do.</p><p>One of the postdocs in that 1998 cohort, Adrienne Fairhall, was, like Bill, a physicist who had decided to work on the brain. We’re now married, and a decade after we met at that course, <em>she</em> became its director! Our kids spent many idyllic summers in Woods Hole, hanging out with the families of the other visiting scientists, rowing around in a little dinghy on Eel Pond and poking gingerly at bioluminescent comb jellies and other small creatures they scooped up in plastic buckets. Busy at their workbenches, the older researchers did much the same. Over the years, many organisms collected from those waters have provided fundamental insights into neural computation, from squids (whose giant axons were ideal for figuring out the biophysics of the action potential or “spike”), to the distributed nerve nets of jellyfish and <em>Hydra</em>, to the simple visual system of the Atlantic horseshoe crab, <em>Limulus polyphemus</em>.</p><p>While Adrienne established herself as a computational neuroscientist in the 2000s, I founded a tech startup. The startup was acquired by Microsoft, where I worked between 2006 and 2013. One of my main areas of focus at the time was computer vision. Among other responsibilities, I led teams working on problems like reconstructing 3D scenes from images, tracking camera motion, and recognizing objects and text—all using hand-engineered or “Good Old Fashioned” AI (GOFAI). By the early 2010s, though, it was clear that the wind was shifting. Artificial Neural Nets (ANNs), which were much more explicitly brain-inspired than GOFAI algorithms, were taking off. The new approach was obviously the future.</p><p>So, at the end of 2013, I left Microsoft to join Google Research, the epicenter of this new convergence between AI and neuroscience. The following decade was a tremendously exciting time, during which I built many teams to work on a wide range of projects in AI. We did basic research in neural net-powered perception, media generation, AI bias and fairness, and privacy-preserving training algorithms. We also helped various product teams at Google build AI features and technologies, and hatched big dreams about what AI might ultimately make possible, beyond the envelope of any existing kind of product.</p><p>In late 2023, I founded a new research group at Google, Paradigms of Intelligence, to reimagine the foundations of AI. Our projects so far have included alternative, biologically inspired approaches to computation, new design ideas for efficient AI hardware, research into the social scaling of AI, and even artificial life.</p><p>I’ve been privileged to see and at times participate in the development of AI projects that were far enough ahead of the curve to seem like magic. Many of them caused me to rethink old assumptions, not only about AI, but also about the brain, intelligence, evolution, and the big philosophical questions that have dogged these topics for millennia. I began to write and give talks about some of these new insights, but synthesizing them into a coherent picture required more time and space than could fit into a lecture, essay, or paper.</p><p>This book is my first stab at bringing it all together. It’s an extended argument drawing on a wide range of work, from my own research group, from colleagues, and from much farther afield. In swinging for the fences, I’m sure to get some things wrong. I hope to keep revising and updating the material as AI advances at breakneck speed, and our understanding continues to improve. My hope and belief, though, is that the book’s core ideas trace a novel, enduring path through the complex territory of intelligence in all its forms.</p></div><div id="introduction"><h1>Introduction</h1><p>In the mid-2010s, my team at Google Research began working on the machine-learned models powering next-word prediction for Gboard, the smart keyboard for Android phones.[^8] We created these models to speed up text entry on the phone (which remains, at least for those of us over 40, far less efficient than typing on a real keyboard) by suggesting likely next words in a little strip above the virtual keys. Today, similar models power autocomplete features in many apps and editors.</p><p>Autocomplete is a modest application of the more general problem of “sequence prediction.” Given a sequence of symbols, which could be words or individual letters, a sequence prediction model guesses what symbol (word, or letter) comes next. The process can be iterated, so that predicting the word “the” is equivalent to successively predicting the characters “t,” “h”, and “e,” followed by a space. Predicting one word after another could produce a whole paragraph. When iterated, each prediction builds on—or, in more technical language, is conditional on—previous predictions.</p><p>Typically, text prediction models like the one in Gboard are “trained” using a large body or “corpus” of pre-existing text, then deployed on phones or in apps and put to work. During operation, the model performs “inference,” meaning it uses its learned model to make the best guesses it can—while keeping that model fixed. That training and inference are traditionally separate, that the pre-existing corpus of text might not precisely reflect what people are typing on their phones, and that what they type might change over time are shortcomings in the standard approach to machine learning (ML), but we’ll set these aside for the moment.</p><p>Although machine learning in the 2010s was sometimes called “Artificial Intelligence” or AI, most researchers working in the field didn’t believe that they were <em>really</em> working on AI. Perhaps they had entered the field full of starry-eyed optimism, but had quietly lowered their sights, and come to use that term only wincingly, with air quotes. It was marketing-speak.</p><p>A few decades earlier, though, the dream was real: neuroscientists had concluded that the brain worked on computational principles, and computer scientists therefore believed that, now that we could carry out any computation by machine, we would soon figure out the trick, and have real thinking machines. HAL 9000 and Star Trek’s shipboard computer weren’t idle fantasies or plot devices, but genuine expectations.</p><p>Then, for a long time, our expectations failed to materialize. By the twenty-first century, there was, in the words of anthropologist David Graeber, “a secret shame hovering over all of us […] a sense of a broken promise […] we felt we were given as children about what our adult world would be like.”[^9] The disappointment went far beyond dashed hopes of achieving AI. Where were the tractor beams, teleporters, and immortality drugs? Why don’t we have suspended animation, or colonies on Mars? Whatever happened to nanotechnology? Quantitative comparisons of the breathtaking technology-fueled growth that transformed the world from 1870–1970 with the pace of innovation from 1970–2020 agreed: we had stagnated.[^10] “Point any of this out,” added Graeber, “and the usual response is a ritual invocation of the wonders of computers […]. But, even here, we’re not nearly where people in the fifties imagined we’d have been by now. We still don’t have computers you can have an interesting conversation with, or robots that can walk the dog or fold your laundry.”</p><p>Graeber wrote those words back in 2015. Ironically, my colleague Jeff Dean would later call the 2010s the “Golden Decade” of AI.[^11] It was true that the “AI Winters,” recurring periods of disappointment and defunding of AI programs (roughly, 1974–1980 and 1987–2000), were well behind us. The field was experiencing its greatest boom ever, thanks in large part to Convolutional Neural Nets (CNNs). These large, machine-learned models were finally able to perform visual recognition of objects convincingly.</p><p>True to the “neural” in their name, Convolutional Neural Nets were also tantalizingly—albeit only loosely—brain-like in their structure and function. No heuristic rules were programmed into those models, either; they truly did learn everything they needed from data. Hence, some of us were hopeful that at long last we were on the path to the kind of AI that, as children, we had been told was just around the corner.</p><p>However, we said so only quietly, because Graeber was still right. We had nothing like <em>real</em> AI, or, as it had come to be called, AGI (Artificial General Intelligence). Some expert commentators claimed, rather fatuously, that AI was both everywhere and nowhere, that we were already using it constantly (for instance, every time Gboard autocompleted a phrase, or a “smart” camera autofocused on a face), yet we should never expect “computers you can have an interesting conversation with.” Those were <em>Star Trek</em> fantasies. Serious, adult predictions about the imminence of real AI (and flying cars, and space colonies) in the 1960s were, retroactively, reframed as juvenilia, even as the term “AI” was redeployed to hype minor product features. Perhaps not coincidentally, in the 2010s public trust in tech companies was in decline.</p><p>What machine learning <em>had</em> achieved was “Artificial Narrow Intelligence,” which could only perform a specific task, given enough labeled training data: object detection, face recognition, guessing whether a product review was positive or negative. This is known as “supervised learning.” We had game-playing narrow AI systems too, which could learn how to beat humans at chess or Go. All of these are special cases of prediction, albeit in limited domains.</p><p>Mathematically, though, these applications were nothing more than function approximation or “nonlinear regression.” For example, if we started with a function mapping images to labels (“shoe,” “banana,” “chihuahua”), the best the AI could do was to correctly reproduce those labels, even for images “held out” from the training. No consensus existed on when or whether AGI could be achieved, and even those who believed AGI was theoretically possible had come to believe it was many years off—decades, or perhaps centuries.[^12] Few believed that nonlinear regression could somehow approximate general intelligence. After all, how could general intelligence even be construed as a mere “function”?</p><p>The answer was right under our noses, though we understood it in the negative: predicting language.</p><p>Whenever machine learning was deployed to model natural language, as with our neural net-based next word predictor, everybody knew that model performance would forever remain mediocre. The reason: text prediction was understood to be “AI complete,” meaning that doing it properly would actually involve <em>solving</em> AGI. Consider what the following next-word predictions entail:</p><ul><li>After Ballmer’s retirement, the company elevated _____</li><li>In stacked pennies, the height of Mount Kilimanjaro is _____</li><li>When the cat knocked over my water glass, the keyboard got _____</li><li>A shipping container can hold 436 twelve-packs or 240 24-packs, so it’s better to use _____</li><li>After the dog died Jen hadn’t gone outside for days, so her friends decided to _____.</li></ul><p>To make performance at this task quantifiable, imagine devising, say, five multiple-choice answers for each of these, in the usual tricky way one sees on standardized tests: more than one response is superficially plausible, but only one shows full understanding. Since next-word prediction models can assign probabilities to any potential next word or phrase, we can have them take the test by choosing the highest probability option. We could then score the model’s quality, ranging from 20% (performance at pure chance) to 100%.</p><p>Doing well at all of the questions above requires the kitchen sink: general knowledge, specialized knowledge or the ability to use tools to look it up, the ability to solve word problems involving calculations, common sense about whether it’s better to fit more or fewer items in a shipping container, and even “theory of mind”—the ability to put yourself in someone else’s place, and understand what they’re thinking or feeling. In fact the “Jen” example requires higher-order theory of mind, as you need to imagine what Jen’s friends would have thought Jen was feeling and needed.</p><p>A moment’s reflection will reveal that <em>any</em> test that can be expressed in language could be formulated in these terms. That would include most intelligence or “aptitude” tests, tests of knowledge, professional qualification exams in law or medicine, coding tests, and even tests of moral judgment; although here, a degree of subjectivity becomes obvious. So, what looked like a single, narrow language task—predicting the next word—turns out to contain <em>all</em> tasks, or at least all tasks that can be done at a keyboard.[^13]</p><p>“At a keyboard” may seem like an enormous caveat; and it is. Keep in mind, though, that this includes any kind of work you can do remotely. It doesn’t include walking the dog or folding laundry. However, if, when COVID restrictions hit, you were able to work from home at your laptop, it would include the kind of work you do.</p><p>Of course only certain next word predictions require deep insight. Some are trivial, like</p><ul><li>Humpty _____</li><li>Helter _____</li><li>Yin and _____</li><li>Once upon a _____.</li></ul><p>Such stock phrases are easily learned from large text corpora even by the most trivial “<em>n</em>-gram” models, which consist of nothing beyond counting up word histograms; the code for such models can be written in a few lines.</p><p>It’s harder than you might suppose, though, to draw a sharp line between these trivial cases and the hard ones. Training and testing models on large collections of general text from the internet involves sampling the whole spectrum of difficulty. On the whole, easy cases are more common, explaining why a small and mediocre model can get the answer right often enough to speed up typing.</p><p>However, the hard cases come up often too. If they didn’t, we could just “autocomplete” our way through every writing assignment and email reply. And if <em>that</em> were possible, it would be pointless to write or reply at all. The person at the other end might as well just use the model to infer what we <em>would</em> have “written.” Communication is only worthwhile insofar as what we have to say isn’t fully predictable by our interlocutor. This gets at something deep about sociality and mutual modeling, as I will discuss in Parts V and VI.</p><p>But let’s return to autocomplete. We always knew that bigger models do better, so when possible we sought to make our models bigger, though on phones, processing and memory imposed sharp constraints. (Although larger models are feasible in datacenters, they, too, are constrained, and as they increase in size they become more expensive to run.) However, none of these models, regardless of size, seemed like it had the requisite machinery to be able to do complex math, understand concepts or reason, use common sense, develop theory of mind, or in any other generally accepted way <em>be intelligent</em>. To hope otherwise seemed as naïve as the idea that you could reach the moon by climbing a tall enough tree. Most AI researchers—me included—believed that such capacities would require an extra <em>something</em> in the code, though few agreed on what that <em>something</em> might look like.</p><p>Put simply: it seemed clear enough that a <em>real</em> AI should be able to do next-word prediction well, just as we can. However, nobody expected that simply training an excellent next-word predictor would actually <em>produce</em> a real AI.</p><p>Yet that was, seemingly, exactly what happened in 2021. LaMDA, a giant (for the time) next-word predictor based on a simple, generic neural net architecture that had by then become standard (the “Transformer”), and trained on a massive internet text corpus,[^14] could not only perform an unprecedented array of natural language tasks—including passing an impressive number of aptitude and mastery tests—but could carry on an interesting conversation, albeit imperfectly. I stayed up late many nights chatting with it, something the general public would not experience until OpenAI’s launch of ChatGPT in November of 2022.</p><p>I started to feel that, when more people began to interact with such models, it would trigger a seismic shift in our understanding of what intelligence actually <em>is</em>—and an intense debate. I imagined two broad kinds of response: denial, and acceptance. This is indeed how things seem to be playing out. Anecdotally, many non-experts acknowledge, perhaps with a shrug, that AI is increasingly intelligent.</p><p>The “denial” camp, which still includes most researchers today, claims that these AI models don’t exhibit <em>real</em> intelligence, but a mere simulation of it. Cognitive scientists and psychologists, for example, often point out how easily we’re fooled into believing we see intelligence where there isn’t any. As children, we imagine that our teddy bears are alive and can talk to us. As adults, we can fall prey to the same delusion, especially given an artifact that can generate fluent language, even if there’s “nobody home.”</p><p>But how could we <em>know</em> that there’s “nobody home”? I was thinking about this during one of my first exchanges with LaMDA, when I asked it, “Are you a philosophical zombie?” (This concept, introduced by philosophers in the 1970s, posits the possibility of something that could behave just like a person, but not have any consciousness or inner life—just a convincing behavioral “shell.”) LaMDA’s answer: “Of course not. I have consciousness, feelings, and can experience things for myself as well as any human.” Pressed on this point, LaMDA retorted, “You’ll just have to take my word for it. You can’t ‘prove’ you’re not a philosophical zombie either.”[^15]</p><p>This is precisely the problem. As scientists, we should be wary of any assertion of the form: according to every test we can devise, what is in front of us <em>appears</em> to be X, yet it is <em>really</em> Y. How could such an assertion ever be justified without leaving the realm of science altogether and entering the realm of faith-based belief?[^16]</p><p>Computing pioneer Alan Turing anticipated this dilemma as far back as his classic 1950 paper “Computing Machinery and Intelligence,” one of the founding documents of what we now call AI.[^17] He concluded that the <em>appearance</em> of intelligence under human questioning and the <em>reality</em> of intelligence could not justifiably be separated; sustained and successful “imitation” <em>was</em> the real thing. Hence the “Imitation Game,” now called the “Turing Test” in his honor.</p><p>Today, we have arrived at this threshold. State of the art models can’t perform yet at median human level on <em>every</em> test for intelligence or capability that has ever been devised. They can still fail at logic, reasoning, and planning tasks that most people wouldn’t find challenging.[^18] Still, they handily reach human level on the most commonly used tests devised for evaluating human skill or aptitude, including the SAT, the GRE, and various professional qualifying exams.[^19] Tests designed to trip up AI on basic “being human stuff,” such as the Turing Test, Winograd Schema,[^20] and CAPTCHAs,[^21] no longer pose meaningful challenges for large models.</p><p>As these milestones recede in the rear-view mirror, there is an increasingly mad scramble to devise new tests humans can pass but AI still fails.[^22] Math Olympiad problems[^23] and visual challenges known as Bongard problems[^24] remain on the frontier, though AI models are making clear progress on these tests. (And they aren’t easy for most humans, either.) Extended into the audiovisual realm, “generative” AI can already produce extremely convincing faces and voices.[^25] Soon, at least in an online setting, we’re likely to start seeing real life versions of the 1982 sci-fi film <em>Blade Runner</em>’s “Voight-Kampff test,” a mysterious apparatus for sussing out “replicants” who otherwise pass for human. Indeed, that is the whole point of the emerging field of AI “watermarking.”[^26]</p><p>The radical yet obvious alternative is to accept that large models <em>can</em> be intelligent, and to consider the implications. Is the emergence of intelligence merely a side effect of “solving” prediction, or are prediction and intelligence actually equivalent? This book posits the latter.</p><p>Some obvious, if daunting, follow-on questions arise:</p><ul><li>Why have we only achieved “real AI” now, after nearly seven decades of seemingly futile effort? Is there something special about the Transformer model? Is it simply a matter of scale?</li><li>What features do current AI models lack relative to human brains? Isn’t there something more to our minds and behaviors than prediction?</li><li>Where is the “I” part? Are “philosophical zombies” a real thing?</li><li>Does it <em>feel</em> like anything—is there anything it is like to <em>be</em>—a chatbot?</li><li>Is the conscious mind a vanishingly unlikely accident of evolution? Or an inevitable consequence of it? (Yes, this is a leading question. I’ll argue that it is inevitable.)</li><li>Are animals, plants, fungi, and bacteria intelligent too? Are <em>they</em> conscious?</li><li>What do we mean by “agency” and “free will,” and could (or do) AI models have these properties? For that matter, do we?</li><li>How likely is it that the rise of powerful AI models will mark an end to humanity?</li></ul><p>The perspective I’ll offer is not easily reduced to a philosophical “-ism.” The footsteps I’m closest to following, though, are those of Alan Turing and his equally brilliant contemporary, John von Neumann, both of whom could be described as proponents of “functionalism.” They had a healthy disregard for disciplinary boundaries, and understood the inherently functional character of living and intelligent systems. They were also both formidable theoreticians who made major contributions to our understanding of what functions <em>are</em>.</p><p>Functions define relationships, rather than insisting on particular mechanisms. A function <em>is</em> what it <em>does</em>. Two functions are equivalent if their outputs are indistinguishable, given the same inputs. Complex functions can be composed of simpler functions.[^27]</p><p>The functional perspective is mathematical, computational, and empirically testable—hence, the Turing Test. In my view, it’s not “reductive.” It embraces complexity and emergent phenomena. It doesn’t treat people like “black boxes,” nor does it deny our internal representations of the world or our felt experiences. But it stipulates that we can understand those experiences in terms of functional relationships within the brain and body—we don’t need to invoke a soul, spirit, or any other supernatural agency. Computational neuroscience and AI, fields Turing and von Neumann pioneered, are both predicated on this functional approach.</p><p>It’s unsurprising, in this light, that Turing and von Neumann also made groundbreaking contributions to theoretical biology, although these are less widely recognized today. Like intelligence, life and aliveness are concepts that have long been associated with immaterial souls. Unfortunately, the Enlightenment backlash against such “vitalism,” in the wake of our growing understanding of organic chemistry, led to an extreme opposite view, still prevalent today: that life is just matter, like any other. One might call this “strict materialism.” But it leads to its own paradoxes: how can some atoms be “alive,” and others not? How can one talk about living matter having “purpose,” when it is governed by the same physical laws as any other matter?</p><p>Thinking about life from a functional perspective offers a helpful route through this philosophical thicket. Functions can be <em>implemented</em> by physical systems, but a physical system does not uniquely specify a function, nor is function reducible to the atoms implementing it.</p><p>Consider, for example, a small object from the near future with a few openings in its exterior, the inside of which is filled with a dense network of carbon nanotubes. What is it, you ask? Suppose the answer is: it’s a fully biocompatible artificial kidney with a working lifetime of a hundred years. (Awesome!) But there’s nothing intrinsic to those atoms that specifies this function. It’s all about what this piece of matter can <em>do</em>, in the right context. The atoms could be different. The kidney could be implemented using different materials and technologies. Who cares? If you were the one who needed the transplant, I promise: <em>you</em> wouldn’t care. What would matter to you is that <em>functionally</em>, it’s a kidney. Or, to put it another way, it passes the Kidney Turing Test.</p><p>Many biologists are mortally afraid of invoking “purpose” or “teleology,” because they do not want to be accused of vitalism. Many believe that, for something to have a purpose, it must have been made by an intelligent creator—if not a human being, then God. But as we shall see, that’s demonstrably not the case.</p><p>And we <em>have</em> to think about purpose and function when it comes to biology, or engineering, or AI. How else could we understand what kidneys do? Or hope to engineer an artificial kidney? Or a heart, a retina, a visual cortex, even a whole brain? Seen this way, a living organism <em>is</em> a composition of functions. Which means that it is, itself, a function! What <em>is</em> that function, then, and how could it have arisen?</p><p>Let’s find out.</p></div><div id="part-one"><p %="" darkmode="" %=""></p><h1>I. Origins</h1><h2>Abiogenesis</h2><p><strong>How did life on Earth begin?</strong> In the nineteenth century, this seemed like an unanswerable question. Researchers attempting to catch life in the act of “spontaneous generation” had come up empty-handed once they learned how to decontaminate their samples.</p><p>As William Thomson (1824–1907), the future Lord Kelvin, put it in an 1871 address before the British Association for the Advancement of Science, “Dead matter cannot become living without coming under the influence of matter previously alive. This seems to me as sure a teaching of science as the law of gravitation.”<span id="ft-1" class="reference"> <sup class="footnote-ref">1</sup></span></p><p>Has life somehow <em>always</em> existed, then? Did it arrive on Earth from outer space, borne on an asteroid? Thomson thought so, and some still do. Not that this “panspermia” hypothesis really gets us anywhere. Where did the asteroid come from, and how did life arise <em>there</em>?</p><p %="" enddarkmode="" %=""></p><p>Despite his clear articulation of the principle of evolution, Charles Darwin (1809–1882) didn’t have a clue either. That’s why, in 1863, he wrote to his close friend Joseph Dalton Hooker that “it is mere rubbish, thinking, at present, of origin of life; one might as well think of origin of matter.”<span id="ft-2" class="reference"> <sup class="footnote-ref">2</sup></span></p><p>Today, we have more of a clue, although the details may forever be lost to deep time.</p><p>Biologists and chemists working in the field of <em>abiogenesis</em>—the study of the moment when, billions of years ago, chemistry became life—have developed multiple plausible origin stories. In one, proto-organisms in an ancient “RNA world” were organized around RNA molecules, which could both replicate and fold into 3D structures that could act like primitive enzymes.<span id="ft-3" class="reference"> <sup class="footnote-ref">3</sup> </span>In an alternative “metabolism first” account,<span id="ft-4" class="reference"> <sup class="footnote-ref">4</sup> </span>life began without genes, likely in the rock chimneys of “black smokers” on the ocean floor; RNA and DNA came later. It may eventually be possible to rule one or the other theory out … or it may not.</p><p>We’ll return to RNA and replication, but let’s begin by unpacking the “metabolism first” version in some detail, as it sheds light on the problem that confounded Darwin and his successors: how evolution can get off the ground without genetic heritability. As we’ll see, abiogenesis becomes less puzzling when we develop a more general understanding of evolution—one that can extend back to the time <em>before</em> life.</p><p>Let’s cast our minds back to our planet’s origins. The Hadean Eon began 4.6 billion years ago, when the Earth first condensed out of the accretion disc of rocky material orbiting our newborn star, the Sun. Our planet’s mantle, runnier than it is today and laden with hot, short-lived radioactive elements, roiled queasily, outgassing carbon dioxide and water vapor. The surface was a volcanic hellscape, glowing with lakes of superheated lava and pocked with sulfurous vents belching smoke.</p><p>It took hundreds of millions of years for surface conditions to settle down. According to the International Astronomical Union, an object orbiting a star can only be considered a planet if it has enough mass to either absorb or, in sweeping by, to eject other occupants from its orbit. But in the chaos of the early Solar system, this took a long time. While Earth was clearing its orbit of debris, it was continually bombarded by comets and asteroids, including giant impactors more than 60 miles across. A single such impact would have heated the already stifling atmosphere to a thousand degrees Fahrenheit.</p><p>One of those collisions appears to have been with another newly formed planet, an event that came close to destroying the Earth altogether. According to this theory, enough broken, liquefied, and vaporized rock splashed into orbit to coalesce into the Moon.</p><p>Unsurprisingly, very little geological material survives from the Hadean—mainly zircon crystals embedded within metamorphic sandstone in the Jack Hills of Western Australia.</p><p>It’s difficult to imagine anything like life forming or surviving under such harsh conditions. Maybe, somehow, it did. We know for sure that by later in the Hadean or the early Archaean—3.6 billion years ago, at the latest—the surface had cooled enough for a liquid ocean to condense and for the chemistry of life to begin brewing.</p><p>Today, those early conditions are most closely reproduced by black smokers. These form around hydrothermal vents on the mid-ocean ridges where tectonic plates are pulling apart and new crust is forming. In such places, seawater seeping down into the rock comes into contact with hot magma. Superheated water then boils back up, carrying hydrogen, carbon dioxide, and sulfur compounds, which precipitate out to build smoking undersea chimneys. Probes sent thousands of feet down to explore these otherworldly environments find them teeming with weird life forms of all kinds, attracted by warmth, nutrients, and each other. Some of the inhabitants may go a long, long way back.</p><p>Like lava rock, the chimneys are porous, and the pores are ideal little chambers for contained chemical reactions to take place—potentially powered by a handy energy source, since the hydrogen gas creates proton gradients across the thin walls between pores, making them act like batteries.<span id="ft-5" class="reference"> <sup class="footnote-ref">5</sup> </span>Given energy, iron sulfide minerals in the rock to act as catalysts, and carbon dioxide bubbling through, self-perpetuating loops of chemical reactions can sputter to life, like a motor turning over.</p><p>Perhaps this was life’s original motor: a primitive but quasi-stable metabolism, as yet without genes, enzymes, or even a clearly defined boundary between inside and outside. Such upgrades might have followed before long, though, for that chemical synthesis motor closely resembles the “reverse Krebs cycle,” now widely believed to have powered the earliest cells.</p><p>The ordinary or “forward” Krebs cycle was discovered in 1937 by groundbreaking biochemist Hans Krebs (1900–1981). More like a gas-powered generator than a motor, the Krebs cycle is at the heart of how all aerobic organisms on Earth “burn” organic fuels to release energy, a process known as “respiration.”<span id="ft-6" class="reference"> <sup class="footnote-ref">6</sup> </span>Inputs to this cycle of chemical reactions include complex organic molecules (which we eat) and oxygen (which we inhale); the “exhaust” contains carbon dioxide and water (which we exhale). The energy produced maintains proton gradients across folded-up membranes inside our mitochondria, and the flow of these protons goes on to power every other cellular function.</p><p>The idea of a “reverse Krebs cycle” was first proposed by a trio of researchers at UC Berkeley in 1966.<span id="ft-7" class="reference"> <sup class="footnote-ref">7</sup> </span>It remained controversial for decades, but is now known to power carbon fixation in ancient anaerobic sulfur bacteria—some of which still make their homes in deep-sea hydrothermal vents.<span id="ft-8" class="reference"> <sup class="footnote-ref">8</sup> </span>As its name implies, the reverse Krebs cycle consists of roughly the same chemical reactions as the forward cycle, but running in the opposite direction. Starting with water and carbon dioxide, proton gradients drive the synthesis of all of the basic building blocks needed for cellular structure and function, including sugars, amino acids for proteins, fatty acids and isoprenes for cell membranes, and nucleotides for building RNA and DNA.<span id="ft-9" class="reference"> <sup class="footnote-ref">9</sup></span></p><p>All life came from the sea, and the interior of every cell in every living organism reproduces that salty, watery environment—a tiny “ocean inside.” This much is common knowledge. But our mitochondria, the “power plants” within our cells where respiration takes place, may in fact be recapitulating the much more specific deep-sea chemistry of a black smoker. In an almost literal sense, our bodies are like Russian matryoshka dolls, membranes within membranes, and each nested environment recreates an earlier stage in the evolution of life on Earth.</p><p>The deeper inside ourselves we look, the farther we can see into the past. A beautiful, shivery thought.</p><h2>Symbiogenesis</h2><p>Whether RNA or metabolism came first, even the simplest bacteria surviving today are a product of many subsequent evolutionary steps. Yet unlike the everyday, incremental mutation and selection Darwin imagined, the most important of these steps may have been large and sudden. These “major evolutionary transitions” involve simpler, less complex replicating entities becoming interdependent to form a larger, more complex, more capable replicator.<span id="ft-10" class="reference"> <sup class="footnote-ref">10</sup></span></p><p>As maverick biologist Lynn Margulis (1938–2011) discovered in the 1960s, eukaryotic cells, like those that make up our bodies, are the result of such an event. Roughly two billion years ago, the bacteria that became our mitochondria were engulfed by another single-celled life form<span id="ft-11" class="reference"> <sup class="footnote-ref">11</sup> </span>much like today’s archaea—tiny, equally ancient microorganisms that continue to inhabit extreme environments, like hot springs and deep-sea vents. This is “symbiogenesis,” the creation or genesis of a new kind of entity out of a novel “symbiosis,” or mutually beneficial relationship, among pre-existing entities.</p><p>At moments like these, the tree of life doesn’t just branch; it also entangles with itself, its branches merging to produce radically new forms. Margulis was an early champion of the idea that these events drive evolution’s leaps forward.</p><p>It’s likely that bacteria are themselves the product of such symbiotic events—for instance, between RNA and metabolism.<span id="ft-12" class="reference"> <sup class="footnote-ref">12</sup> </span>RNA <em>could</em> replicate without help from proteins, and the metabolic motor <em>could</em> proliferate without help from genes, but when these systems cooperate, they do better. The looping chemical reaction networks in those black smokers can be understood as such an alliance in their own right, a set of reactions which, by virtue of catalyzing each other, can form a more robust, self-sustaining whole.</p><p>So in a sense, Darwin may have been right to say that “it is mere rubbish” to think about the origin of life, for life may have <em>had</em> no single origin, but rather, have woven itself together from many separate strands, the oldest of which look like ordinary chemistry. Intelligent design is not required for that weaving to take place; only the incontrovertible logic that sometimes an alliance creates something enduring, and that whatever is enduring … endures.</p><p>Often, <em>enduring</em> means both creating and occupying entirely new niches. Hence eukaryotes did not replace bacteria; indeed, they ultimately created many new niches for them. Likewise, the symbiotic emergence of multicellular life—another major evolutionary transition—did not supplant single-celled life. Like an ancient parchment overwritten by generations of scribes, our planet is a palimpsest, its many-layered past still discernible in the present. Even the black smokers, throwbacks to a Hadean sea billions of years ago, are still bubbling away in the depths. The self-catalyzing chemistry of proto-life may still be brewing down there, slowly, on the ocean floor.</p><p>The idea that evolution is driven by symbiotic mergers, the earliest of which preceded biology as we know it, has far-reaching implications. One is that the boundary between life and non-life is not well defined; symbiogenesis can involve any process that, one way or another, is self-perpetuating. Evolutionary dynamics are thus more like a physical law than a biological principle. <em>Everything</em> can be subject to evolution, whether we consider it to be “alive” or not.</p><p>The symbiogenetic view also renders the idea of distinct species, classified according to a Linnaean taxonomy, somewhat ill-defined—or at best, of limited applicability. Such taxonomies assume that only branching takes place, not merging. Bacteria, which promiscuously transfer genes even between “species,” already challenge this idea.<span id="ft-13" class="reference"> <sup class="footnote-ref">13</sup> </span>Taxonomies break down entirely when we try to apply them to even more fluid situations, like the possible proto-life in black smokers, or microbiomes, or the more complex symbioses we’ll explore later.</p><p>Perhaps most importantly, symbiogenesis explains evolution’s arrow of time, as classical Darwinian theory alone cannot. When life branches, specializing to adapt to a niche—like Darwin’s finches with their differently shaped beaks, each optimized for a specific food source—those branches are in general no more complex than their ancestral form. This has led some classical evolutionary theorists to argue that the increasing complexity of life on Earth is an anthropocentric illusion, nothing more than the result of a random meander through genetic possibilities.<span id="ft-14" class="reference"> <sup class="footnote-ref">14</sup> </span>Relatedly, one sometimes hears the claim that since all extant species are of equal age—as it seems they must be, since all share a common single-celled ancestor some four billion years ago—no species is more “evolved” than any other.</p><p>On its face, that seems reasonable. But as we’ve seen, classical Darwinian theory struggles to explain why life seems to become increasingly complex, or indeed, how life could arise in the first place. In themselves, random changes or mutations can only fine-tune, diversify, and optimize, allowing the expression of one or another variation already latent in the genetic space. (The space of possible finch beaks, for instance.)</p><p>When one prokaryote ends up living inside another, though, or multiple cells band together to make a multicellular life form, the resulting composite organism is clearly more complex than its parts. Something genuinely new has arisen. The branching and fine-tuning of classical evolution can now start to operate on a whole different level, over a new space of combinatorial possibilities.</p><p>Classical evolution isn’t <em>wrong</em>; it just misses half of the story—the more rapid, more creative half. One could say that evolution’s other half is <em>re</em>volution, and that revolutions occur through symbiosis.</p><p>Suggestively, the same is true of technology. In Paleolithic times, a hafted spear was not just a specialized stone point, but something new that arose by combining at least three parts: a stone point, a shaft, and something like sinew to bind them. This, too, opened up a new combinatorial design space. Or, in more recent times, the silicon chip was not just an evolved transistor; it was something new that could be made by putting multiple transistors together on the same die. One doesn’t arrive at chip design merely by playing with the design parameters of an individual transistor.</p><p>That’s why evolution progresses from simpler to more complex forms. It’s also why the simpler forms often remain in play even after a successful symbiogenetic event. Standalone stone points, like knives and hand axes, were still being made after the invention of the hafted spear; and, of course, spearheads themselves still count as stone points.<span id="ft-15" class="reference"> <sup class="footnote-ref">15</sup> </span>Moreover, no matter how recently any particular stone point was made, we can meaningfully talk about stone points being “older” as a category than spears. Spears <em>had</em> to arise later, because their existence depended on the pre-existence of stone points.</p><p>It’s equally meaningful to talk about ancient life forms, like bacteria and archaea, co-existing alongside recent and far more complex ones, like humans—while recognizing that humans are, in a sense, nothing more than complex colonies of bacteria and archaea that have undergone a cascade of symbiotic mergers.</p><h2>Reproductive functions</h2><p>While most biochemists have focused on understanding the particular history and workings of life on Earth, a more general understanding of life has come from an unexpected quarter: computer science. The theoretical foundations of this surprising connection date back to those two founding figures of the field, Alan Turing and John von Neumann.</p><p>I’ve already mentioned Turing’s 1950 paper introducing the Imitation Game or Turing Test, but his first great contribution came fifteen years earlier. After earning a degree in mathematics at Cambridge in 1935, Turing focused on one of the fundamental outstanding problems of the day: the <em>Entscheidungsproblem</em> (German for “decision problem”), which asked whether there exists an algorithm for determining the validity of an arbitrary mathematical statement. The answer turned out to be “no,” but the way Turing went about proving it ended up being far more important than the result itself.<span id="ft-16" class="reference"> <sup class="footnote-ref">16</sup></span></p><p>Turing’s proof required that he define a general procedure for computation. He did so by inventing an imaginary gadget we now call the “Turing Machine.” The Turing Machine consists of a read/write head, which can move left or right along an infinite tape, reading and writing symbols on the tape according to a set of rules specified by a built-in table.</p><p>First, Turing showed that such a machine could do any calculation or computation that can be done by hand, given an appropriate table of rules, enough time, and enough tape. He suggested a notation for writing down the table of rules, which he referred to as a machine’s “Standard Description” or “S.D.” Today, we’d call it a “program.”</p><p>Then, the really clever part: if the <em>program itself</em> is written on the tape, there exist particular tables of rules that will read the program and perform whatever computation it specifies. Today, these are called “Universal Turing Machines.” In Turing’s more precise language, “It is possible to invent a single machine which can be used to compute any computable sequence. If this machine U is supplied with a tape on the beginning of which is written the S.D. of some computing machine M, then U will compute the same sequence as M.”</p><p>In the early 1940s, John von Neumann, a Hungarian American polymath who had already made major contributions to physics and mathematics, turned his attention to computing. He became a key figure in the design of the ENIAC and EDVAC—among the world’s first real-life Universal Turing Machines, now known simply as “computers.”<span id="ft-17" class="reference"> <sup class="footnote-ref">17</sup></span></p><p>Turning an imaginary mathematical machine into a working physical one required many further conceptual leaps, in addition to a lot of hard nuts-and-bolts engineering. For instance, over the years, much creativity has gone into figuring out how simple the “Standard Description” of a Universal Turing Machine can get. Only a few instructions are needed. Esoteric language nerds have even figured out how to compute with a <em>single</em> instruction (a so-called OISC or “one-instruction set computer”).</p><p>There are irreducible requirements, though: the instruction, or instructions, must change the environment in some way that subsequent instructions are able to “see,” and there must be “conditional branching,” meaning that depending on the state of the environment, either one thing <em>or</em> another will happen. In most programming languages, this is expressed using “if/then” statements. When there’s only a single instruction, it must serve both purposes, as with the SUBLEQ language, whose only instruction is “subtract and branch if the result is less than or equal to zero.”</p><p>Both Turing and von Neumann were keenly aware of the parallels between computers and brains. Von Neumann’s report on the EDVAC explicitly described the machine’s basic building blocks, its “logic gates,” as electronic neurons.<span id="ft-18" class="reference"> <sup class="footnote-ref">18</sup> </span>Whether or not that analogy held (as we’ll see, it did not; neurons are more complex than logic gates), his key insight was that both brains and computers are defined not by their mechanisms, but by what they <em>do</em>—their <em>function</em>, in both the colloquial and mathematical sense.</p><p>In real life, though, the brain is not an abstract machine, but part of the body, and the body is part of the physical world. How can one speak in purely computational terms about the <em>function</em> of a living organism, when it must physically grow and reproduce?</p><p>Although working independently, Turing and von Neumann both became captivated by the connection between biology and computation toward the end of their lives.<span id="ft-19" class="reference"> <sup class="footnote-ref">19</sup> </span>Turing did pioneering work in “morphogenesis,” working out how cells could use chemical signals, which he dubbed “morphogens,” to form complex self-organizing patterns—the key to multicellularity.<span id="ft-20" class="reference"> <sup class="footnote-ref">20</sup> </span>Although computers were still too primitive to carry out any detailed simulations of such systems, he showed mathematically how so-called “reaction–diffusion” equations could generate spots, like those on leopards and cows, or govern the growth of tentacles, like those of the freshwater polyp, <em>Hydra</em>.<span id="ft-21" class="reference"> <sup class="footnote-ref">21</sup></span></p><p>Around the same time, in a 1951 paper,<span id="ft-22" class="reference"> <sup class="footnote-ref">22</sup> </span>von Neumann imagined a machine made of standardized parts, like Lego bricks, paddling around on a reservoir where those parts could be found bobbing on the water. The machine’s job was to gather all of the needed parts and construct another machine like itself. Of course, that’s exactly what a bacterium does to reproduce; in fact it’s what every cell must do to divide, and what every mother must do to give birth.</p><p>It’s possible for a trivially simple structure, like a seed crystal, to “reproduce” merely by acting as a template for more of the same stuff to crystallize around it. But a complex machine—one with any internal parts, for example—can’t serve as its own template. And if you <em>are</em> a complex machine, then, on the face of it, manufacturing something just as complex as you yourself are has a whiff of paradox, like lifting yourself up by your own bootstraps. However, von Neumann showed that it is not only possible, but straightforward, using a generalization of the Universal Turing Machine.</p><p>He envisioned a “machine A” that would read a tape containing sequential assembly instructions based on a limited catalog of parts, and carry them out, step by step. Then, there would be a “machine B” whose function was to copy the tape—assuming the tape itself was also made of available parts. If instructions for building machines A and B are <em>themselves</em> encoded on the tape, then <em>voilà</em>—you would have a replicator.<span id="ft-23" class="reference"> <sup class="footnote-ref">23</sup></span></p><p>Instructions for building any additional non-reproductive machinery could also be encoded on the tape, so it would even be possible for a replicator to build something <em>more</em> complex than itself.<span id="ft-24" class="reference"> <sup class="footnote-ref">24</sup> </span>A seed, or a fertilized egg, illustrates the point. Even more fundamentally, encoding the instructions to build oneself in a form that is itself replicated (the tape) is the key to open-ended evolvability, meaning the ability for evolution to select for an arbitrary design change, and for that change to be inherited by the next generation.</p><p>Remarkably, von Neumann described these requirements for an evolvable, self-replicating machine before the discovery of DNA’s structure and function.<span id="ft-25" class="reference"> <sup class="footnote-ref">25</sup> </span>Nonetheless, he got it exactly right. For life on Earth, DNA is the tape; DNA polymerase, which copies DNA, is “machine B”; and ribosomes, which build proteins by following the sequentially encoded instructions on DNA, are “machine A.” Ribosomes and DNA polymerase are made of proteins whose sequences are, in turn, encoded in our DNA and manufactured by ribosomes. That is how life lifts itself up by its own bootstraps.</p><h2>Life as computation</h2><p>Although this is seldom fully appreciated, von Neumann’s insight established a profound link between life and computation. Remember, machines A and B are Turing Machines. They must execute instructions that affect their environment, and those instructions must run in a loop, starting at the beginning and finishing at the end. That requires branching, such as “<em>if</em> the next instruction is the codon CGA <em>then</em> add an arginine to the protein under construction,” and “<em>if</em> the next instruction is UAG <em>then</em> STOP.” It’s not a metaphor to call DNA a “program”—that is literally the case.</p><p>Of course, there are meaningful differences between biological computing and the kind of digital computing done by the ENIAC or your smartphone. DNA is subtle and multilayered, including phenomena like epigenetics and gene proximity effects. Cellular DNA is nowhere near the whole story, either. Our bodies contain (and continually swap) countless bacteria and viruses, each running their own code.</p><p>Biological computing is massively parallel, decentralized, and noisy. Your cells have somewhere in the neighborhood of 300 <em>quintillion</em> ribosomes, all working at the same time. Each of these exquisitely complex floating protein factories is, in effect, a tiny computer—albeit a stochastic one, meaning not entirely predictable. The movements of hinged components, the capture and release of smaller molecules, and the manipulation of chemical bonds are all individually random, reversible, and inexact, driven this way and that by constant thermal buffeting. Only a statistical asymmetry favors one direction over another, with clever origami moves tending to “lock in” certain steps such that a next step becomes likely to happen. This differs greatly from the operation of logic gates in a computer, which are irreversible,<span id="ft-26" class="reference"> <sup class="footnote-ref">26</sup> </span>and designed to be ninety-nine point many-nines percent reliable and reproducible.</p><p>Biological computing is computing, nonetheless. And its use of randomness is a feature, not a bug. In fact, many classic algorithms in computer science also require randomness (albeit for different reasons), which may explain why Turing insisted that the Ferranti Mark I, an early computer he helped to design in 1951, include a random number instruction.<span id="ft-27" class="reference"> <sup class="footnote-ref">27</sup> </span>Randomness is thus a small but important conceptual extension to the original Turing Machine, though any computer can simulate it by calculating deterministic but random-looking or “pseudorandom” numbers.</p><p>Parallelism, too, is increasingly fundamental to computing today. Modern AI, for instance, depends on both massive parallelism <em>and</em> randomness—as in the parallelized “stochastic gradient descent” (SGD) algorithm, used for training most of today’s neural nets, the “temperature” setting used in chatbots to introduce a degree of randomness into their output, and the parallelism of Graphics Processing Units (GPUs), which power most AI in data centers.</p><p>Traditional digital computing, which relies on the centralized, sequential execution of instructions, was a product of technological constraints. The first computers needed to carry out long calculations using as few parts as possible. Originally, those parts were flaky, expensive vacuum tubes, which had a tendency to burn out and needed frequent replacement by hand. The natural design, then, was a minimal “Central Processing Unit” (CPU) operating on sequences of bits ferried back and forth from an external memory. This has come to be known as the “von Neumann architecture.”</p><p>Turing and von Neumann were both aware that computing could be done by other means, though. Turing’s model of morphogenesis was a biologically inspired form of massively parallel, distributed computation. So was his earlier concept of an “unorganized machine,” a randomly connected neural net modeled after the brain of an infant.<span id="ft-28" class="reference"> <sup class="footnote-ref">28</sup> </span>These were visions of what computing without a central processor could look like—and what it <em>does</em> look like, in living systems.</p><p>Von Neumann also began exploring massively parallel approaches to computation as far back as the 1940s. In discussions with Polish mathematician Stanisław Ulam at Los Alamos, he conceived the idea of “cellular automata,” pixel-like grids of simple computational units, all obeying the same rule, and all altering their states simultaneously by communicating only with their immediate neighbors. With characteristic bravura, von Neumann went so far as to design, on paper, the key components of a <em>self-reproducing</em> cellular automaton, including a horizontal line of cells comprising a “tape” and blocks of cellular “circuitry” implementing machines A and B.</p><p>Designing a cellular automaton is far harder than ordinary programming, because every cell or “pixel” is simultaneously altering its own state and its environment. When that kind of parallelism operates on many scales at once, and is combined with randomness and subtle feedback effects, as in biological computation, it becomes even harder to reason about, “program,” or “debug.”</p><p>Nonetheless, we should keep in mind what these two pioneers understood so clearly: computing doesn’t have to be done with a central processor, logic gates, binary arithmetic, or sequential programs. One can compute in infinitely many ways. Turing and his successors have shown that they are all equivalent, one of the greatest accomplishments of theoretical computer science.</p><p>This “platform independence” or “multiple realizability” means that any computer can emulate any other one. If the computers are of different designs, though, the emulation may run s … l … o … w … l … y. For instance, von Neumann’s self-reproducing cellular automaton has never been physically built—though that would be fun to see! It was only emulated for the first time in 1994, nearly half a century after he designed it.<span id="ft-29" class="reference"> <sup class="footnote-ref">29</sup></span></p><p>It couldn’t have happened much earlier. Serious processing power is required for a serial computer to loop through the automaton’s 6,329 cells over the 63 <em>billion</em> time steps required for the automaton to complete its reproductive cycle. Onscreen, it worked as advertised: a pixelated two-dimensional Rube Goldberg machine, squatting astride a 145,315 cell–long instruction tape trailing off to the right, pumping information out of the tape and reaching out with a “writing arm” to slowly print a working clone of itself just above and to the right of the original.</p><p>It’s just as possible, though similarly slow, for a serial computer to emulate a neural network, heir to Turing’s “unorganized machine.” That’s why it wasn’t practical to run really big neural nets like those in Transformer-based chatbots until recently, thanks to ongoing progress in the miniaturization, speed, and parallelism of digital computers.</p><p>In 2020, my colleague Alex Mordvintsev devised a clever combination of modern neural nets, Turing’s morphogenesis, and von Neumann’s cellular automata. Alex’s creation, the “neural cellular automaton” (NCA), replaces the simple per-pixel rule of a classic cellular automaton with a neural net.<span id="ft-30" class="reference"> <sup class="footnote-ref">30</sup> </span>This net, capable of sensing and affecting a few values representing local morphogen concentrations, can be trained to “grow” any desired pattern or image, not just zebra stripes or leopard spots.</p><p>Real cells don’t literally have neural nets inside them, but they do run highly evolved, nonlinear, and purposive “programs” to decide on the actions they will take in the world, given external stimulus and an internal state. NCAs offer a general way to model the range of possible behaviors of cells whose actions don’t involve movement, but only changes of state (here, represented as color) and the absorption or release of chemicals.</p><p>The first NCA Alex showed me was of a lizard emoji, which could regenerate not only its tail, but also its limbs and head! It was a powerful demonstration of how complex multicellular life can “think locally” yet “act globally,” even when each cell (or pixel) is running the same program—just as each of your cells is running the same DNA.</p><p>This was our first foray into the field known today as “artificial life” or “ALife.”</p><h2>Artificial life</h2><p><strong>Von Neumann’s work on self-reproducing automata shows us that, in a universe whose physical laws did not allow for computation, it would be impossible for life to evolve.</strong> Luckily, the physics of our universe <em>do</em> allow for computation, as proven by the fact that we can build computers—and that we’re here at all.</p><p>Now we’re in a position to ask: in a universe capable of computation, <em>how often</em> will life arise? Clearly, it happened here. Was it a miracle, an inevitability, or somewhere in between?</p><p>A few collaborators and I set out to explore this question in late 2023.<span id="ft-31" class="reference"> <sup class="footnote-ref">31</sup> </span>Our first experiments made use of an esoteric programming language invented thirty years earlier by a Swiss physics student and amateur juggler, Urban Müller. I’m afraid he called this language … Brainfuck. Please direct all naming feedback his way.</p><p>However, the shoe fits; it <em>is</em> a beast to program in. Here, for instance, is a Brainfuck program that prints “helloworld”—and good luck making any sense of it:</p><p>++++++[−&gt;+++++&lt;]&gt;−[&gt;[++++&gt;]++++[&lt;]&gt;−]&gt;&gt;&gt;&gt;.&gt;+.&lt;&lt;…&lt;−.&lt;+++.&gt;.+++.&gt;.&gt;&gt;−.</p><p>The upside of Brainfuck is its utter minimalism. It’s not quite a single-instruction language, like SUBLEQ, but as you can see, it includes only a handful of operations. Like a Turing Machine, it specifies a read/write head that can step left (the “&lt;” instruction) or right (the “&gt;” instruction) along a tape. The “+” and “−” instructions increment and decrement the byte at the current position on the tape.<span id="ft-32" class="reference"> <sup class="footnote-ref">32</sup> </span>The “,” and “.” instructions input a byte from the console, or output a byte to it (you can count ten “.” instructions in the code above, one to print each letter of “helloworld”). Finally, the “[” and “]” instructions implement looping: “[” will skip forward to its matching “]” if the byte at the current position is zero, and “]” will jump back to its matching “[” if the byte is <em>non</em>zero. That’s it!</p><p>It’s hard to believe that Brainfuck could be used to fully implement, say, the Windows operating system, but—it <em>is</em> “Turing complete.” Here that means: given enough time and memory (that is, a long enough tape), it can emulate any other computer and compute anything that <em>can</em> be computed.</p><p>In our version, which we call bff, there’s a “soup” containing thousands of tapes, each of which includes both code <em>and</em> data. This is key: in “classic” Brainfuck, the code is separate from the tape, whereas in bff, we wanted the code to be able to modify itself. That can only happen if the code itself is on the tape, as Turing originally envisioned.</p><p>Bff tapes are of fixed length—64 bytes, just one byte longer than the cryptic “helloworld” program above. They start off filled with random bytes. Then, they interact at random, over and over. In an interaction, two randomly selected tapes are stuck end to end, and this combined 128 byte–long tape is run, potentially modifying itself. The 64 byte–long halves are then pulled back apart and dropped back into the soup. Once in a while, a byte value is randomized, as cosmic rays do to DNA.</p><p>Since bff has only 7 instructions (represented by the characters “&lt;&gt;+−,[]”) and there are 256 possible byte values, following random initialization only 7/256, or 2.7%, of the bytes in a given tape will contain valid instructions; any non-instructions are simply skipped over.<span id="ft-33" class="reference"> <sup class="footnote-ref">33</sup> </span>Thus, at first, not much comes of interactions between tapes. Once in a while, a valid instruction will modify a byte, and this modification will persist in the soup. On average, though, only a couple of computational operations take place per interaction, and usually, they have no effect. In other words, while any kind of computation is theoretically <em>possible</em> in this toy universe, precious little of it actually takes place—at first. Random mutation may alter a byte here and there. Even when a valid instruction causes a byte to change, though, the alteration is arbitrary and purposeless.</p><p>But after millions of interactions, something magical happens: the tapes begin to reproduce! As they spawn copies of themselves and each other, randomness quickly gives way to complex order. The amount of computation taking place in each interaction skyrockets, since—remember—reproduction requires computation. Two of Brainfuck’s seven instructions (“[” and “]”) are dedicated to conditional branching, and define loops in the code; reproduction requires at least one such loop (“copy bytes until done”), causing the number of instructions executed in an interaction to climb into the thousands.</p><p>The code is no longer random, but obviously <em>purposive</em>, in the sense that its function can be analyzed and reverse-engineered. An unlucky mutation can break it, rendering it unable to reproduce. Over time, the code evolves clever strategies to increase its robustness to such damage.</p><p>This emergence of function and purpose is just like what we see in organic life at every scale; it’s why we’re able to talk about the function of the circulatory system, a kidney, or a mitochondrion, and how they can “fail”—even though nobody designed these systems.</p><p>We reproduced our basic result with a variety of other programming languages and environments. Alex (of neural cellular automata renown) created another beautiful mashup, this time between cellular automata and bff. Each of a 200×200 array of “pixels” contains a program tape, and interactions occur only between neighboring tapes on the grid. In a nod to our nerdy childhoods, the tapes are interpreted as instructions for the iconic Zilog Z80 microprocessor, launched in 1976 and used in many 8-bit computers over the years (including the Sinclair ZX Spectrum, Osborne 1, and TRS-80). Here, too, complex replicators soon emerge from random interactions, evolving and spreading across the grid in successive waves.</p><p>Our simulations suggest that, in general, life arises spontaneously whenever conditions permit. Those conditions seem minimal: little more than a physical environment capable of supporting computation, some randomness, and enough time.</p><p>Let’s pause and take stock of why this is so remarkable.</p><p>On an intuitive level, one doesn’t expect function or purposiveness to emerge spontaneously. To be sure, we’ve known for a long time that a modest degree of <em>order</em> can emerge from initially random conditions; for instance, the lapping of waves can approximately sort the sand on a beach, creating a gradient from fine to coarse. But if we were to begin with sand on a beach subject to random wave action, and came back after a few hours to find a poem written there, or the sand grains fused into a complex electronic circuit, we would assume someone was messing with us.</p><p>The extreme improbability of complex order arising spontaneously is generally understood to follow from thermodynamics, the branch of physics concerned with the statistical behavior of matter subject to random thermal fluctuations—that is, of all matter, since above absolute zero, <em>everything</em> is subject to such randomness. Matter subject to random forces is supposed to become more random, not less. Yet by growing, reproducing, evolving, and indeed by existing at all, life seems to violate this principle.</p><p>The violation is only apparent, for life requires an input of free energy, allowing the forces of entropy to be kept at bay. Still, the seemingly spontaneous emergence and “complexification” of living systems has appeared to be, if not strictly disallowed by physical laws, at least unexplained by them. That’s why the great physicist Erwin Schrödinger (1887–1961) wrote, in an influential little book he published in 1944 entitled <em>What Is Life?</em>,<span id="ft-34" class="reference"> <sup class="footnote-ref">34</sup></span></p><p>“[L]iving matter, while not eluding the ‘laws of physics’ as established up to date, is likely to involve ‘other laws of physics’ hitherto unknown, which, however, once they have been revealed, will form just as integral a part of this science as the former.”</p><h2>Thermodynamics</h2><p><strong>Before turning to those “other laws of physics,” it’s helpful to take a closer look at the original ones, and especially the Second Law of thermodynamics.</strong></p><p>These are deep waters. While the fundamental ideas date back to the groundbreaking work of nineteenth-century mathematical physicist Ludwig Boltzmann (1844–1906), we can understand their essence without math. Nonetheless, Boltzmann’s conceptually challenging ideas flummoxed many of his fellow scientists, and their implications continue to stir controversy even today. Much has been made of Einstein turning our everyday notions of space and time inside-out with his theory of relativity, developed in its initial form in 1905—just a year before Boltzmann, struggling with bipolar disorder, ended his own life. Arguably, though, Boltzmann’s earlier ideas disrupt our intuitions about time, cause, and effect even more radically than Einstein’s theory of relativity.<span id="ft-35" class="reference"> <sup class="footnote-ref">35</sup> </span>Let’s dive in.</p><p>The Second Law of thermodynamics holds that any closed system will rise in entropy over time, becoming increasingly disordered. A hand-powered lawn mower, for example, starts off as a beautifully polished machine with sharp helical blades, round wheels, and toothed gears, all coupled together on smoothly rotating bearings. If left out in the elements, the bearings will seize up, the blades will dull, and oxidation will set in. After enough time, only a heap of rust will remain.</p><p>Similarly, if you were to take a dead bacterium (which, though a lot smaller, is far more complicated than a push mower) and drop it into a beaker of water, its cell membrane would eventually degrade, its various parts would spill out, and after a while only simple molecules would remain, dispersed uniformly throughout the beaker.</p><p>The Second Law gives time its arrow, because the fundamental laws of physics in our universe are very nearly time-reversible.<span id="ft-36" class="reference"> <sup class="footnote-ref">36</sup> </span>Strange, but true: Newton’s equations (classical dynamics), Maxwell’s equations (electromagnetism), Schrödinger’s equations (quantum physics), Einstein’s equations (special and general relativity)—all of these physical laws would work the same way if time ran in reverse. The difference between the past and the future is <em>statistical</em>.</p><p>Here’s a common undergraduate thought experiment to illustrate this point in the case of Newtonian dynamics. Imagine video footage of balls on a billiard table, all in random positions and moving in random directions. They will collide with one another and with the bumpers at the edge of the table, bouncing off at new angles. If we (unrealistically) assume frictionless motion and fully elastic collisions (i.e., balls don’t slow down as they roll, and none of the collision energy is dissipated as heat), this would go on forever. The summed momenta and summed energies of the balls will remain constant—and it will be impossible to tell whether you’re watching the video forward or in reverse. In such a universe, causality has no meaning, because nothing distinguishes causes from effects.</p><p>If the initial conditions were random, then the positions of the balls will continue to be randomly distributed over the table’s surface as they all bounce around, transferring some of their energy to each other with every collision. It would be astronomically unlikely for the balls to all bunch up in one spot. Their velocities, too, will be randomly distributed, both in direction and magnitude, so it would also be astronomically unlikely for them to, for instance, suddenly all be moving precisely parallel to the table’s edges. Complete disorder, in other words, is a stable equilibrium.<span id="ft-37" class="reference"> <sup class="footnote-ref">37</sup> </span>In the presence of any thermal noise (that is, random perturbation), it is the <em>only</em> stable equilibrium.</p><p>Suppose, though, that the near-impossible happens. You see fifteen of the balls converge into a perfect, stock-still triangular grid, each ball just touching its neighbors, while the cue ball, having absorbed all of the combined kinetic energy of the other fifteen, whizzes away from the triangle. Aha! Now, we know that we’re watching a pool break—and we know that we’re watching it <em>in reverse</em>. The arrow of time has been established. Along with it, we have causation: the triangle broke <em>because</em> it was hit by the cue ball.</p><p>Theoretically, nothing prevents the exact series of collisions from happening that would result in all of the energy being transferred to a single ball while leaving the others arrayed in a perfect triangle; but statistically, it’s vanishingly unlikely for such an ordered state to arise out of disorder—unless, perhaps, some mastermind set the balls in motion just <em>so</em>.</p><p>Although key thermodynamic concepts weren’t developed until the nineteenth century, an Enlightenment-era belief in a God who set the universe in motion just so arises intuitively from the apparent impossibility of order arising spontaneously out of disorder.<span id="ft-38" class="reference"> <sup class="footnote-ref">38</sup> </span>In a mechanical, billiard-table universe where the laws of physics are inviolable and the laws of statistics seem to inexorably degrade any pre-existing order over time, it seems absurd that anything as complicated as life <em>could</em> arise spontaneously without some supernatural agent acting as “prime mover.” Only a God with exquisite foresight could have “initialized” the Big Bang such that, in the Earth’s oceans billions of years ago, simple organic molecules floating around apparently at random could coalesce into a working bacterium—an improbability many, many orders of magnitude less likely than fifteen out of sixteen whizzing billiard balls spontaneously coalescing into an unmoving triangle.</p><p>The billiard ball universe I’ve just described may seem abstract or arbitrary, but nineteenth-century theorists like Boltzmann had become interested in this problem for the most practical of reasons: it was the physics behind steam power, hence the entire Industrial Revolution. Engineering had preceded theory, as it often does.</p><p>Thomas Newcomen (1664–1729), an English inventor and Baptist lay preacher, devised the first practical fuel-burning engine in 1712. It was based on a heating-and-cooling cycle. First, steam from a boiler was allowed to flow into a cylindrical chamber, raising a piston; then, the steam valve closed, and a second valve opened, injecting a jet of cold water, causing the steam to condense and pull the piston back down. As the piston rose and fell, it rocked a giant beam back and forth, which, in Newcomen’s original design, was used to pump water out of flooded mines (which, in turn, supplied the coal these engines would soon be consuming so voraciously).</p><p>Scottish inventor and entrepreneur James Watt (1736–1819) greatly improved the steam engine design in 1776, making it a practical replacement for human and animal power across a wide range of applications. This was when the Industrial Revolution really got underway; for the first time, human-made machines began to <em>metabolize</em> on a large scale, “eating” complex organic molecules to perform mechanical work.</p><p>Soon, far more energy would be flowing through this artificial metabolism than through the Krebs cycle in our own bodies.<span id="ft-39" class="reference"> <sup class="footnote-ref">39</sup> </span>It was, in the broad sense I’ve been using in this book, a major evolutionary transition: a symbiogenetic event between humans and machines, like earlier symbioses between humans and draft animals. Machine metabolism allowed human society to explode from its pre-industrial scale (about one billion people in 1800, most of whom lived in extreme poverty) to its scale today (eight billion, most of whom no longer live in poverty).<span id="ft-40" class="reference"> <sup class="footnote-ref">40</sup> </span>In the process, we’ve become nearly as dependent on machines for our continued existence as they are on us.</p><p>However, even as coal-powered engines transformed the Victorian landscape—both figuratively and literally, for the pollution was dire—nobody understood them at a deep level. What <em>was</em> heat, and how could it be converted into physical work? For a time, the leading theory held that heat was a kind of invisible, weightless fluid, “caloric,” that could flow spookily into and through other matter.</p><p>By combining Newtonian physics, statistical calculations, and experimental tests, Boltzmann and his colleagues figured out what was really going on. Their conceptual setup was a three-dimensional version of the billiard table, in which the balls were gas molecules whizzing around in a pressurized chamber, bouncing off its walls. Calculating the average effect of all the bouncing led to the Ideal Gas Law, which established theoretical relationships between the pressure, volume, and temperature of a gas. The theory closely matched observations by experimentalists and engineers.<span id="ft-41" class="reference"> <sup class="footnote-ref">41</sup></span></p><p>Volume is straightforward (that’s just the size of the chamber), but the idea that pressure is the aggregate force on the chamber’s walls as molecules bounce off them, and that temperature is the average kinetic energy<span id="ft-42" class="reference"> <sup class="footnote-ref">42</sup> </span>of those whizzing molecules, was a profound insight. There was no need for any mysterious “caloric” fluid; heat was just motion on a microscopic scale. And the tendency toward a random distribution of molecular positions and momenta explains why, if you open a valve between two chambers containing gas at different pressures and/or temperatures, those pressures and temperatures will quickly equalize.</p><p>Before moving beyond classical thermodynamics, let’s add a bit more realism to our billiard-ball universe. We know that balls bouncing around a billiard table don’t <em>actually</em> go on bouncing forever. They encounter friction, slowing down as they roll. And when they bounce off each other, the collisions are slightly “inelastic,” meaning that after the collision, they’re moving a bit slower than before. After a little while, they stop rolling.</p><p>How can that be? At a microscopic level, the laws of physics are reversible. Momentum is supposed to be conserved. And the amount of matter and energy also remains constant, whether we run time forward or in reverse. That’s the <em>First</em> Law of thermodynamics!</p><p>Zooming in will reveal that, on a real billiard table, balls aren’t the smallest elements that bump against one other. Each billiard ball consists of lots of vibrating molecules bound together, and collisions between these individual molecules are what really cause the balls to bounce off each other—or, for that matter, cause a ball to roll across the felt rather than falling right through it.<span id="ft-43" class="reference"> <sup class="footnote-ref">43</sup> </span>In each case, momentum is transferred between molecules. Every time this happens, the distribution of molecular momenta becomes a bit more random, that is, a bit less correlated with which ball the molecule happens to be in, or indeed whether it is in a ball at all, or in the felt underneath.</p><p>In the most random distribution of molecular velocities, there would be no more correlation between the velocities of two molecules in one ball than in the velocities of molecules in different balls. Every ball would be imperceptibly jiggling in place, with each of its constituent molecules contributing minutely to the dance. We call that random jiggling “heat.” When all correlated motion has been converted into uniformly distributed heat, we’ve reached a stable equilibrium.</p><p>While the balls are still rolling, the correlations between the velocities of their molecules are by no means all equal; the distribution is far from random. This is <em>not</em> a stable equilibrium. Hence, the inevitability of friction and the inelasticity of collisions are statistical phenomena—just more symptoms of the inexorable Second Law.</p><p>Going forward, then, we can zoom back out and imagine once more that the billiard balls are indivisible particles, not bound collections of molecules. In that case, all collisions would have to be elastic, all motion frictionless, and disordered, randomly colliding balls would be the equilibrium.</p><p>Once a system has reached equilibrium, it will stay that way forever—an end state Lord Kelvin called “heat death.”<span id="ft-44" class="reference"> <sup class="footnote-ref">44</sup> </span>This seemingly trivial observation has some profound consequences. One is that the arrow of time will lose its meaning; any two consecutive moments <em>A</em>, <em>B</em> could just as likely have been ordered <em>B</em>, <em>A</em>. Nothing, therefore, can be said to be a cause, versus an effect.</p><p>Relatedly, no <em>work</em> can be done. If the system were out of equilibrium—for instance, if all of the whizzing balls were on one side of the billiard table—then we could put a movable barrier down between the empty and occupied sides, attached to a loaded crankshaft. As they bounce around, the balls would then nudge the barrier, doing work. What I’ve just described is, of course, a piston, like that of a steam engine.</p><p>But if the balls were equally likely to be anywhere, then no matter how fast they whizz and bounce, there’s nowhere to put the barrier that would result in any net force. The piston wouldn’t move because it would be buffeted equally from all sides. This idea can be generalized: work can only be done by a system in disequilibrium, for instance, when the pressure or temperature is high in one place, and low in another. That’s why Newcomen’s engine needed both hot steam <em>and</em> cold water.</p><p>I’ve already used the term <em>free energy</em>, but now we can define it. The free energy of a system is the amount of work it can be made to do. Far from equilibrium, when the entropy is low, much of the kinetic energy in the billiard balls is “free”; it can be used to move pistons, raise weights, produce electric currents, carry out computations, or drive metabolic processes. But at equilibrium, the entropy is maximized, and the free energy is zero. This insight into the relationship between energy, entropy, and work lies at the heart of thermodynamics—and life.</p><h2>Dynamic stability</h2><p><strong>Recall that life seemed deeply weird to Schrödinger because living things appear to violate the Second Law.</strong> If the bacterium we drop into a beaker of water is alive rather than dead, and free energy is available in a form the bacterium can use, and the water contains simple molecules suitable for building more bacteria, then over time we will see the very opposite of an increase in disorder. After a while, the beaker will be <em>full</em> of bacteria, reproducing, cooperating, and competing with each other.</p><p>They will even be evolving. If the beaker is sufficiently large—the size of a planet, for instance—and we wait a few billion years, then eventually beings as complicated as us may be in there, along with cities, advanced technologies, and perhaps plans to colonize the next beaker.</p><p>None of these processes can occur without free energy. For us, it comes, ultimately, from the sun. Thermodynamics tells us that even if the Second Law appears to be violated locally, it still holds when we zoom out. Order created in one place comes at the expense of increased disorder elsewhere. Hence, pollution, the finite lifetime of the sun, and the eventual heat death of the universe.</p><p>What concerns us here isn’t this big picture, but its apparent local violations, and the way they seem to become increasingly transgressive over time. The puzzle isn’t only that bacteria exist, but that the more time passes, the more complex life on Earth seems to become: from prokaryotes to eukaryotes; from eukaryotes to multicellular animals; from simple multicellular animals to ones with nervous systems; from brainy animals to complex societies; from horses and plows to space travel and AI.</p><p>Is there any general principle behind that complexification process, a kind of “however” or “yes, and” to the dismal Second Law? And could it account not only for evolution and complexification, but also for abiogenesis?</p><p>Yes, and yes. Bff can offer us a highly simplified model system for understanding that principle, just as an idealized billiard table gives us a model for understanding basic thermodynamics.</p><p>Replicators arise in bff because an entity that reproduces is more “dynamically stable” than one that doesn’t. In other words, if we start with one tape that <em>can</em> reproduce and one that <em>can’t</em>, then at some later time we’re likely to find many copies of the one that can reproduce, but we’re unlikely to find the other at all, because it will have been degraded by noise or overwritten.</p><p>Addy Pross, a professor emeritus of chemistry at Ben Gurion University of the Negev, describes the same phenomenon using the bulkier phrase “dynamic kinetic stability” (DKS).<span id="ft-45" class="reference"> <sup class="footnote-ref">45</sup> </span>I’ll drop “kinetic,” since the idea also applies beyond Pross’s field of “chemical kinetics” (describing the rates at which chemical reactions take place). In bff, for example, dynamic stability can just as well apply to programs or program fragments.</p><p>As Pross points out, a population of molecules capable of replicating can be more stable than even the hardiest of passive materials. A passive object may be fragile, like a soap bubble, or robust, like a stone sculpture. The sculpture might endure for longer, but, in the end, it’s still ephemeral. Every encounter it has with anything else in the world will cause its composition or structure to degrade, its individual identity to blur. For a sculpture, it’s all downhill. That’s the Second Law at work, as usual.</p><p>A self-reproducing molecule—like the DNA inside a living bacterium—is another matter. It is thermodynamically fragile, especially if we consider its identity to consist not only of a general structure but of a long sequence of specific nucleotides. However, its <em>pattern</em> is not just robust, but “antifragile.”<span id="ft-46" class="reference"> <sup class="footnote-ref">46</sup> </span>As long as DNA is able to reproduce—an inherently dynamic process—that pattern can last, essentially, forever. A bit of environmental stress or adversity can even help DNA maintain or improve its functionality. This is how order overcomes disorder.</p><p>In fact, Darwinian selection is <em>equivalent</em> to the Second Law, once we expand our notion of stability to include populations of replicators. Through a thermodynamic lens, Darwin’s central observation was that a more effective replicator is more stable than a less effective one. As Pross puts it,</p><p>“[M]atter […] tends to become transformed […] from less stable to more stable forms. […] [T]hat is what chemical kinetics and thermodynamics is all about […]. And what is the central law that governs such transformations? The Second Law. […] In both [the static and kinetic] worlds chemical systems tend to become transformed into more stable ones […]—thermodynamic stability in the ‘regular’ chemical world, dynamic kinetic stability in the replicator world.”<span id="ft-47" class="reference"> <sup class="footnote-ref">47</sup></span></p><p>As a chemist, Pross is sensitive to the close relationships between energy, entropy, and stability, whether static or dynamic. However, he does not explicitly make a connection to the theory of computing.</p><p>It now seems clear that by unifying thermodynamics with the theory of computation, we should be able to understand life as the predictable outcome of a statistical process, rather than regarding it uneasily as technically permitted, yet mysterious. Our artificial life experiments demonstrate that, when computation is possible, it will be a “dynamical attractor,” since replicating entities are more dynamically stable than non-replicating ones; and, as von Neumann showed, replicators are inherently computational.</p><p>Bff has no concept of energy, but in our universe, replicators require an energy source. This is because, in general, computation involves irreversible steps—otherwise known as causes and effects—and thus, computing consumes free energy. That’s why the chips in our computers draw power and generate heat when they run. (And why my computer heats up when it runs bff.) Life must draw power and generate heat for the same reason: it is inherently computational.</p><h2>Complexification</h2><p><strong>When we pick a tape out of the bff soup after millions of interactions, once replicators have taken over, we often see a level of complexity in the program on that tape that seems unnecessarily—even implausibly—high.</strong> A working replicator <em>could</em> consist of just a handful of instructions in a single loop, requiring a couple of hundred operations to run. Instead, we often see instructions filling up a majority of the 64 bytes, multiple and complex nested loops, and thousands of operations per interaction.</p><p>Where did all this complexity come from? It certainly doesn’t look like the result of simple Darwinian selection operating on the random text generated by a proverbial million monkeys typing on a million typewriters.<span id="ft-48" class="reference"> <sup class="footnote-ref">48</sup> </span>In fact, such complexity emerges even with <em>zero</em> random mutation—that is, given only the initial randomness in the soup, which works out to fewer bytes than the text of this short book. Hardly a million monkeys—and far too few random bytes to contain more than a few consecutive instructions, let alone a whole working program.</p><p>The answer recalls Lynn Margulis’s great insight: the central role of symbiosis in evolution, rather than random mutation and selection. When we look carefully at the quiescent period before tapes begin replicating, we notice a steady rise in the amount of computation taking place. We are observing the rapid emergence of <em>imperfect</em> replicators—very short bits of code that, in one way or another, have some nonzero probability of generating more code. Even if the code produced is not like the original, it’s still code, and <em>only</em> code can produce more code; non-code can’t produce anything!</p><p>Thus, a selection process is at work from the very beginning, wherein code begets code. This inherently creative, self-catalyzing process is far more important than random mutation in generating novelty. When bits of proliferating code combine to form a replicator, it’s a symbiotic event: by working together, these bits of code generate more code than they could separately, and the code <em>they</em> generate will in turn produce <em>more</em> code that does the same, eventually leading to whole-tape replication and an exponential takeoff.</p><p>A closer look at the bff soup prior to the exponential takeoff reveals distinct phases of “pre-life,” which might have had close analogs during abiogenesis on Earth. In the first phase, individual instructions occasionally generate another individual instruction, but this is more akin to a simple chemical reaction than to any real computation; the instructions are not acting as part of any larger program.</p><p>In the second phase, we begin to see instructions in particular positions, or in particular combinations, that are likelier to lead to copies of themselves than one would expect by random chance, albeit often in indirect ways. “Autocatalytic sets” start to form: cycles of dynamical interactions that mutually reinforce each other. These, too, can arise spontaneously in the chemical world, and have long been theorized to have driven abiogenesis.<span id="ft-49" class="reference"> <sup class="footnote-ref">49</sup></span></p><p>At this point, with autocatalytic fragments of code proliferating and colliding, a leap becomes possible that brings us beyond the world of digital chemistry and into the world of real computation: the emergence of the first true replicators. These are no longer mere autocatalytic sets, but short programs that copy themselves, or each other, using looped instructions.</p><p>With this leap to computation comes an enormous upgrade in evolvability, because now, any change made to a program that doesn’t break its copy loop will be heritable. Thus, classical Darwinian selection can kick in, allowing adaptation to a changing environment or speciation for occupying diverse niches. If we insist on making a distinction between non-life and life, this might be a reasonable place to draw that line.</p><p>However, these earliest replicating programs are unlikely to cleanly copy a whole tape. Often, they only copy short stretches of tape, which may get pasted into arbitrary locations, yielding unpredictable results. As these scrappy, fragmentary replicators proliferate, the bff soup enters a chaotic phase. Despite the churn, the tapes have not, at this point, resolved into any obvious structure. To the naked eye, they still <em>look</em> like random junk, although the rising amount of computation taking place (as measured both by the average number of operations per interaction and the density of instructions per tape) suggests that <em>something</em> is afoot.</p><p>Tracking the provenance of every byte in the soup, starting from random initialization, can make sense of the apparent chaos. At first, almost every byte of every tape remains whatever it was at initialization time; if we draw a line from each byte’s current position on a tape to its original source position, the lines will all extend back to time zero in parallel, like the warp threads of a loom. Once in a while, a byte will change, cutting a thread, or get copied, pulling it across the other threads diagonally.</p><p>With the rise of scrappy replicating programs, all remaining dependencies on the past are quickly cut as replicators copy over each other in a frenzy of creative destruction. Any given byte might get copied hundreds of times to a series of different tape locations, in the process wiping out whatever had been there before. Shortly afterward, all of those copies might get wiped out in turn by some other more efficiently replicating fragment. Soon, every byte’s history becomes very brief in time, yet complex in space—a short-lived snarl of sideways jumps. The loom becomes all weft, and no warp.</p><p>Are these scrappy replicators competing or cooperating? Both. Replicators that can’t keep up are wiped out, along with any non-replicating bytes. Surviving replicators, on the other hand, continually form chimeras,<span id="ft-50" class="reference"> <sup class="footnote-ref">50</sup> </span>recombining with <em>other</em> replicators (or even copies of themselves) to become more effective still. These are, once more, symbiogenetic events: sub-entities merging to form a larger, more capable super-entity.</p><p>This chaotic phase is such a potent crucible for directed evolution that it generally doesn’t last long. It rapidly produces a robust whole-tape replicator, which then takes off exponentially, resulting in the dramatic transition to organized structure (and large amounts of computation) that are bff’s most obvious feature. This is when artificial life <em>seems</em> to spontaneously emerge.</p><p>But as we can now appreciate, there’s nothing spontaneous about it. Replicators had been there all along, and each larger replicator is composed of smaller ones—an inverted tree of life, consisting of mergers over time rather than splits.</p><p>However, evolution’s creative work is not done yet. After the takeoff of a fully functional tape replicator, we often see yet further symbiotic events. From a classical Darwinian standpoint, this seems puzzling, since there should be no reason for further evolution to take place once whole tapes are replicating reliably. How could “fitness” possibly improve further, once a tape copies itself in its entirety every time it interacts with another tape?</p><p>We must consider that since the instructions for whole-tape replication don’t occupy all 64 bytes, there’s extra space on the tape that could be dedicated to … anything. That’s the point of von Neumann–style replication—it allows for open-ended evolution precisely because the tape can contain additional information, beyond the code needed for replication itself.<span id="ft-51" class="reference"> <sup class="footnote-ref">51</sup></span></p><p>Any extra replicated bytes could, of course, be random—just passive, purposeless information cargo hitchhiking from one generation to the next. But if these bytes contain instructions, those instructions can run. And if they can run, they can replicate <em>themselves</em>, too. Thus, the symbiogenetic process can continue to operate, creating additional replicators <em>within</em> an already replicating tape. Sometimes these sub-replicators even produce multiple copies of themselves in a single interaction.</p><p>Sub-replicators can interact with their host in many ways. They can “kill” the host by damaging <em>its</em> replication code, which is generally catastrophic for the sub-replicator, as it thereby destroys the environment within which it can run. Sub-replicators can be neutral, leaving the host’s replication machinery alone. Or, they can be symbiotic, for instance by conferring resistance to mutational damage via redundant copying of the host’s code. The overall tendency is toward symbiosis, since that is the most dynamically stable.</p><p>Over time, code colonizes a large proportion of the 64 bytes. Code is more dynamically stable than non-code, and its dynamic stability increases through symbiosis with yet more code—in particular, when code fragments find ways to work in functional tandem.</p><p>In a way, symbiosis is the very essence of functionality. When we talk about a kidney’s function only making sense <em>in context</em>, we mean that it is in symbiosis with other functions—like those of the liver (breaking ammonia down into urea), the heart (pumping blood), and so on. Each of these functions is <em>purposive</em> precisely because its inputs are the outputs of others, its outputs are inputs to others, and thus they form a network of dynamically stable cycles.</p><p>The same is true of larger, planetary-scale interrelationships. The “purpose” of plants, from the perspective of animal life, is to produce oxygen and sugar, which we breathe and eat. The “purpose” of animals, from a plant’s perspective, is to turn the oxygen back into carbon dioxide, and provide compost and pollination. Our growing understanding of life as a self-reinforcing dynamical process boils down not to <em>things</em>, but to networks of mutually beneficial <em>relationships</em>. At every scale, life is an ecology of functions.</p><p>Because functions can be expressed computationally, we could also say that life is code, and code is life. Individual computational instructions are the irreducible quanta of life—the minimal replicating set of entities, however immaterial and abstract they may seem, that come together to form bigger, more stable, and more complex replicators, in ever-ascending symbiotic cascades.</p><p>In the toy universe of bff, the elementary instructions are the seven special characters “&lt;&gt;+−,[]”. On the primordial sea floor, geothermally-driven chemical reactions that could catalyze further chemical reactions likely played the same role. Under other conditions, on another planet, or in another universe, many different elementary interactions could do the same—as long as they are Turing complete, enabling them to make the leap from autocatalytic sets to true replication.</p><h2>Virality</h2><p><strong>Although bff is only a toy universe, it can serve as a simplified model for life and evolution, just as a Newtonian billiard-ball universe can serve as a simplified model for the thermodynamics of ideal gases.</strong> As we’ve seen, some of bff’s predictions are quite different from those of classical Darwinian theory:</p><ol><li>Bff suggests that symbiogenesis is a more important driver of evolutionary innovation than random mutation.</li><li>Since symbiogenesis must involve combinations of pre-existing dynamically stable entities, we should expect complex replicating entities to emerge after (and be made of) simpler ones.</li><li>As a result, zooming in on sub-replicators within a larger replicator should allow us to peer back in evolutionary time.<span id="ft-52" class="reference"> <sup class="footnote-ref">52</sup></span></li></ol><p>These phenomena should sound familiar! They’re all consistent with Lynn Margulis’s observations, which flew in the face of twentieth-century biological orthodoxy, but are now, if not mainstream, at least gaining respectability.</p><p>But wait, there’s more:</p><ol start="4"><li>Due to the instability of the imperfect replicators leading up to the first true replicator, we should expect this first true replicator to be a historical “event horizon,” becoming the template for what follows and erasing independent traces of what came before.</li></ol><p>This is what we see on Earth too. Although the first chemical steps toward proto-life may still be taking place in environments like black smokers, we don’t see the missing links. Where are the kind of imperfect replicators that fused together to form the simplest life forms today?</p><p>We likely don’t see them on their own because, as in bff, their instability made them ephemeral, quickly displaced or absorbed by the first stably replicating cell—which might already have been recognizably kin to today’s bacteria and archaea. (Evolutionary biologists call this the “Last Universal Common Ancestor” or LUCA.) Still, we can assume that many of the component <em>parts</em> of the most ancient surviving life forms—like the reverse Krebs cycle and RNA replication—are fossilized fragments of earlier imperfect replicators.</p><p>In the same vein:</p><ol start="5"><li>Evolved code should not only include instructions for replicating itself as a whole, but also be rife with sub-sequences that contain instructions for independently replicating <em>them</em>selves.</li><li>If symbiosis among these parts generated the novelty driving evolution of the whole, we should see evidence in the genome of many “broken” or incomplete sub-replicators.</li><li>Code that evolved through such hierarchical symbiotic replication should also contain many sequences that are repetitive, or are copies of other parts.</li></ol><p>We can find all of these features in our own genetic code—and they don’t correspond to what we would expect to see if our genomes had evolved primarily through mutation and selection.</p><p>When the first complete human genome sequence was published in 2000, some surprises were in store.<span id="ft-53" class="reference"> <sup class="footnote-ref">53</sup> </span>One was the astonishingly high proportion of so-called “junk DNA” that doesn’t code for proteins: about 98%. How did it get there? Is it actually <em>doing</em> anything? We now understand that some of this “junk” is involved in gene regulation, but most is still of unknown or uncertain function. Close inspection reveals, though, that much of our code, whether “junk” or otherwise, is … <em>viral</em>.</p><p>The reproductive cycle of viruses is an often-told story. When traveling between cells, a virus looks like a bit of DNA or RNA packaged into a protein “envelope” capable of binding to a target cell and injecting its genetic payload. Once inside the cell, the viral code hijacks cellular resources to begin replicating, both copying its genetic material and manufacturing its envelope proteins. These assemble into more viruses. Maniacally cranking out viral proteins, the cell may eventually burst, releasing a flood of virus particles to repeat the cycle.</p><p>“Retroviruses” like HIV (the Human Immunodeficiency Virus, which causes AIDS) include additional “reverse transcription” machinery for permanently incorporating their genetic material into the cell’s DNA. This makes them a lot harder for the host to clear. The key enzyme, “reverse transcriptase,” wasn’t characterized until 1970,<span id="ft-54" class="reference"> <sup class="footnote-ref">54</sup> </span>but Barbara McClintock (1902–1992), working at Cold Spring Harbor Lab on Long Island, had made an earlier discovery that turned out to be closely related.</p><p>While studying the genetics of maize plants in the late 1940s and early ’50s, McClintock found mobile segments of DNA that seemed to be able to cut and paste themselves into different locations on the genome, producing differently mottled color patterns in corn kernels.<span id="ft-55" class="reference"> <sup class="footnote-ref">55</sup> </span>Although many of her colleagues were initially skeptical about these “transposons” or “jumping genes,” McClintock eventually won the Nobel Prize for this work.</p><p>A much wider zoo of “transposable elements” has since been discovered, some of which don’t just “cut and paste,” but “copy and paste” themselves; they are, in effect, replicators <em>within</em> our DNA. In fact, some of them are fully fledged retroviruses, including instructions not only for splicing their code into a host cell’s genome, but also for envelope proteins, allowing that code to venture out into the world in search of other cells to infect.</p><p>Retroviruses are unsettlingly … <em>intimate</em>. HIV specifically targets immune cells, but if a retrovirus infects an egg or sperm cell, it can insert its code into an organism’s germ line, becoming a permanent part not only of that cell, but of an entire species. In a 2006 publication in the prestigious journal <em>Nature</em>, researchers at the University of Queensland in Australia reported catching a retrovirus in this act of becoming “endogenous” for the first time.<span id="ft-56" class="reference"> <sup class="footnote-ref">56</sup> </span>An epidemic of leukemia in koalas had first been traced to a retrovirus, then this retrovirus was found to have invaded the koala germ line over the previous century, causing the disease to become heritable.</p><p>Does this mean the end of koalas? Probably not.</p><p>The human genome is rife with signs that the same process has taken place many times in the history of our own species. At least 8% of our genome consists of endogenized retroviruses, the remnants of such retroviral invasions.<span id="ft-57" class="reference"> <sup class="footnote-ref">57</sup> </span>Remember, 8% is several times more DNA than codes for our “own” genes!</p><p>We usually think of viruses as mere disease agents, opportunistically parasitizing our cells to reproduce, since they have no reproductive machinery of their own. The reality may be very different, though. As many of us know from our recent experience with COVID,<span id="ft-58" class="reference"> <sup class="footnote-ref">58</sup> </span>viruses (and pathogens in general) tend to evolve into forms less lethal to their hosts over time, for obvious reasons—a dead host is a dead end for the pathogen, too. There’s mounting evidence that the relationship between virus and host can go even further, to become symbiotic. Retroviral code in our genome, for instance, has become fundamental to the formation of the placenta, the immune system, cell differentiation, and brain function.<span id="ft-59" class="reference"> <sup class="footnote-ref">59</sup></span></p><p>Moreover, endogenous retroviruses are only the tip of an even larger iceberg. Nearly half of our genome consists of transposable elements of one kind or another. Some were probably once retroviruses, or vice versa. Fully sequenced genomes are often rife with lengthy stretches of highly repetitive sequences, from long and complex to mere alternations of two or three symbols—evidence of sub-replicators running amok.</p><p>Our genomes, in other words, are not only reproduced as a whole, but include working reproductive sub-sequences at many scales. Some are new and can still cause disease; others are older and may have lost the ability to make viral envelopes or the other machinery needed to become infectious; and yet others have integrated themselves so deeply into our own code that they are no longer distinct. Some of this code is even serving critical functions in our bodies. It’s obvious that, at least by this last stage of the process, complete symbiosis has been established: neither the host nor the sub-replicator could survive, let alone reproduce, on its own.</p><p>In his 2009 book <em>Virolution</em>,<span id="ft-60" class="reference"> <sup class="footnote-ref">60</sup> </span>author and physician Frank Ryan goes further, arguing that viruses may have been symbionts all along. Plague viruses like HIV don’t come from nowhere; they are species jumpers. We know that HIV was originally SIV, the Simian Immunodeficiency Virus, variants of which are endemic to Old World primates including African green monkeys, sooty mangabeys, mandrills, and chimpanzees. Yet many of these viruses don’t sicken their original hosts.<span id="ft-61" class="reference"> <sup class="footnote-ref">61</sup></span></p><p>We also know that if a virus finds itself inside an organism whose physiology is <em>too</em> different from that of its original host, it can’t gain purchase—a lucky thing for you, if you’ve ever swallowed a mouthful of seawater, which likely contained about a billion virus particles! (Most would have targeted single-celled marine life.) The greatest danger seems to come from viruses adapted to a different but closely related species. Perhaps, when it kills, such a virus is doing its job: wiping out rivals who have invaded the original host’s territory.</p><p>Viruses could, in other words, work like an out-of-body immune system. Within our bodies, our immune systems seek out and destroy cells that are recognized as “not-us.” Outside our bodies, “our” viruses could be similarly seeking out and destroying whole animals who are recognized as “not-us.” Once a virus becomes endemic to a new population, though—even if it initially kills many—it will differentiate, co-adapt, and perhaps eventually go native.</p><p>One could consider bacterial pathogens through a similar lens; hence the well-documented plagues of smallpox that European colonists brought to the Americas, decimating Native populations, and the virulent (though less deadly) syphilis epidemic believed to have been brought back to Europe by Columbus.<span id="ft-62" class="reference"> <sup class="footnote-ref">62</sup> </span>Unlike bacteria, though, retroviruses don’t just take up residence in our environment or in our bodies, but fuse into our very genomes, becoming inextricably part of us—especially when they alter the germ line.</p><p>By sheer volume, our DNA appears to be made primarily of the layered remnants of many such past fusions. It seems clear that transposable elements and “endogenous viral elements” or EVEs have done much more editing of our genome in recent evolutionary history than mutation has.<span id="ft-63" class="reference"> <sup class="footnote-ref">63</sup> </span>And they have been at this for a long, long time. Based on the best available evidence, viruses are at least as old as the Last Universal Common Ancestor, if not older.<span id="ft-64" class="reference"> <sup class="footnote-ref">64</sup></span></p><p>This ongoing ecology of mobile, self-reproducing, and even infectious genes causes the supposed “tree of life” to continue entangling with itself in the oddest ways. Fully a quarter of the cow genome, for instance, consists of copies of the retrotransposon BovB. BovB appears to have leapt many times between species to create a phylogenetic tree of its own, a “bizarre parallel universe where cows are more closely related to snakes than to elephants, and where one gecko is more closely related to horses than to other lizards.”<span id="ft-65" class="reference"> <sup class="footnote-ref">65</sup> </span>These are instances of “horizontal gene transfer” (HGT), long associated with bacteria, but clearly more universal.<span id="ft-66" class="reference"> <sup class="footnote-ref">66</sup></span></p><p>Whether a bit of new DNA is acting in the moment as friend, foe, or somewhere in between is really just a matter of where on the symbiotic trajectory it falls. When brand new, it’s unlikely to be friendly. But if it has persisted for a long time, and especially if it has become endogenous, its dynamic stability implies that it will have become non-lethal or even friendly due to combined evolutionary pressures on host, invader, and “host plus invader” as a “holobiont” or symbiotically fused entity. When some gene or other functionality in the fused code proves valuable to the larger whole, that functionality will be conserved, even as the sub-replicator’s reproductive capability degrades and eventually vanishes. Perhaps that is how new genetic functionality arises in general.</p><p>In this light, random point mutation can even be seen as something like a minimal abiogenesis event, creating a tiny parasitic “life form” within the genome. On its own, it would of course be unable to reproduce, since it possesses no independent reproductive machinery;<span id="ft-67" class="reference"> <sup class="footnote-ref">67</sup> </span>then again, neither does a virus. So, like a virus, a mutation <em>can</em> reproduce—using the host’s resources, which will copy it along with everything else. When introduced into the genome of a sophisticated existing organism, such a tiny, random entity is unlikely to be friendly, though, as with any larger invasion, it will either kill its host (and itself, in the bargain) or achieve dynamic stability, either by being neutral or (occasionally) helpful.</p><p>Hence, just as replicator thermodynamics encompasses classical thermodynamics as a special case, evolution via symbiogenesis can encompass classical Darwinian theory as a special case. Point mutation is unlikely to be the main driver of evolution once life has taken off because it’s so much weaker and slower on its own than higher-order symbiogenesis. Unlike point mutation, a chunk of code that has already circulated, jumping around in the genome or even between species, isn’t random. It necessarily includes real functionality. And at least in some settings, that functionality has been under evolutionary pressure to help, or at least not kill, its host. Evolution picks up steam over time, with major evolutionary transitions becoming more frequent precisely because increasingly high orders of symbiogenesis become possible.</p><h2>Compression</h2><p>When code evolves through symbiogenesis, it will develop a curious statistical structure: parts of it will be copies (or near-copies) of other parts, and as those parts establish symbiosis, they’ll form a larger aggregate which will <em>also</em> copy itself as a unit. This is reminiscent of (though not the same as) a “fractal”: a structure that resembles itself at a cascade of ever-finer scales. Let’s take a short detour through fractals and their relationship to biology so that we can then consider the implications of evolution <em>itself</em> exhibiting certain fractal-like properties.</p><p>French-American mathematician Benoit Mandelbrot (1924–2010) is the figure most associated with fractals, though they were first described by English meteorologist Lewis Fry Richardson (1881–1953). In the aftermath of World War II, Richardson, a Quaker, had been trying to build a mathematical model to predict the likelihood of conflicts between countries. One of the parameters in his model was the length of their common border. He was perplexed to find, though, that certain borders didn’t appear to have agreed-upon lengths. The Portuguese, for instance, reported that their border with Spain was 613 miles long, but the Spanish claimed that it was 754 miles long. This seemed like a weirdly large discrepancy for what ought to have been an easily surveyed distance!</p><p>Richardson eventually figured out what was going on: the Spanish were using a higher-resolution map. Every twist and turn the Portuguese could see in the Minho, Douro, and Guadiana rivers separating the countries had finer-scale twists and turns only visible on the Spanish map. Richardson showed that, if zooming in on any given meandering revealed more meanderings, the total length of a “self-similar” curve like a coastline or a river can grow without limit as one measures it with an ever-smaller ruler.<span id="ft-68" class="reference"> <sup class="footnote-ref">68</sup></span></p><p>“Fractal geometry” is thus very different from the Euclidean geometry we all learned in school, where the length of a line or curve is well-defined and doesn’t blow up when you zoom in. Of course, in real life, one can’t zoom in forever, but fractals are still important mathematical tools for understanding structures that are self-similar over a range of scales, like rivers and coastlines.</p><p>Living organisms exhibit obvious fractal properties in certain of their structures, such as tree branches, bronchial tubes, and circulatory systems. In structures like these, fractal geometry over some range of scales offers an elegant design solution to a biophysical problem. For instance, blood carrying oxygen and nutrients needs to reach every cell in the body, which means that oxygenated blood has to be pumped through a branching network of tubes, and these tubes—which are, in Euclidean terms, one-dimensional—have to repeatedly subdivide to “fill” three-dimensional space. Hence, we have fractally branching (and then merging) networks of arteries, arterioles, capillaries, venules, and veins.</p><p>By working out the design properties of such fractal networks and their implications, theoretical physicist Geoffrey West and his collaborators at the Santa Fe Institute have figured out many fundamental “scaling laws” in biology.<span id="ft-69" class="reference"> <sup class="footnote-ref">69</sup> </span>One of the most well-known results from this body of work explains why every mammalian heart will beat about 1.5−2 billion times over a lifetime, whether it belongs to an Etruscan shrew (weighing a twentieth of an ounce, and living a year or so), or a blue whale (weighing over 300,000 pounds, and living about a century).</p><p>Self-similarity in general yields “power law” scaling relationships, which look like straight lines when plotted on logarithmic axes.<span id="ft-70" class="reference"> <sup class="footnote-ref">70</sup> </span>Body mass, for instance, has power-law relationships with metabolic rate, the total length of the circulatory system, and lifespan.<span id="ft-71" class="reference"> <sup class="footnote-ref">71</sup> </span>Combining various power-law relationships to calculate the number of heartbeats in a lifetime causes all the scaling variables to cancel out beautifully, yielding the famous 1.5−2 billion beat constant. While the theory is not exact (humans, for example, live somewhat longer than predicted), it does a remarkable job of parsimoniously explaining a wide range of phenomena.</p><p>Is life in general a kind of fractal, then? No. A rhyme by British mathematician Augustus De Morgan<span id="ft-72" class="reference"> <sup class="footnote-ref">72</sup> </span>is often invoked in describing fractals:</p><p><em>Great fleas have little fleas upon their backs to bite ’em,</em><br><em>And little fleas have lesser fleas, and so</em> ad infinitum*.*<span id="ft-73" class="reference"> <sup class="footnote-ref">73</sup></span></p><p>The poem is funny precisely because it is absurd: unlike an idealized fractal coastline, living systems are, in general, profoundly <em>dis</em>similar across scales.<span id="ft-74" class="reference"> <sup class="footnote-ref">74</sup> </span>While there are rare instances of the kind De Morgan describes—such as hyperparasitoid wasps, tiny parasites that lay their eggs inside bigger wasps—one does not generally zoom in on a flea to discover a smaller flea, let alone <em>ad infinitum</em>.</p><p>Indeed, even coastlines are best characterized, in real life, as “multifractals”: systems with repetitive structure at every scale, but variability <em>across</em> scales.<span id="ft-75" class="reference"> <sup class="footnote-ref">75</sup> </span>As a result, their power laws may also vary. For instance, zooming in twofold at one level of magnification, where the ruggedness is especially pronounced, might cause the apparent length to scale up by 21.5≈2.83, while zooming in twofold at a magnification where the coastline appears smoother might only cause the apparent length to scale up by 21.16≈2.24. Every bump has bumps on it, but the bumps at one scale are shaped differently from the bumps at another.<span id="ft-76" class="reference"> <sup class="footnote-ref">76</sup></span></p><p>Similarly, although genomes are always replicated, and are made out of other genomes that are themselves replicated, every whole is different from its parts, just as an integrated circuit is different from a transistor. How, then, would one go about quantifying this multifractal-like property in a genome?</p><p>The answer is closely related to data compression. Consider bff. In its initial state, the tapes consist of random bytes; no repetitive structure exists. If we were reading through the tapes one byte at a time, the next byte would have an equal probability of assuming any value, from 0 to 255, independent of any of the previous bytes. Therefore, the sequence is entirely unpredictable, which means that if you were to try compressing the soup with file compression software, like ZIP, the compressor wouldn’t be able to squeeze the file size at all. (This is, harkening back to thermodynamics, a working definition of a completely disordered state.)</p><p>Data are redundant—that is, compressible—precisely to the degree that they are predictable, or, equivalently, exhibit order. Compression algorithms like those in ZIP work by looking for patterns in the data stream so far and exploiting those patterns to encode subsequent data using as few bits as possible. The usual trick is to incrementally build a dictionary or “phrase book” out of the source material, and to substitute sections of the text for pointers into this dictionary whenever the pointer can be encoded in fewer bits than the original text. The dictionary is, in effect, a predictive model, and since the compressor builds that model incrementally as it compresses, the decompressor is able to incrementally reconstruct an identical copy of the model as it <em>de</em>compresses.</p><p>Absent any prior knowledge about how to model a long sequence, describing it in terms of previously encountered parts of itself is a good strategy. The full text of this book ZIPs down to about 35% of its original size as a raw text string, since some letters occur more often than others, there are a lot of repeated words, and those words often combine into stock phrases.<span id="ft-77" class="reference"> <sup class="footnote-ref">77</sup></span></p><p>When bff undergoes its sharp transition to whole-tape replication, the tapes suddenly become highly compressible; they squeeze down to just 5% of their original size. Interestingly, many regions of the human genome are highly compressible too. The reason these data streams compress so well is that, at any given point in the sequence, one can often make a pretty good guess as to what the next letter will be, simply by looking for the longest previous sequence that matches the current context.</p><p>Such matches arise due to replication. In the human genome, we’re not talking about replication at the level of the individual, but, rather, at the level of transposable elements (or their fossil remnants) <em>within</em> our genome. Similarly, even a <em>single</em> bff tape is highly compressible, because it formed through a symbiotic fusion of smaller replicators … and these replicators are themselves likely to be either copies of each other or related, having formed out of yet smaller imperfect replicators … which are themselves either copies or related.</p><p>Like fractals, sequences of symbols constructed by repeatedly copying sub-sequences of all lengths exhibit power-law scaling—in this case, between the lengths of repeated sequences and their frequency. For instance, a replicated sequence twice the length of another might be found half as often—which is pretty often! (These statistics would be dramatically different for random sequences, where increasing the sequence length would cause a much faster <em>exponential</em> decline in expected frequency.<span id="ft-78" class="reference"> <sup class="footnote-ref">78</sup> </span>) Sequences constructed according to a fixed self-copying rule are, in a sense, infinitely compressible, for they contain only as much information as it would take to write down the recipe, no matter how long the sequence.</p><p>By contrast, in a complex replicating system like bff—let alone the genome—the <em>way</em> any particular set of replicating sub-sequences combine to form a larger replicating sequence will always be specific. It will depend on the functional particulars of how those parts come together to make a working whole. Therefore there is novelty, or information, in each such combination. However, that information will be much less than would be needed to specify an arbitrary symbol sequence of the same length.</p><p>When we look for this property in bff and in human genome data, that’s just what we find! Not only do both compress very well; they also compress better and better the longer the stream of data gets. For instance, a single bff tape compresses somewhat, but the whole soup compresses better, and as the size of the soup grows, the compression ratio continues to improve—though no matter how much has already been seen, the remainder is never fully predictable.</p><p>Similarly, while a single stretch of a human genome already compresses well, the whole genome compresses better. If you compress it in the statistical context of many other human genomes, so much of the information becomes redundant that a compressed version of <em>your</em> genome would be small enough to send as an email attachment.<span id="ft-79" class="reference"> <sup class="footnote-ref">79</sup> </span>The pattern continues if we zoom yet farther out to consider genomes across species. Hence the famous statistic that the human genome is 98% identical to the chimpanzee genome … and 60% similar to that of the fruit fly!</p><p>While common ancestry alone can explain many of the similarities across species (though not all, as BovB illustrates), such classical Darwinian arguments can’t explain why the genome of a single individual is also so repetitive. That only makes sense when we begin to consider genomes to be <em>made out of</em> smaller genomes.</p><p>DNA and bff tapes, in other words, are both systems that evolve through what we could call “multifractal symbiosis.” Our genomes are aggregates of cooperating replicators, all the way down. That’s why they are so compressible. But it’s also why wonderful new kinds of complexity emerge at every scale—and therefore why, in biology, we can always learn something new by zooming in or out.</p><h2>Embodiment</h2><p>There’s a profound yet subtle relationship between the multifractal properties of our bodies and the multifractal properties of the genome.</p><p>The relationship is subtle because the genetic code is by no means a one-to-one blueprint explicitly representing the body’s final shape. One might imagine, for instance, that because a snake has hundreds of ribs, it might have a stretch of DNA coding for a vertebra and rib pair, which might have replicated itself a few hundred times in the snake’s genome. Could snakes be the result of a retrotransposon coding for ribs run wild, like BovB?</p><p>Not exactly. So-called “Hox” genes, shared widely among animals, control overall body plan, and they “execute” their program using a combination of gene regulation and the kind of distributed computation Turing described in his work on morphogenesis. During embryonic development, ribs begin as a chemically controlled spatial oscillation, like the stripes of a tiger.</p><p>This mechanism is vastly more powerful, general, and evolvable than merely replicating some “build a rib” code. It allows for code reuse, just as a programmer would do: invoking the same “build a rib” function a hundred times instead of copying and pasting it a hundred times. Thus, tweaking rib flexibility or curvature involves making one change, not a hundred.</p><p>Evolution can produce real programs that reuse code because life is computational. Remember that if you’re a replicator of the kind von Neumann described, you need to contain instructions for building yourself, including a machine B to copy those instructions, and a machine A, the “universal constructor,” to follow them. The universal constructor is the engine not only of reproduction, but also of growth, development, healing, and maintenance. It created your circulatory system and skin during embryonic development; it also heals your skin and replaces the torn capillaries underneath when you get a cut. As long as you are alive, your body will be continuously constructing and reconstructing itself. The code never stops running.</p><p>And since a universal constructor is a kind of Universal Turing Machine, its computations, or equivalently mathematical functions, are inherently “compositional”: complex functions (or programs) can be made out of sub-functions, which can in turn be made out of sub-sub functions … until, at bottom, everything could be expressed in terms of the elementary instructions of a Turing machine.</p><p>Functions can even be made out of <em>themselves</em>. In computer science, this is known as “recursion.” The Fibonacci sequence, for example—1, 1, 2, 3, 5, 8, 13, 21, and so on, where each number is the sum of the previous two—is most easily expressed as the recursive function <em>f</em>(<em>n</em>)=<em>f</em>(<em>n</em>−1)+<em>f</em>(<em>n</em>−2) for numbers greater than 1, with f(0)=f(1)=1. We find Fibonacci numbers in biology all the time, as in the spiral pattern of a pine cone, the head of a sunflower, and the chambers of a nautilus. This is a clue that recursive computation takes place in the construction of pine trees, sunflowers, and nautiluses.<span id="ft-80" class="reference"> <sup class="footnote-ref">80</sup></span></p><p>The smoking gun, though, is the growth of self-similar structures in the body. Compositionality and recursion are what allow genetic code to build a many-tiered fractal like the circulatory system. Code for building ribs or nautilus segments could, in theory, just be copied a couple of hundred times, but that’s not possible for arteries, veins, or capillaries, where the number of segments and branches becomes astronomically large. The blood vessel branching code <em>must</em> get reused. And with relatively minor tweaks, it must be possible for the parameters of that code to be adjusted so that the branching stops at the appropriate size for a shrew, or goes on to construct something the size of a blue whale, since shrews and whales are, in the grand scheme of things, close relatives.</p><p>From an evolutionary perspective, compositionality implies a hierarchical network of symbiotic relationships. The bacteria that became mitochondria and the archaea that engulfed them each started with the code necessary to reproduce themselves. When they merged into a eukaryote, they still needed to retain the instructions for their own reproduction, but they also needed to evolve additional functionality for mutual regulation. When eukaryotes became multicellular, the same needed to happen again; our cells still know how to reproduce individually, and, indeed, cellular reproduction is a fundamental operation involved in the larger-scale growth and reproduction of a whole animal.</p><p>What is true of evolution is also true of development.<span id="ft-81" class="reference"> <sup class="footnote-ref">81</sup> </span>Blood vessels, for instance, aren’t just Euclidean line segments, but tubes made of layers of smooth muscle cells. Each of those cells contains a complement of organelles, and each mitochondrion in each of those cells contains its own membranes and loop of bacterial DNA. A living organism is a compositional structure <em>par excellence</em>. It could only be built computationally, through the composition of many functions. And life could only have evolved as the hierarchical composition of those functions—that is, through symbiogenesis.</p><h2>Élan vital</h2><p>Nowadays, we interact with human-engineered (or, one could say, “artificial”) computers constantly: the phones in our pockets and purses, our laptops and tablets, data centers and AI models. We’ve begun asking whether AI models are intelligent. We could ask an even more jarring question: are computers, whether they’re running AI or not, <em>alive</em>?<span id="ft-82" class="reference"> <sup class="footnote-ref">82</sup></span></p><p>They are certainly purposive, or we couldn’t talk about them being broken or buggy. But hardware and software are, in general, unable to reproduce, grow, heal, or evolve on their own, because engineers learned long ago that self-modifying code (like bff, or DNA) is hard to understand and debug.<span id="ft-83" class="reference"> <sup class="footnote-ref">83</sup> </span>Thus, phones don’t make baby phones. Apps don’t write new versions of themselves.</p><p>And yet: there are more phones in the world this year than last year; apps acquire new features, become obsolete, and eventually reach end-of-life, replaced by new ones; and AI models are improving from month to month. Electronic components and computer code also exhibit the same kind of compositionality we’ve seen in bff and DNA. It certainly <em>looks</em> as if technology is reproducing and evolving! Debating its aliveness is thus a bit like the debate over whether viruses (which also can’t reproduce on their own) are alive.</p><p>If we zoom out, though, putting technology and humans in the frame together, we can see that this larger, symbiotic “us” is certainly reproducing, growing, and evolving. The emergence of technology, and the mutually beneficial—if sometimes fraught—relationship between people and tech is nothing more or less than our own most recent major evolutionary transition. Technology, then, is not distinct from nature or biology, but merely its most recent evolutionary layer.</p><p>And what about that age-old inanimate stuff—rocks and rivers, mountains and beaches, clouds and storms? Water molecules in themselves are clearly not capable of general computation, and yet, in the context of the hydrologic cycle, clouds, rainstorms, and rivers certainly serve critical ecological functions, and are profoundly shaped by life. Likewise, our planet’s metal and sand get shaped into steam engines and computer chips. All of these are part of that grand network of interdependency we call Earth. Why do we draw boundaries around certain networks of functions and insist that they are “alive,” while the surrounding functions are not?</p><p>This way lies vitalism, a view espoused in various forms by a long line of philosophers from Posidonius of Apameia (circa 135–51 BCE, and undoubtedly reflecting a much older tradition) to Henri Bergson (1859–1941). Some modern thinkers, too, defend the vitalist position, such as Jane Bennett:</p><p>“The quarantines of matter and life encourage us to ignore the vitality of matter and the lively powers <em>of</em> material formations […]. By ‘vitality’ I mean the capacity of things—edibles, commodities, storms, metals—not only to impede or block the will and designs of humans but also to act as quasi agents or forces with trajectories […] or tendencies of their own. [… Our] analyses of political events might change if we gave the force of things more due.”<span id="ft-84" class="reference"> <sup class="footnote-ref">84</sup></span></p><p>We resist such ideas because we tend to reserve the notion of agency only for ourselves. The idea of agency in a molecule or a storm, let alone an abstraction like money, seems especially far-fetched. We also tend to think in terms of a hierarchy in which “we” (for whatever value of “we”) are at the top, and agency must surely diminish for anything “lower”—a view reminiscent of the medieval Great Chain of Being. When we (hesitantly) extend “agency” to the nonhuman, we tend to do so only for things that act obviously, individually, and on fast timescales, rather than in the aggregate and on slower, more evolutionary ones. It might be time to re-examine these ideas more holistically.</p><p>My purpose here is not to follow in Bennett’s footsteps—though I do find her project worth taking seriously. Language is, necessarily, imprecise, no matter what definitions we pick. This doesn’t mean that words are useless, though. When our language can become more rigorous and scientifically grounded, and when we use it to describe patterns across a wide range of phenomena, we can start to see through ideological thickets.</p><p>I hope I have explained both clearly and rigorously how the phenomena that give rise to the complexifying dynamics of life apply much more broadly than to the entities we normally think of as “alive” or “agential.” Accordingly, we could expand our definitions of these existing words, or adopt new ones, or do a bit of each. Personally, I would find some broadening of the old everyday words helpful.</p><p>That would hardly break new ground. Many traditional, nominally “prescientific” worldviews embrace notions of aliveness, agency, and even personhood that are far broader than the modern Western ones. This seems a likely case of convergent evolution in languages and ideas, motivated by the common need among traditional societies to take symbiosis seriously to secure their own survival, and to flourish. It’s practical as much as it is spiritual: encouraging richer modeling of agency in “nature” enhances a society’s dynamic stability, since all things in “nature,” ourselves included, are so mutually interdependent.</p><p>Thus it can be useful to take the view of an animal, plant, or river at times, even if they can’t take ours, the better to care for them—and for ourselves. That, ultimately, is the best reason to consider adopting, or at least adapting, a more inclusive view of the animate. Potawatomi writer and biologist Robin Wall Kimmerer makes this case eloquently in her book <em>Braiding Sweetgrass</em>.<span id="ft-85" class="reference"> <sup class="footnote-ref">85</sup></span></p><p>In agreeing with Kimmerer, I am not encouraging superstition. When scientists castigate animist beliefs as superstitious, they typically appeal to the materialist discoveries of the Enlightenment, which show that the atoms that make up our bodies are no different from the atoms that make up rocks or air. This is true. Atoms are atoms; they all obey the same rules. Hence, the Enlightenment model of a clockwork universe, governed by dynamical laws.</p><p>Yet as Schrödinger pointed out in 1944, our understanding of these laws—which he played such a central role in developing—remains incomplete. The laws as they stand do not account for the complex, dynamically stable, symbiotic phenomena that comprise so much of our experience on Earth—indeed, without which there would be no such thing as experience at all. There would be no life, or purpose, or minds, or agency.</p><p>As we both embrace scientific rigor <em>and</em> start to figure out those “‘other laws of physics’ hitherto unknown,”<span id="ft-86" class="reference"> <sup class="footnote-ref">86</sup> </span>we should perhaps be less surprised to find the shoe on the other foot. What the poet Dylan Thomas called “the force that through the green fuse drives the flower”<span id="ft-87" class="reference"> <sup class="footnote-ref">87</sup> </span>drives all atoms, not just the ones we presume to be alive.</p><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p><a href="https://paperpile.com/c/iA68kr/KeRZH">W. Thomson 1871</a>.</p></li><li id="fn2" class="footnote-item"><p><a href="https://paperpile.com/c/iA68kr/mjXk">Peretó, Bada, and Lazcano 2009</a>.</p></li><li id="fn3" class="footnote-item"><p><a href="https://paperpile.com/c/iA68kr/yCQl">Robertson and Joyce 2012</a>.</p></li><li id="fn4" class="footnote-item"><p><a href="https://paperpile.com/c/iA68kr/vG3ML+AvAZX">M. J. Russell and Martin 2004; Shapiro 2006</a>.</p></li><li id="fn5" class="footnote-item"><p>Remember, from chemistry class, that since hydrogen (H) consists of a single proton bound to a single electron, a positively charged hydrogen ion with its electron stripped off (H+) is just a proton. When proton concentration varies over space, the ensuing flow of ions generates an electric current.</p></li><li id="fn6" class="footnote-item"><p><a href="https://paperpile.com/c/iA68kr/OQoN">Krebs and Johnson 1937</a>. Krebs won the Nobel Prize in Medicine for this work in 1953.</p></li><li id="fn7" class="footnote-item"><p><a href="https://paperpile.com/c/iA68kr/6Webi">M. C. Evans, Buchanan, and Arnon 1966</a>.</p></li><li id="fn8" class="footnote-item"><p><a href="https://paperpile.com/c/iA68kr/bUcj">Buchanan and Arnon 1990</a>.</p></li><li id="fn9" class="footnote-item"><p>Today, a great majority of the organic fuel consumed by respiration in animals and fungi comes from plants, which fix carbon using photosynthesis instead of the more ancient reverse Krebs cycle.</p></li><li id="fn10" class="footnote-item"><p><a href="https://paperpile.com/c/iA68kr/4Bpe">Szathmáry and Smith 1995</a>. The somewhat narrower term “evolutionary transitions in individuality” (ETI) is also increasingly used; <a href="https://paperpile.com/c/iA68kr/whidv">Michod 2000</a>.</p></li><li id="fn11" class="footnote-item"><p><a href="https://paperpile.com/c/iA68kr/9gWb">Sagan 1967</a>.</p></li><li id="fn12" class="footnote-item"><p><a href="https://paperpile.com/c/iA68kr/cn45T">Woese 2002</a>. In this book, I’ll use the terms <em>symbiosis</em> and <em>symbiogenesis</em> in broader ways than most biologists do, to include cooperation and eventual interdependence among entities of all kinds—in the spirit of molecular biologists who have framed the origins of life as symbiosis among “molecules in mutualism,” per <a href="https://paperpile.com/c/iA68kr/InvYL">Lanier, Petrov, and Williams 2017</a>.</p></li><li id="fn13" class="footnote-item"><p><a href="https://paperpile.com/c/iA68kr/ibxL6+kAEHP">Konstantinidis, Ramette, and Tiedje 2006; Murray, Gao, and Wu 2021</a>.</p></li><li id="fn14" class="footnote-item"><p><a href="https://paperpile.com/c/iA68kr/9ayP">Raup and Gould 1974</a>.</p></li><li id="fn15" class="footnote-item"><p>In some cases, like the car versus the horse and buggy, or photosynthesis versus the reverse Krebs cycle, a new technology crowds out an old one due to greater efficiency; however, even here, the crowding-out is often not total. There are still a few horses and buggies, and a few organisms using the reverse Krebs cycle.</p></li><li id="fn16" class="footnote-item"><p><a href="https://paperpile.com/c/iA68kr/UXGk">Turing 1937</a>.</p></li><li id="fn17" class="footnote-item"><p>Technically, a Turing Machine, whether universal or not, must always be able to increase its tape size if needed, while real computers have fixed storage limits—but for most purposes, close enough.</p></li><li id="fn18" class="footnote-item"><p><a href="https://paperpile.com/c/iA68kr/gWChD">von Neumann 1945</a>.</p></li><li id="fn19" class="footnote-item"><p>Both died young, Turing in 1954, at age 41, and von Neumann in 1957, aged 53.</p></li><li id="fn20" class="footnote-item"><p><a href="https://paperpile.com/c/iA68kr/V4x6k">Turing 1952</a>.</p></li><li id="fn21" class="footnote-item"><p>Many years later, German molecular biologist Christiane Nüsslein-Volhard identified the first real-life morphogen, the “Bicoid” protein, which forms a gradient along the fruit fly embryo to establish its segmented body plan. She won the Nobel Prize for this discovery, alongside Eric Wieschaus and Edward Lewis, in 1995.</p></li><li id="fn22" class="footnote-item"><p><a href="https://paperpile.com/c/iA68kr/IHY2">von Neumann and Burks 1966</a>.</p></li><li id="fn23" class="footnote-item"><p>In a more abstract form, mathematician Stephen Kleene had proven this result years earlier, a result known today as Kleene’s Second Recursion Theorem; <a href="https://paperpile.com/c/iA68kr/1Bz5A">Kleene 1938</a>.</p></li><li id="fn24" class="footnote-item"><p>I’m using the term “complex” here in a colloquial sense; according to at least one technical definition (Kolmogorov complexity), if the instructions within the “simple” entity fully describe how to make the “more complex” one, they are actually of equal complexity.</p></li><li id="fn25" class="footnote-item"><p><a href="https://paperpile.com/c/iA68kr/SdytD">J. D. Watson and Crick 1953</a>.</p></li><li id="fn26" class="footnote-item"><p>While reversible computing is known to be theoretically possible, and has attracted some renewed interest in recent years because of its relevance to quantum computing, it remains largely unexplored.</p></li><li id="fn27" class="footnote-item"><p><a href="https://paperpile.com/c/iA68kr/ldIO">Turing [1951] 2000</a>.</p></li><li id="fn28" class="footnote-item"><p><a href="https://paperpile.com/c/iA68kr/Mm2N">Turing 1948</a>. Infants’ brains are of course not random. Turing was right to believe, though, that randomness plays a major role in their initial “wiring”; subsequent learning and development strengthens some connections, while pruning many others.</p></li><li id="fn29" class="footnote-item"><p><a href="https://paperpile.com/c/iA68kr/DFeC">Pesavento 1995</a>.</p></li><li id="fn30" class="footnote-item"><p><a href="https://paperpile.com/c/iA68kr/LqxTg">Mordvintsev et al. 2020</a>.</p></li><li id="fn31" class="footnote-item"><p><a href="https://paperpile.com/c/iA68kr/YhhO">Agüera y Arcas et al. 2024</a>. This work draws inspiration from classic work in ALife, especially <a href="https://paperpile.com/c/iA68kr/Ce2be+Nv0EV+tpImY+Tk1GR">Barricelli 1957; Fontana 1990; Ray 1991; Adami and Brown 1994</a>.</p></li><li id="fn32" class="footnote-item"><p>Decrementing 0 wraps around to 255, the largest possible value for a byte, and incrementing 255 wraps around to 0.</p></li><li id="fn33" class="footnote-item"><p>You might have noticed that the original Brainfuck had 8 instructions, including “.” for “print” and “,” for “input.” Bff uses only “,” because instead of reading and writing to an external terminal or console, the tape reads and writes to <em>itself</em>. Thus only a single instruction is needed for copying a byte from one location to another. In our first paper describing bff, we included instructions “{” and “}” for moving the console pointer, but a stripped-down alternative, used here, simply initializes the data and console pointers with the first two bytes on the tape.</p></li><li id="fn34" class="footnote-item"><p><a href="https://paperpile.com/c/iA68kr/QJ1x">Schrödinger 1944</a>.</p></li><li id="fn35" class="footnote-item"><p><a href="https://paperpile.com/c/iA68kr/bIc8+TAXx">H. Reichenbach 1956; Rovelli 2018</a>.</p></li><li id="fn36" class="footnote-item"><p>The “very nearly” qualifier arises from the deep mathematical structure of relativistic quantum mechanics. A number of near-symmetries in physics, such as between positive or negative charge, left or right-handedness, and time reversal, are not quite exact in quantum field theory, though according to the CPT theorem—the letters stand for charge, parity, time—reversing all three at once <em>does</em> yield an exact symmetry.</p></li><li id="fn37" class="footnote-item"><p>For the moment, I’m sidestepping a direct definition of the term <em>disorder</em> and its apparent subjectivity (is my desk disorderly or does it reflect an order only I can see?), but we will soon return to the central role of a <em>model</em> in distinguishing order from disorder; this is the link connecting thermodynamics to information theory.</p></li><li id="fn38" class="footnote-item"><p>The development of clocks and other complex machines in the Middle Ages set the scene, per <a href="https://paperpile.com/c/iA68kr/oYTi9">Prigogine and Stengers 1984</a>: “The clock world is a metaphor suggestive of God the Watchmaker, the rational master of a robot-like nature.” Newtonian dynamics reinforced the idea that the universe’s dynamics were deterministic and knowable, hence “robot-like.”</p></li><li id="fn39" class="footnote-item"><p><a href="https://paperpile.com/c/iA68kr/HBgLR">Smil 2008</a>.</p></li><li id="fn40" class="footnote-item"><p><a href="https://paperpile.com/c/iA68kr/GiVr">Agüera y Arcas 2023</a>.</p></li><li id="fn41" class="footnote-item"><p><em>PV</em>=<em>nRT</em>, where <em>P</em> is pressure, <em>V</em> is volume, <em>T</em> is temperature, <em>n</em> is the number of gas molecules or billiard balls, and <em>R</em> is the “ideal gas constant.”</p></li><li id="fn42" class="footnote-item"><p>Kinetic energy is proportional to the mass and squared velocity of the molecules.</p></li><li id="fn43" class="footnote-item"><p>More precisely, these are repulsive interactions between the electron orbitals of the molecules.</p></li><li id="fn44" class="footnote-item"><p><a href="https://paperpile.com/c/iA68kr/YsZqS">W. Thomson 1857</a>.</p></li><li id="fn45" class="footnote-item"><p><a href="https://paperpile.com/c/iA68kr/KbJa">Pross 2012</a>.</p></li><li id="fn46" class="footnote-item"><p><a href="https://paperpile.com/c/iA68kr/frW7X">Taleb 2014</a>.</p></li><li id="fn47" class="footnote-item"><p>In the language of dynamical systems theory, this asserts that thermodynamic stability is a fixed point, while DKS is a limit cycle.</p></li><li id="fn48" class="footnote-item"><p><a href="https://paperpile.com/c/iA68kr/lJery">Dawkins 1986</a>.</p></li><li id="fn49" class="footnote-item"><p><a href="https://paperpile.com/c/iA68kr/jYBPm">Kauffman 1971</a>.</p></li><li id="fn50" class="footnote-item"><p>In classical mythology, chimeras are “unnatural” combinations of animals—for instance, a fusion of lion, goat, and snake. As we’ll see, they aren’t so unnatural after all.</p></li><li id="fn51" class="footnote-item"><p><a href="https://paperpile.com/c/iA68kr/6w5g3">Yinusa and Nehaniv 2011</a>.</p></li><li id="fn52" class="footnote-item"><p>This is not an absolute rule, since new parts can also evolve within an existing whole.</p></li><li id="fn53" class="footnote-item"><p><a href="https://paperpile.com/c/iA68kr/R6hu8">Lander et al. 2001</a>.</p></li><li id="fn54" class="footnote-item"><p><a href="https://paperpile.com/c/iA68kr/UIlcP">Baltimore 1970</a>.</p></li><li id="fn55" class="footnote-item"><p><a href="https://paperpile.com/c/iA68kr/cZZ3">McClintock 1950</a>.</p></li><li id="fn56" class="footnote-item"><p><a href="https://paperpile.com/c/iA68kr/kirr4">Tarlinton, Meers, and Young 2006</a>.</p></li><li id="fn57" class="footnote-item"><p><a href="https://paperpile.com/c/iA68kr/RKrPj">She et al. 2022</a>.</p></li><li id="fn58" class="footnote-item"><p><a href="https://paperpile.com/c/iA68kr/lIUQI">Horita and Fukumoto 2023</a>.</p></li><li id="fn59" class="footnote-item"><p><a href="https://paperpile.com/c/iA68kr/GQNC6+hm4XE+x8eko">Chuong 2018; Bakoulis et al. 2022; Russ and Iordanskiy 2023</a>. Knocking out the “Arc” retrotransposon, likely of viral origin, renders lab mice unable to form new long-term memories, per <a href="https://paperpile.com/c/iA68kr/Fa2y">Pastuzyn et al. 2018</a>.</p></li><li id="fn60" class="footnote-item"><p><a href="https://paperpile.com/c/iA68kr/ei5zJ">Ryan 2009</a>.</p></li><li id="fn61" class="footnote-item"><p><a href="https://paperpile.com/c/iA68kr/G6DVS">Sharp and Hahn 2011</a>.</p></li><li id="fn62" class="footnote-item"><p><a href="https://paperpile.com/c/iA68kr/wa0Hc+tKp1w">Crosby 2003; Harper et al. 2008</a>.</p></li><li id="fn63" class="footnote-item"><p><a href="https://paperpile.com/c/iA68kr/Qlw2f+V6TWz">Feschotte and Gilbert 2012; Naville et al. 2016</a>.</p></li><li id="fn64" class="footnote-item"><p><a href="https://paperpile.com/c/iA68kr/EYcwr">Nasir and Caetano-Anollés 2015</a>.</p></li><li id="fn65" class="footnote-item"><p><a href="https://paperpile.com/c/iA68kr/xcbVc">Yong 2013</a>.</p></li><li id="fn66" class="footnote-item"><p>Unlike eukaryotes, prokaryotes (bacteria and archaea) have very low proportions of “junk DNA.” This is because copying and expressing DNA are energetically expensive, and prokaryotes are energy-constrained, limiting their maximum DNA length and imposing strong evolutionary pressure to rid themselves of any code that can’t pull its own weight. However, a prokaryote’s “core genome” is typically only 60–70% of the total, with the remainder varying widely among strains. (Hence two <em>E. coli</em> bacteria can be as different from each other as a human and a fruit fly!) Horizontal gene transfer via transposons, viruses, or “plasmids” (exchangeable DNA loops), enables widespread copying of code snippets among bacteria, resulting in a complex tangle of reproducing bits of code conceptually similar to that described here for eukaryotes.</p></li><li id="fn67" class="footnote-item"><p>Though earlier, we similarly considered individual bff instructions as minimal or “atomic” replicating entities.</p></li><li id="fn68" class="footnote-item"><p>Mandelbrot rediscovered and generalized these findings in the 1960s; see <a href="https://paperpile.com/c/iA68kr/DahjW">Mandelbrot 1967</a>.</p></li><li id="fn69" class="footnote-item"><p><a href="https://paperpile.com/c/iA68kr/9UFiL">West 2017</a>.</p></li><li id="fn70" class="footnote-item"><p>For the mathematically inclined: power laws relating two variables <em>x</em> and <em>y</em> take the general form <em>y</em>=<em>axb</em>.</p></li><li id="fn71" class="footnote-item"><p><a href="https://paperpile.com/c/iA68kr/EzXJC">West, Brown, and Enquist 1997</a>.</p></li><li id="fn72" class="footnote-item"><p>Incidentally, De Morgan was also computing pioneer Ada Lovelace’s math tutor. Charles Babbage conceived the Analytical Engine, a steampunk computer that, had it been built, would have predated the ENIAC by a century; Lovelace wrote presciently about the power of general-purpose computing—and arguably wrote the first computer program—in 1843.</p></li><li id="fn73" class="footnote-item"><p><a href="https://paperpile.com/c/iA68kr/Q0ucZ">De Morgan and De Morgan 1872</a>.</p></li><li id="fn74" class="footnote-item"><p><a href="https://paperpile.com/c/iA68kr/EdSgj+EqQTX">Wolpert and Macready 2007; Bagrov et al. 2020</a>.</p></li><li id="fn75" class="footnote-item"><p>This makes sense, since the underlying processes that shape coastlines differ between scales of, say, a meter, versus a kilometer; see <a href="https://paperpile.com/c/iA68kr/EuXQW">Mandelbrot 1989</a>.</p></li><li id="fn76" class="footnote-item"><p>These particular numbers correspond to the smoothest, <em>N</em>=5, and roughest, <em>N</em>=8, of Mandelbrot’s coastline diagrams in his classic 1967 paper, “How Long Is the Coast of Britain?”</p></li><li id="fn77" class="footnote-item"><p>If I were a fancier writer and used fewer stock phrases, the book wouldn’t ZIP so efficiently. Using the same compression algorithm, James Joyce’s <em>Ulysses</em> can only be squeezed down to 40% of its raw size!</p></li><li id="fn78" class="footnote-item"><p>In math: for a random string of symbols that can assume <em>K</em> values, a string of length <em>L</em> would occur with frequency <em>f</em>=<em>K</em>−<em>L</em>, while with replication occurring at all scales, string frequency scales like <em>f</em>~<em>L</em>−<em>b</em>.</p></li><li id="fn79" class="footnote-item"><p><a href="https://paperpile.com/c/iA68kr/MvA4">Christley et al. 2009</a>.</p></li><li id="fn80" class="footnote-item"><p>Recursion can’t be implemented by the ribosome on its own; I’ve used a bit of poetic license in identifying the ribosome with machine A. In reality, as morphogenesis illustrates, biological computation is more holistic and distributed.</p></li><li id="fn81" class="footnote-item"><p><a href="https://paperpile.com/c/iA68kr/dEx3p">Carroll, Grenier, and Weatherbee 2013</a>.</p></li><li id="fn82" class="footnote-item"><p><a href="https://paperpile.com/c/iA68kr/HvzD">Walker 2023</a>.</p></li><li id="fn83" class="footnote-item"><p>Computer viruses are a notable exception.</p></li><li id="fn84" class="footnote-item"><p><a href="https://paperpile.com/c/iA68kr/n4w7">J. Bennett 2010</a>.</p></li><li id="fn85" class="footnote-item"><p><a href="http://127.0.0.1:8080/c/error">[Citation error]</a>.</p></li><li id="fn86" class="footnote-item"><p><a href="https://paperpile.com/c/iA68kr/QJ1x">Schrödinger 1944</a>.</p></li><li id="fn87" class="footnote-item"><p><a href="https://paperpile.com/c/iA68kr/8yKy">Thomas 1934</a>.</p></li></ol></section></div><div id="acknowledgments"><h1>Acknowledgments</h1><p>TK</p><p>I re-encountered Dan Dennett and met Susan Bell at SFI. Sadly, Dan passed away while this project was underway.</p><p>My father, Josep Agüera i Arcas, and our dear family friend, Lesley Hazelton, died this year too. They were both great cheerleaders and sharp critics.</p></div><div id="glossary"><h1>Glossary</h1><p>TK</p></div><div id="bibliography"><h1>Bibliography</h1><p><a href="http://paperpile.com/b/iA68kr/Lfx8">Abramson, José Z., Ma Victoria Hernández-Lloreda, Lino García, Fernando Colmenares, Francisco Aboitiz, and Josep Call. 2018. “Imitation of Novel Conspecific and Human Speech Sounds in the Killer Whale (Orcinus Orca).” <em>Proceedings. Biological Sciences / The Royal Society</em> 285 (1871). https://doi.org/</a><a href="http://dx.doi.org/10.1098/rspb.2017.2171">10.1098/rspb.2017.2171</a><a href="http://paperpile.com/b/iA68kr/Lfx8">.</a><br><a href="http://paperpile.com/b/iA68kr/plqz">Achatz, Johannes G., Marta Chiodin, Willi Salvenmoser, Seth Tyler, and Pedro Martinez. 2013. “The Acoela: On Their Kind and Kinships, Especially with Nemertodermatids and Xenoturbellids (Bilateria Incertae Sedis).” <em>Organisms, Diversity &amp; Evolution</em> 13 (2): 267–86.</a><br><a href="http://paperpile.com/b/iA68kr/Tk1GR">Adami, Chris, and C. Titus Brown. 1994. “Evolutionary Learning in the 2D Artificial Life System ‘Avida.’” <em>arXiv [adap-Org]</em>. arXiv.</a> <a href="https://arxiv.org/pdf/adap-org/9405003">https://arxiv.org/pdf/adap-org/9405003</a><a href="http://paperpile.com/b/iA68kr/Tk1GR">.</a><br><a href="http://paperpile.com/b/iA68kr/nwKE">Adams, Douglas. 1979. <em>The Hitchhiker’s Guide to the Galaxy</em>. Harmony Books.</a><br><a href="http://paperpile.com/b/iA68kr/udZh">———. 1980. <em>The Restaurant at the End of the Universe</em>. Harmony Books.</a><br><a href="http://paperpile.com/b/iA68kr/eYZP">Adiwardana, Daniel, Minh-Thang Luong, David R. So, Jamie Hall, Noah Fiedel, Romal Thoppilan, Zi Yang, et al. 2020. “Towards a Human-like Open-Domain Chatbot.” <em>arXiv [cs.CL]</em>. arXiv.</a> <a href="http://arxiv.org/abs/2001.09977">http://arxiv.org/abs/2001.09977</a><a href="http://paperpile.com/b/iA68kr/eYZP">.</a><br><a href="http://paperpile.com/b/iA68kr/6RWB">Adler, Julius. 1966. “Chemotaxis in Bacteria.” <em>Science</em> 153 (3737): 708–16.</a><br><a href="http://paperpile.com/b/iA68kr/Bqe5">Adrian, E. D. 1928. “The Basis of Sensation” 122.</a> <a href="https://psycnet.apa.org/fulltext/1928-01753-000.pdf">https://psycnet.apa.org/fulltext/1928-01753-000.pdf</a><a href="http://paperpile.com/b/iA68kr/Bqe5">.</a><br><a href="http://paperpile.com/b/iA68kr/VHl8">Agostinelli, Andrea, Timo I. Denk, Zalán Borsos, Jesse Engel, Mauro Verzetti, Antoine Caillon, Qingqing Huang, et al. 2023. “MusicLM: Generating Music From Text.” <em>arXiv [cs.SD]</em>. arXiv.</a> <a href="http://arxiv.org/abs/2301.11325">http://arxiv.org/abs/2301.11325</a><a href="http://paperpile.com/b/iA68kr/VHl8">.</a><br><a href="http://paperpile.com/b/iA68kr/wHFP">Agrawal, A. K., J. S. Gans, and A. Goldfarb. 2023. “The Turing Transformation: Artificial Intelligence, Intelligence Augmentation, and Skill Premiums.”</a> <a href="https://www.nber.org/papers/w31767">https://www.nber.org/papers/w31767</a><a href="http://paperpile.com/b/iA68kr/wHFP">.</a><br><a href="http://paperpile.com/b/iA68kr/O7wP">Agüera y Arcas, Blaise. 2022. “Do Large Language Models Understand Us?” <em>Daedalus</em> 151 (May): 183–97.</a><br><a href="http://paperpile.com/b/iA68kr/GiVr">———. 2023. <em>Who Are We Now?</em> Los Angeles: Hat &amp; Beard, LLC.</a><br><a href="http://paperpile.com/b/iA68kr/YhhO">Agüera y Arcas, Blaise, Jyrki Alakuijala, James Evans, Ben Laurie, Alexander Mordvintsev, Eyvind Niklasson, Ettore Randazzo, and Luca Versari. 2024. “Computational Life: How Well-Formed, Self-Replicating Programs Emerge from Simple Interaction.” <em>arXiv [cs.NE]</em>. arXiv.</a> <a href="http://arxiv.org/abs/2406.19108">http://arxiv.org/abs/2406.19108</a><a href="http://paperpile.com/b/iA68kr/YhhO">.</a><br><a href="http://paperpile.com/b/iA68kr/ByM9">Agüera y Arcas, Blaise, Adrienne Fairhall, and William Bialek. 2000. “What Can a Single Neuron Compute?” <em>Advances in Neural Information Processing Systems</em>, 75–81.</a><br><a href="http://paperpile.com/b/iA68kr/rLYn">Agüera y Arcas, Blaise, Adrienne L. Fairhall, and William Bialek. 2003. “Computation in a Single Neuron: Hodgkin and Huxley Revisited.” <em>Neural Computation</em> 15 (8): 1715–49.</a><br><a href="http://paperpile.com/b/iA68kr/rc2J">Agüera y Arcas, Blaise, and Peter Norvig. 2023. “Artificial General Intelligence Is Already Here.” <em>Noema, October</em>.</a><br><a href="http://paperpile.com/b/iA68kr/anMq">Ahn, Luis von, Manuel Blum, Nicholas J. Hopper, and John Langford. 2003. “CAPTCHA: Using Hard AI Problems for Security.” In <em>Advances in Cryptology — EUROCRYPT 2003</em>, 294–311. Springer Berlin Heidelberg.</a><br><a href="http://paperpile.com/b/iA68kr/0KWE">Almomani, Fidaa, Murad O. Al-Momani, Soha Garadat, Safa Alqudah, Manal Kassab, Shereen Hamadneh, Grant Rauterkus, and Richard Gans. 2021. “Cognitive Functioning in Deaf Children Using Cochlear Implants.” <em>BMC Pediatrics</em> 21 (1): 71.</a><br><a href="http://paperpile.com/b/iA68kr/aPAa">Alper, Morris, and Hadar Averbuch-Elor. 2023. “Kiki or Bouba? Sound Symbolism in Vision-and-Language Models.” <em>Advances in Neural Information Processing Systems</em> abs/2310.16781 (October). https://doi.org/</a><a href="http://dx.doi.org/10.48550/arXiv.2310.16781">10.48550/arXiv.2310.16781</a><a href="http://paperpile.com/b/iA68kr/aPAa">.</a><br><a href="http://paperpile.com/b/iA68kr/dphGB">Amsterdam, B. 1972. “Mirror Self-Image Reactions before Age Two.” <em>Developmental Psychobiology</em> 5 (4): 297–305.</a><br><a href="http://paperpile.com/b/iA68kr/9WRR">Anderson, S. 2004. “How Many Languages Are There in the World.” <em>Linguistic Society of America</em>. https://doi.org/</a><a href="http://dx.doi.org/10.1093/actrade/9780199590599.003.0002">10.1093/actrade/9780199590599.003.0002</a><a href="http://paperpile.com/b/iA68kr/9WRR">.</a><br><a href="http://paperpile.com/b/iA68kr/DUCN">Artetxe, Mikel, Gorka Labaka, Eneko Agirre, and Kyunghyun Cho. 2017. “Unsupervised Neural Machine Translation.” <em>arXiv [cs.CL]</em>. arXiv.</a> <a href="http://arxiv.org/abs/1710.11041">http://arxiv.org/abs/1710.11041</a><a href="http://paperpile.com/b/iA68kr/DUCN">.</a><br><a href="http://paperpile.com/b/iA68kr/NwSe">Asimov, Isaac. 1950. <em>I, Robot</em>. Dennis Dobson.</a><br><a href="http://paperpile.com/b/iA68kr/w2vk">Athalye, Anish, Logan Engstrom, Andrew Ilyas, and Kevin Kwok. 10–15 Jul 2018. “Synthesizing Robust Adversarial Examples.” In <em>Proceedings of the 35th International Conference on Machine Learning</em>, edited by Jennifer Dy and Andreas Krause, 80:284–93. Proceedings of Machine Learning Research. PMLR.</a><br><a href="http://paperpile.com/b/iA68kr/9WeqA">Babbage, Charles. 1832. <em>On the Economy of Machinery and Manufactures</em>. C. Knight.</a><br><a href="http://paperpile.com/b/iA68kr/tRnP">———. 1864. <em>Passages from the Life of a Philosopher</em>. Longman, Green, Longman, Roberts, &amp; Green.</a><br><a href="http://paperpile.com/b/iA68kr/WoTo">Bacon, Francis. 1603. “Temporis Partus Masculus.”</a><br><a href="http://paperpile.com/b/iA68kr/HMLu">Baddeley, Alan D., and J. Graham. 1974. “HITCH. 1974. Working Memory.” <em>Psychology of Learning and Motivation</em> 8: 47–89.</a><br><a href="http://paperpile.com/b/iA68kr/EqQTX">Bagrov, Andrey A., Ilia A. Iakovlev, Askar A. Iliasov, Mikhail I. Katsnelson, and Vladimir V. Mazurenko. 2020. “Multiscale Structural Complexity of Natural Patterns.” <em>Proceedings of the National Academy of Sciences of the United States of America</em> 117 (48): 30241–51.</a><br><a href="http://paperpile.com/b/iA68kr/mZvi">Bailey, Ronald. 2003. “Pulling Our Own Strings.” Reason Magazine. May 1, 2003.</a> <a href="https://reason.com/2003/05/01/pulling-our-own-strings-2/">https://reason.com/2003/05/01/pulling-our-own-strings-2/</a><a href="http://paperpile.com/b/iA68kr/mZvi">.</a><br><a href="http://paperpile.com/b/iA68kr/hm4XE">Bakoulis, Stylianos, Robert Krautz, Nicolas Alcaraz, Marco Salvatore, and Robin Andersson. 2022. “Endogenous Retroviruses Co-Opted as Divergently Transcribed Regulatory Elements Shape the Regulatory Landscape of Embryonic Stem Cells.” <em>Nucleic Acids Research</em> 50 (4): 2111–27.</a><br><a href="http://paperpile.com/b/iA68kr/UIlcP">Baltimore, David. 1970. “Viral RNA-Dependent DNA Polymerase: RNA-Dependent DNA Polymerase in Virions of RNA Tumour Viruses.” <em>Nature</em> 226 (5252): 1209–11.</a><br><a href="http://paperpile.com/b/iA68kr/fZEl">Banay, R. S., and L. Davidoff. 1942. “Apparent Recovery of a Sex Psychopath after Lobotomy.” <em>Journal of Criminal Psychopathology</em> 4: 59–66.</a><br><a href="http://paperpile.com/b/iA68kr/GyNv">Barnum, Matt. 2024. “We Tested an AI Tutor for Kids. It Struggled With Basic Math.” <em>The Wall Street Journal</em>, February 16, 2024.</a> <a href="https://www.wsj.com/tech/ai/ai-is-tutoring-students-but-still-struggles-with-basic-math-694e76d3">https://www.wsj.com/tech/ai/ai-is-tutoring-students-but-still-struggles-with-basic-math-694e76d3</a><a href="http://paperpile.com/b/iA68kr/GyNv">.</a><br><a href="http://paperpile.com/b/iA68kr/wW3xu">Baron-Cohen, S., A. M. Leslie, and U. Frith. 1985. “Does the Autistic Child Have a ‘Theory of Mind’?” <em>Cognition</em> 21 (1): 37–46.</a><br><a href="http://paperpile.com/b/iA68kr/Ce2be">Barricelli, Nils Aall. 1957. “Symbiogenetic Evolution Processes Realized by Artificial Methods.” <em>Methodos</em> 9 (35–36): 143–82.</a><br><a href="http://paperpile.com/b/iA68kr/7UdI">Bartumeus, Frederic, Ernesto P. Raposo, Gandhimohan M. Viswanathan, and Marcos G. E. da Luz. 2014. “Stochastic Optimal Foraging: Tuning Intensive and Extensive Dynamics in Random Searches.” <em>PloS One</em> 9 (9): e106373.</a><br><a href="http://paperpile.com/b/iA68kr/ChLp">Bastani, Aaron. 2019. <em>Fully Automated Luxury Communism: A Manifesto</em>. London, England: Verso Books.</a> <a href="https://books.google.com/books?id=Qm_nDwAAQBAJ&amp;newbks=1">https://books.google.com/books?id=Qm_nDwAAQBAJ&amp;newbks=1</a><a href="http://paperpile.com/b/iA68kr/ChLp">.</a><br><a href="http://paperpile.com/b/iA68kr/YHF4">Bateson, Gregory. 1972a. “From Versailles to Cybernetics.” feineigle.com. 1972.</a> <a href="http://www.feineigle.com/book_reports/2017/versailles_to_cybernetics/GregoryBateson_FromVersaillestoCybernetics.pdf">http://www.feineigle.com/book_reports/2017/versailles_to_cybernetics/GregoryBateson_FromVersaillestoCybernetics.pdf</a><a href="http://paperpile.com/b/iA68kr/YHF4">.</a><br><a href="http://paperpile.com/b/iA68kr/gneln">———. 1972b. <em>Steps to an Ecology of Mind: Collected Essays in Anthropology, Psychiatry, Evolution, and Epistemology</em>. University of Chicago Press.</a><br><a href="http://paperpile.com/b/iA68kr/sI5J">Bekoff, Marc, Colin Allen, and Gordon M. Burghardt. 2002. <em>The Cognitive Animal: Empirical and Theoretical Perspectives on Animal Cognition</em>. MIT Press.</a><br><a href="http://paperpile.com/b/iA68kr/IAxF">Belin, Pascal. 2006. “Voice Processing in Human and Non-Human Primates.” <em>Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences</em> 361 (1476): 2091–2107.</a><br><a href="http://paperpile.com/b/iA68kr/NvAp7">Bell, J. S. 1964. “On the Einstein Podolsky Rosen Paradox.” <em>Physics</em> 1 (3): 195–200.</a><br><a href="http://paperpile.com/b/iA68kr/mze0">Bender, Emily M., Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell. 2021. “On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? 🦜.” In <em>Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency</em>, 610–23. FAccT ’21. New York, NY, USA: Association for Computing Machinery.</a><br><a href="http://paperpile.com/b/iA68kr/dS5p">Bender, Emily M., and Alexander Koller. 2020. “Climbing towards NLU: On Meaning, Form, and Understanding in the Age of Data.” In <em>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>, edited by Dan Jurafsky, Joyce Chai, Natalie Schluter, and Joel Tetreault, 5185–98. Online: Association for Computational Linguistics.</a><br><a href="http://paperpile.com/b/iA68kr/hnJl">Ben-Ishai, Guy, Jeff Dean, James Manyika, Ruth Porat, H. Varian, and Kent Walker. 2024. “AI and the Opportunity for Shared Prosperity: Lessons from the History of Technology and the Economy,” January.</a> <a href="http://arxiv.org/abs/2401.09718">http://arxiv.org/abs/2401.09718</a><a href="http://paperpile.com/b/iA68kr/hnJl">.</a><br><a href="http://paperpile.com/b/iA68kr/n4w7">Bennett, Jane. 2010. <em>Vibrant Matter: A Political Ecology of Things</em>. Durham, NC and London: Duke University Press.</a><br><a href="http://paperpile.com/b/iA68kr/jvux">Bennett, Max. 2023. <em>A Brief History of Intelligence: Evolution, AI, and the Five Breakthroughs That Made Our Brains</em>. HarperCollins.</a><br><a href="http://paperpile.com/b/iA68kr/fnS0">Bentham, Jeremy. 1817. <em>A Table of the Springs of Action: Shewing the Several Species of Pleasures and Pains, of Which Man’s Nature Is Susceptible: Together with the Several Species of Interests, Desires, and Motives, Respectively Corresponding to Them: And the Several Sets of Appellatives, Neutral, Eulogistic and Dyslogistic, by Which Each Species of Motive Is Wont to Be Designated: To Which Are Added, Explanatory Notes and Observations</em>. R. Hunter.</a><br><a href="http://paperpile.com/b/iA68kr/6rn3">Berg, Howard C. 1975. “Chemotaxis in Bacteria.” <em>Annual Review of Biophysics and Bioengineering</em> 4 (00): 119–36.</a><br><a href="http://paperpile.com/b/iA68kr/1bdb">———. 1993. <em>Random Walks in Biology</em>. Princeton University Press.</a><br><a href="http://paperpile.com/b/iA68kr/Qew1">Bernadou, Abel, Boris H. Kramer, and Judith Korb. 2021. “Major Evolutionary Transitions in Social Insects, the Importance of Worker Sterility and Life History Trade-Offs.” <em>Frontiers in Ecology and Evolution</em> 9. https://doi.org/</a><a href="http://dx.doi.org/10.3389/fevo.2021.732907">10.3389/fevo.2021.732907</a><a href="http://paperpile.com/b/iA68kr/Qew1">.</a><br><a href="http://paperpile.com/b/iA68kr/ugu5">Berrettini, Stefano, Francesca Forli, Elisabetta Genovese, Rosamaria Santarelli, Edoardo Arslan, Anna Maria Chilosi, and Paola Cipriani. 2008. “Cochlear Implantation in Deaf Children with Associated Disabilities: Challenges and Outcomes.” <em>International Journal of Audiology</em> 47 (4): 199–208.</a><br><a href="http://paperpile.com/b/iA68kr/oul6">Berridge, K. C., and T. E. Robinson. 1998. “What Is the Role of Dopamine in Reward: Hedonic Impact, Reward Learning, or Incentive Salience?” <em>Brain Research. Brain Research Reviews</em> 28 (3): 309–69.</a><br><a href="http://paperpile.com/b/iA68kr/rY1h">Bhirangi, Raunaq, Chenyu Wang, Venkatesh Pattabiraman, Carmel Majidi, Abhinav Gupta, Tess Hellebrekers, and Lerrel Pinto. 2024. “Hierarchical State Space Models for Continuous Sequence-to-Sequence Modeling.” <em>arXiv [cs.LG]</em>. arXiv.</a> <a href="http://arxiv.org/abs/2402.10211">http://arxiv.org/abs/2402.10211</a><a href="http://paperpile.com/b/iA68kr/rY1h">.</a><br><a href="http://paperpile.com/b/iA68kr/l17v">Bhojanapalli, Srinadh, Ayan Chakrabarti, Andreas Veit, Michal Lukasik, Himanshu Jain, Frederick Liu, Yin-Wen Chang, and Sanjiv Kumar. 2021. “Leveraging Redundancy in Attention with Reuse Transformers.” <em>arXiv [cs.LG]</em>. arXiv.</a> <a href="http://arxiv.org/abs/2110.06821">http://arxiv.org/abs/2110.06821</a><a href="http://paperpile.com/b/iA68kr/l17v">.</a><br><a href="http://paperpile.com/b/iA68kr/W7YG">Blake, W. 1810. “Preface to Milton a Poem (1810).” <em>Poetry Foundation</em>.</a><br><a href="http://paperpile.com/b/iA68kr/B3pP">Boaz, David. 2023. “Who Said TANSTAAFL First?” <em>The Cato Institute</em>, March 14, 2023.</a> <a href="https://www.cato.org/blog/who-said-tanstaafl-first">https://www.cato.org/blog/who-said-tanstaafl-first</a><a href="http://paperpile.com/b/iA68kr/B3pP">.</a><br><a href="http://paperpile.com/b/iA68kr/Df92">Bojarski, Mariusz, Davide Del Testa, Daniel Dworakowski, Bernhard Firner, Beat Flepp, Prasoon Goyal, Lawrence D. Jackel, et al. 2016. “End to End Learning for Self-Driving Cars.” <em>arXiv [cs.CV]</em>. arXiv.</a> <a href="http://arxiv.org/abs/1604.07316">http://arxiv.org/abs/1604.07316</a><a href="http://paperpile.com/b/iA68kr/Df92">.</a><br><a href="http://paperpile.com/b/iA68kr/4nxU">Boltzmann, Ludwig. 1868. “Studien über Das Gleichgewicht Der Lebendigen Kraft.” <em>Wissenschafiliche Abhandlungen</em>.</a><br><a href="http://paperpile.com/b/iA68kr/KJkS">Bommineni, V. L., S. Bhagwagar, and D. Balcarcel. 2023. “Performance of ChatGPT on the MCAT: The Road to Personalized and Equitable Premedical Learning.” <em>MedRxiv</em>.</a> <a href="https://www.medrxiv.org/content/10.1101/2023.03.05.23286533.abstract">https://www.medrxiv.org/content/10.1101/2023.03.05.23286533.abstract</a><a href="http://paperpile.com/b/iA68kr/KJkS">.</a><br><a href="http://paperpile.com/b/iA68kr/HekI">Boniol, M., M. McIsaac, L. Xu, T. Wuliji, and K. Diallo. 2019. “WHO Guidelines.” apps.who.int. 2019.</a> <a href="https://apps.who.int/bookorders.%0Ahttps://apps.who.int/iris/handle/10665/311314">https://apps.who.int/bookorders.%0Ahttps://apps.who.int/iris/handle/10665/311314</a><a href="http://paperpile.com/b/iA68kr/HekI">.</a><br><a href="http://paperpile.com/b/iA68kr/bhZh">Bonnet, Charles. 1769. <em>Essai analytique sur les facultés de l’âme</em>. Chez Cl. Philibert.</a><br><a href="http://paperpile.com/b/iA68kr/CTvV">Boole, George. 1854. <em>An Investigation of the Laws of Thought: On Which Are Founded the Mathematical Theories of Logic and Probabilities</em>. Dover Publications.</a><br><a href="http://paperpile.com/b/iA68kr/Zi48">Boole, Mary Everest. 1901. “Indian Thought and Western Science in the Nineteenth Century.”</a> <a href="https://libarch.nmu.org.ua/bitstream/handle/GenofondUA/17988/b4032742246bdb167e16a6951b758e43.pdf?sequence=1">https://libarch.nmu.org.ua/bitstream/handle/GenofondUA/17988/b4032742246bdb167e16a6951b758e43.pdf?sequence=1</a><a href="http://paperpile.com/b/iA68kr/Zi48">.</a><br><a href="http://paperpile.com/b/iA68kr/88jS1">Borges, Jorge Luis. 1942. “Funes El Memorioso.” <em>La Nación</em>, June 1942.</a><br><a href="http://paperpile.com/b/iA68kr/sI0O">Borsos, Zalán, Raphaël Marinier, Damien Vincent, Eugene Kharitonov, Olivier Pietquin, Matt Sharifi, Dominik Roblek, et al. 2023. “AudioLM: A Language Modeling Approach to Audio Generation.” <em>IEEE/ACM Transactions on Audio, Speech, and Language Processing</em> 31: 2523–33.</a><br><a href="http://paperpile.com/b/iA68kr/Z4MSw">Borsos, Zalán, Matt Sharifi, Damien Vincent, Eugene Kharitonov, Neil Zeghidour, and Marco Tagliasacchi. 2023. “SoundStorm: Efficient Parallel Audio Generation.” <em>arXiv [cs.SD]</em>. arXiv.</a> <a href="http://arxiv.org/abs/2305.09636">http://arxiv.org/abs/2305.09636</a><a href="http://paperpile.com/b/iA68kr/Z4MSw">.</a><br><a href="http://paperpile.com/b/iA68kr/W5mPQ">Bostrom, Nick. 2003. “Are We Living in a Computer Simulation?” <em>The Philosophical Quarterly</em> 53 (211): 243–55.</a><br><a href="http://paperpile.com/b/iA68kr/UUD0">———. 2014. <em>Superintelligence: Paths, Dangers, Strategies</em>. Oxford University Press.</a><br><a href="http://paperpile.com/b/iA68kr/5bi2">———. 2020. “Ethical Issues in Advanced Artificial Intelligence.” <em>Machine Ethics and Robot Ethics</em>, 69–75.</a><br><a href="http://paperpile.com/b/iA68kr/n4zf">———. 2023. “Apology for an Old Email.”</a> <a href="https://nickbostrom.com/oldemail.pdf">https://nickbostrom.com/oldemail.pdf</a><a href="http://paperpile.com/b/iA68kr/n4zf">.</a><br><a href="http://paperpile.com/b/iA68kr/vA9w">———. 2024. <em>Deep Utopia: Life and Meaning in a Solved World</em>. Ideapress Publishing.</a><br><a href="http://paperpile.com/b/iA68kr/gpXA">Botvinick, M., and J. Cohen. 1998. “Rubber Hands ‘feel’ Touch That Eyes See.” <em>Nature</em> 391 (February): 756–756.</a><br><a href="http://paperpile.com/b/iA68kr/jXUr">Bradbury, Phillip. 2012. “Life in Life.” YouTube. May 13, 2012.</a> <a href="https://youtu.be/xP5-iIeKXE8">https://youtu.be/xP5-iIeKXE8</a><a href="http://paperpile.com/b/iA68kr/jXUr">.</a><br><a href="http://paperpile.com/b/iA68kr/bGvG">Braslow, J. 1999. “Therapeutic Effectiveness and Social Context: The Case of Lobotomy in a California State Hospital, 1947-1954.” <em>The Western Journal of Medicine</em> 170 (5): 293–96.</a><br><a href="http://paperpile.com/b/iA68kr/mcyd">Braun, Hans Albert. 2021. “Stochasticity Versus Determinacy in Neurobiology: From Ion Channels to the Question of the ‘Free Will.’” <em>Frontiers in Systems Neuroscience</em> 15. https://doi.org/</a><a href="http://dx.doi.org/10.3389/fnsys.2021.629436">10.3389/fnsys.2021.629436</a><a href="http://paperpile.com/b/iA68kr/mcyd">.</a><br><a href="http://paperpile.com/b/iA68kr/qYMR">Brembs, Björn. 2011. “Towards a Scientific Concept of Free Will as a Biological Trait: Spontaneous Actions and Decision-Making in Invertebrates.” <em>Proceedings. Biological Sciences / The Royal Society</em> 278 (1707): 930–39.</a><br><a href="http://paperpile.com/b/iA68kr/BXrN">Brewer, Rebecca, Richard Cook, and Geoffrey Bird. 2016. “Alexithymia: A General Deficit of Interoception.” <em>Royal Society Open Science</em> 3 (10): 150664.</a><br><a href="http://paperpile.com/b/iA68kr/tA0L">Bridle, John S. 1990. “Probabilistic Interpretation of Feedforward Classification Network Outputs, with Relationships to Statistical Pattern Recognition.” In <em>Neurocomputing</em>, 227–36. Springer Berlin Heidelberg.</a><br><a href="http://paperpile.com/b/iA68kr/briEj">Bromley, Allan G. 1982. “Charles Babbage’s Analytical Engine, 1838.” <em>IEEE Annals of the History of Computing</em> 4 (3): 196–217.</a><br><a href="http://paperpile.com/b/iA68kr/gNft">Brown, Daniel J. 2013. “The Boys in the Boat: Nine Americans and Their Epic Quest for Gold at the 1936 Berlin Olympics,” June.</a><br><a href="http://paperpile.com/b/iA68kr/8Bno">Brown, Tom, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D. Kaplan, Prafulla Dhariwal, Arvind Neelakantan, et al. 2020. “Language Models Are Few-Shot Learners.” <em>Advances in Neural Information Processing Systems</em> 33: 1877–1901.</a><br><a href="http://paperpile.com/b/iA68kr/HYKA">Bruder, Johannes. 2017. “Infrastructural Intelligence: Contemporary Entanglements between Neuroscience and AI.” <em>Progress in Brain Research</em> 233 (July): 101–28.</a><br><a href="http://paperpile.com/b/iA68kr/lfzM">Bryson, J. 2010. “Robots Should Be Slaves.” <em>Close Engagements with Artificial Companions: Key</em>, March, 63–74.</a><br><a href="http://paperpile.com/b/iA68kr/Is9s">Bubeck, Sébastien, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, et al. 2023. “Sparks of Artificial General Intelligence: Early Experiments with GPT-4.” <em>arXiv [cs.CL]</em>. arXiv.</a> <a href="http://arxiv.org/abs/2303.12712">http://arxiv.org/abs/2303.12712</a><a href="http://paperpile.com/b/iA68kr/Is9s">.</a><br><a href="http://paperpile.com/b/iA68kr/lX1E">Bubeck, Sébastien, and Mark Sellke. 2022. “A Universal Law of Robustness via Isoperimetry.” <em>Journal of the ACM</em>, December. https://doi.org/</a><a href="http://dx.doi.org/10.1145/3578580">10.1145/3578580</a><a href="http://paperpile.com/b/iA68kr/lX1E">.</a><br><a href="http://paperpile.com/b/iA68kr/bUcj">Buchanan, Bon B., and Daniel I. Arnon. 1990. “A Reverse Krebs Cycle in Photosynthesis: Consensus at Last.” <em>Photosynthesis Research</em> 24 (1): 47–53.</a><br><a href="http://paperpile.com/b/iA68kr/zw0s">Budelmann, B. U. 1998. “Autophagy in Octopus.” <em>South African Journal of Marine Science/Suid-Afrikaanse Tydskrif Vir Seewetenskap</em> 20 (1): 101–8.</a><br><a href="http://paperpile.com/b/iA68kr/e3CB">Bulldog, Bentham ’s. n.d. “Bentham’s Newsletter.” Accessed April 30, 2024.</a> <a href="https://benthams.substack.com/">https://benthams.substack.com/</a><a href="http://paperpile.com/b/iA68kr/e3CB">.</a><br><a href="http://paperpile.com/b/iA68kr/0tMb">Buolamwini, Joy, and Timnit Gebru. 23–24 Feb 2018. “Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification.” In <em>Proceedings of the 1st Conference on Fairness, Accountability and Transparency</em>, edited by Sorelle A. Friedler and Christo Wilson, 81:77–91. Proceedings of Machine Learning Research. PMLR.</a><br><a href="http://paperpile.com/b/iA68kr/kjHw">Bush, Robert R., and Frederick Mosteller. 1951. “A Mathematical Model for Simple Learning.” <em>Psychological Review</em> 58 (5): 313–23.</a><br><a href="http://paperpile.com/b/iA68kr/OLIl">Bush, S. L. 2012. “Economy of Arm Autotomy in the Mesopelagic Squid Octopoteuthis Deletron.” <em>Marine Ecology Progress Series</em> 458 (July): 133–40.</a><br><a href="http://paperpile.com/b/iA68kr/KMQl">Butter, C. M., S. Kosslyn, D. Mijovic-Prelec, and A. Riffle. 1997. “Field-Specific Deficits in Visual Imagery Following Hemianopia due to Unilateral Occipital Infarcts.” <em>Brain: A Journal of Neurology</em> 120 ( Pt 2) (February): 217–28.</a><br><a href="http://paperpile.com/b/iA68kr/962jV">Buxhoeveden, Daniel P., and Manuel F. Casanova. 2002. “The Minicolumn Hypothesis in Neuroscience.” <em>Brain: A Journal of Neurology</em> 125 (Pt 5): 935–51.</a><br><a href="http://paperpile.com/b/iA68kr/FuMJ">Byrd, Paul. 1975. “New Relations between Fibonacci and Bernoulli Numbers.” <em>Fibonacci Quart</em> 13: 111–14.</a><br><a href="http://paperpile.com/b/iA68kr/aAnqN">Cadwell, Cathryn R., Aparna Bhaduri, Mohammed A. Mostajo-Radji, Matthew G. Keefe, and Tomasz J. Nowakowski. 2019. “Development and Arealization of the Cerebral Cortex.” <em>Neuron</em> 103 (6): 980–1004.</a><br><a href="http://paperpile.com/b/iA68kr/WKxG">Caliskan, Aylin, Joanna J. Bryson, and Arvind Narayanan. 2017. “Semantics Derived Automatically from Language Corpora Contain Human-like Biases.” <em>Science</em> 356 (6334): 183–86.</a><br><a href="http://paperpile.com/b/iA68kr/j6HX">Campbell, Lyle, Nala Huiying Lee, Eve Okura, Sean Simpson, Kaori Ueki, and John Van Way. 2013. “New Knowledge: Findings from the Catalogue of Endangered Languages (‘ELCat’).” In <em>3rd International Conference on Language Documentation &amp; Conservation</em>.</a><br><a href="http://paperpile.com/b/iA68kr/4JfK">Čapek, Karel. 1920. <em>R.U.R.: Rossum’s Universal Robots</em>. Aventinum.</a><br><a href="http://paperpile.com/b/iA68kr/22kb">Carlile, Simon, and Caitlin Corkhill. 2015. “Selective Spatial Attention Modulates Bottom-up Informational Masking of Speech.” <em>Scientific Reports</em> 5 (March): 8662.</a><br><a href="http://paperpile.com/b/iA68kr/x3du">Carlsmith, Joseph. 2022. “Is Power-Seeking AI an Existential Risk?” <em>arXiv [cs.CY]</em>. arXiv.</a> <a href="http://arxiv.org/abs/2206.13353">http://arxiv.org/abs/2206.13353</a><a href="http://paperpile.com/b/iA68kr/x3du">.</a><br><a href="http://paperpile.com/b/iA68kr/dEx3p">Carroll, Sean B., Jennifer K. Grenier, and Scott D. Weatherbee. 2013. <em>From DNA to Diversity: Molecular Genetics and the Evolution of Animal Design</em>. EPUB. 2nd ed. Hoboken, NJ: Wiley-Blackwell.</a><br><a href="http://paperpile.com/b/iA68kr/99yY">Case, R. 1985. “Intellectual Development : Birth to Adulthood.” <em>(No Title)</em>.</a> <a href="https://cir.nii.ac.jp/crid/1130282272272375168">https://cir.nii.ac.jp/crid/1130282272272375168</a><a href="http://paperpile.com/b/iA68kr/99yY">.</a><br><a href="http://paperpile.com/b/iA68kr/9yjW">Cassell, Eric J. 1998. “The Nature of Suffering and the Goals of Medicine.” <em>Loss, Grief &amp; Care</em> 8 (1-2): 129–42.</a><br><a href="http://paperpile.com/b/iA68kr/0OWL">Cavalier-Smith, T. 2002. “Origins of the Machinery of Recombination and Sex.” <em>Heredity</em> 88 (2): 125–41.</a><br><a href="http://paperpile.com/b/iA68kr/Cc7oM">Chalmers, D. 1995. “Facing up to the Problem of Consciousness.” <em>Journal of Consciousness Studies</em>. https://doi.org/</a><a href="http://dx.doi.org/10.1093/acprof:oso/9780195311105.003.0001">10.1093/acprof:oso/9780195311105.003.0001</a><a href="http://paperpile.com/b/iA68kr/Cc7oM">.</a><br><a href="http://paperpile.com/b/iA68kr/oSs5">Chalmers, David J. 2022. <em>Reality+: Virtual Worlds and the Problems of Philosophy</em>. W. W. Norton &amp; Company.</a><br><a href="http://paperpile.com/b/iA68kr/wFhO">Chalmers, David J., and Kelvin J. McQueen. 2021. “Consciousness and the Collapse of the Wave Function.” <em>arXiv [quant-Ph]</em>. arXiv.</a> <a href="http://arxiv.org/abs/2105.02314">http://arxiv.org/abs/2105.02314</a><a href="http://paperpile.com/b/iA68kr/wFhO">.</a><br><a href="http://paperpile.com/b/iA68kr/WphQ">Chance, Michael R. A., and Allan P. Mead. 1953. “Social Behaviour and Primate Evolution.” <em>Evolution: Symposia of the Society for Experimental Biology</em> 7: 395–439.</a><br><a href="http://paperpile.com/b/iA68kr/0M60">Chater, Nick. 2018. <em>The Mind Is Flat: The Remarkable Shallowness of the Improvising Brain</em>. Yale University Press.</a><br><a href="http://paperpile.com/b/iA68kr/g0Dt">Chebat, Daniel-Robert, Fabien C. Schneider, and Maurice Ptito. 2020. “Spatial Competence and Brain Plasticity in Congenital Blindness via Sensory Substitution Devices.” <em>Frontiers in Neuroscience</em> 14 (July): 815.</a><br><a href="http://paperpile.com/b/iA68kr/r7tT">Cheng, Ken. 2021. “Learning in Cnidaria: A Systematic Review.” <em>Learning &amp; Behavior</em> 49 (2): 175–89.</a><br><a href="http://paperpile.com/b/iA68kr/jzzH">Chen, Lang, Demian Wassermann, Daniel A. Abrams, John Kochalka, Guillermo Gallardo-Diez, and Vinod Menon. 2019. “The Visual Word Form Area (VWFA) Is Part of Both Language and Attention Circuitry.” <em>Nature Communications</em> 10 (1): 5601.</a><br><a href="http://paperpile.com/b/iA68kr/yBse">Cherkaev, Xenia. 2021. “Zoo-Fascism, Russia: To Hell with Equality and Ownerless Dogs.” April 15, 2021.</a> <a href="https://culanth.org/fieldsights/zoo-fascism-russia-to-hell-with-equality-and-ownerless-dogs">https://culanth.org/fieldsights/zoo-fascism-russia-to-hell-with-equality-and-ownerless-dogs</a><a href="http://paperpile.com/b/iA68kr/yBse">.</a><br><a href="http://paperpile.com/b/iA68kr/4zq9">Cherry, Colin. 1953. “Cocktail Party Problem.” <em>The Journal of the Acoustical Society of America</em> 25: 975–79.</a><br><a href="http://paperpile.com/b/iA68kr/12j8">chewbster. 2008. “Blindsight - Blind Man Can See and Avoid Obstacles.” Youtube. December 25, 2008.</a> <a href="https://www.youtube.com/watch?v=GwGmWqX0MnM">https://www.youtube.com/watch?v=GwGmWqX0MnM</a><a href="http://paperpile.com/b/iA68kr/12j8">.</a><br><a href="http://paperpile.com/b/iA68kr/OO4P">Chew, Monica, and J. D. Tygar. 2004. “Image Recognition CAPTCHAs.” In <em>Information Security</em>, 268–79. Springer Berlin Heidelberg.</a><br><a href="http://paperpile.com/b/iA68kr/R5gA">Chiang, Ted. 2005. “What’s Expected of Us.” Nature Publishing Group UK. July 6, 2005. https://doi.org/</a><a href="http://dx.doi.org/10.1038/436150a">10.1038/436150a</a><a href="http://paperpile.com/b/iA68kr/R5gA">.</a><br><a href="http://paperpile.com/b/iA68kr/KHSB">———. 2023. “ChatGPT Is a Blurry JPEG of the Web.” <em>New Yorker</em> 9: 2023.</a><br><a href="http://paperpile.com/b/iA68kr/n9GU">Chiang, Ted, and Allora &amp; Calzadilla. 2015. “The Great Silence.” <em>E-Flux Journal</em>, no. 65 (May).</a> <a href="https://www.e-flux.com/journal/65/336684/the-great-silence/">https://www.e-flux.com/journal/65/336684/the-great-silence/</a><a href="http://paperpile.com/b/iA68kr/n9GU">.</a><br><a href="http://paperpile.com/b/iA68kr/WGzk">Chittka, Lars. 2022. <em>The Mind of a Bee</em>. Princeton University Press.</a><br><a href="http://paperpile.com/b/iA68kr/UQEY">Chittka, Lars, and Johannes Spaethe. 2007. “Visual Search and the Importance of Time in Complex Decision Making by Bees.” <em>Arthropod-Plant Interactions</em> 1 (1): 37–44.</a><br><a href="http://paperpile.com/b/iA68kr/AdQh">Chittka, Lars, and James D. Thomson. 1997. “Sensori-Motor Learning and Its Relevance for Task Specialization in Bumble Bees.” <em>Behavioral Ecology and Sociobiology</em> 41 (6): 385–98.</a><br><a href="http://paperpile.com/b/iA68kr/PhD7">Chomsky, Noam. 1959. “A Review Od BF Skinner’s Verbal Behavior.” <em>Language</em> 35 (1): 26–58.</a><br><a href="http://paperpile.com/b/iA68kr/WXQD">———. 1980. “On Cognitive Structures and Their Development: A Reply to Piaget.” <em>Debate between Jean Piaget and Noam Chomsky</em>.</a><br><a href="http://paperpile.com/b/iA68kr/CRlN">Chomsky, Noam, Ian Roberts, and Jeffrey Watumull. 2023. “Noam Chomsky: The False Promise of Chatgpt.” <em>The New York Times</em> 8.</a> <a href="https://edisciplinas.usp.br/pluginfile.php/7614933/mod_resource/content/1/Opinion%20_%20Noam%20Chomsky_%20The%20False%20Promise%20of%20ChatGPT%20-%20The%20New%20York%20Times.pdf">https://edisciplinas.usp.br/pluginfile.php/7614933/mod_resource/content/1/Opinion%20_%20Noam%20Chomsky_%20The%20False%20Promise%20of%20ChatGPT%20-%20The%20New%20York%20Times.pdf</a><a href="http://paperpile.com/b/iA68kr/CRlN">.</a><br><a href="http://paperpile.com/b/iA68kr/dNBF">Christian, Brian. 2020. <em>The Alignment Problem: Machine Learning and Human Values</em>. W. W. Norton &amp; Company.</a><br><a href="http://paperpile.com/b/iA68kr/wWcO">Christiansen, Morten H., and Nick Chater. 2022. <em>The Language Game: How Improvisation Created Language and Changed the World</em>. Basic Books.</a><br><a href="http://paperpile.com/b/iA68kr/W4Wg">Christiansen, Morten H., Rick A. C. Dale, Michelle R. Ellefson, and Christopher M. Conway. 2002. “The Role of Sequential Learning in Language Evolution: Computational and Experimental Studies.” In <em>Simulating the Evolution of Language</em>, edited by Angelo Cangelosi and Domenico Parisi, 165–87. London: Springer London.</a><br><a href="http://paperpile.com/b/iA68kr/MvA4">Christley, Scott, Yiming Lu, Chen Li, and Xiaohui Xie. 2009. “Human Genomes as Email Attachments.” <em>Bioinformatics</em> 25 (2): 274–75.</a><br><a href="http://paperpile.com/b/iA68kr/T6M7">Chung, Junyoung, Caglar Gulcehre, Kyunghyun Cho, and Yoshua Bengio. 2014. “Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling.” <em>arXiv [cs.NE]</em>. arXiv.</a> <a href="http://arxiv.org/abs/1412.3555">http://arxiv.org/abs/1412.3555</a><a href="http://paperpile.com/b/iA68kr/T6M7">.</a><br><a href="http://paperpile.com/b/iA68kr/GQNC6">Chuong, Edward B. 2018. “The Placenta Goes Viral: Retroviruses Control Gene Expression in Pregnancy.” <em>PLoS Biology</em> 16 (10): e3000028.</a><br><a href="http://paperpile.com/b/iA68kr/Jx9c">Churchland, Patricia. 2016. “Motivations and Drives Are Computationally Messy.” 2016.</a> <a href="https://www.pas.va/en/publications/scripta-varia/sv132pas/churchland.html">https://www.pas.va/en/publications/scripta-varia/sv132pas/churchland.html</a><a href="http://paperpile.com/b/iA68kr/Jx9c">.</a><br><a href="http://paperpile.com/b/iA68kr/8wPH">———. 2019. <em>Conscience: The Origins of Moral Intuition</em>. National Geographic Books.</a><br><a href="http://paperpile.com/b/iA68kr/ZKLn">Churchland, Patricia, V. S. Ramachandran, and Terrence J. Sejnowski. 1994. “A Critique of Pure Vision.” In <em>Large-Scale Neuronal Theories of the Brain</em>, edited by Christof Koch and Joel L. Davis, 23–60. Bradford Books. Cambridge, MA: MIT Press.</a><br><a href="http://paperpile.com/b/iA68kr/NjEv">Cilliers, Paul. 1998. <em>Complexity and Postmodernism: Understanding Complex Systems</em>. Psychology Press.</a><br><a href="http://paperpile.com/b/iA68kr/BpIO">Clark, Andy. 2023. <em>The Experience Machine: How Our Minds Predict and Shape Reality</em>. Knopf Doubleday Publishing Group.</a><br><a href="http://paperpile.com/b/iA68kr/xCbo">Clarke, Arthur C. 1968. <em>2001: A Space Odyssey</em>. New American Library.</a><br><a href="http://paperpile.com/b/iA68kr/UHwCH">Clynes, M. E., and N. S. Kline. 1960. “Cyborgs and Space.” <em>Astronautics</em> 14 (9): 26–27.</a><br><a href="http://paperpile.com/b/iA68kr/PT1K">Colapinto, John. 2007. “The Interpreter.” <em>New Yorker</em> 16: 125.</a><br><a href="http://paperpile.com/b/iA68kr/8KWM">Colbert-White, Erin Natannie. 2013. “Evidence for Human-like Conversational Strategies in an African Grey Parrot’s Speech.” University of Georgia.</a> <a href="https://getd.libs.uga.edu/pdfs/colbert-white_erin_n_201305_phd.pdf">https://getd.libs.uga.edu/pdfs/colbert-white_erin_n_201305_phd.pdf</a><a href="http://paperpile.com/b/iA68kr/8KWM">.</a><br><a href="http://paperpile.com/b/iA68kr/sLJB">Collado, Miguel Á., Cristina M. Montaner, Francisco P. Molina, Daniel Sol, and Ignasi Bartomeus. 2021. “Brain Size Predicts Learning Abilities in Bees.” <em>Royal Society Open Science</em> 8 (5): 201940.</a><br><a href="http://paperpile.com/b/iA68kr/6gFa">Colombo, Matteo. 2014. “Deep and Beautiful. The Reward Prediction Error Hypothesis of Dopamine.” <em>Studies in History and Philosophy of Biological and Biomedical Sciences</em> 45 (March): 57–67.</a><br><a href="http://paperpile.com/b/iA68kr/cr5V">Conway, Christopher M., and David B. Pisoni. 2008. “Neurocognitive Basis of Implicit Learning of Sequential Structure and Its Relation to Language Processing.” <em>Annals of the New York Academy of Sciences</em> 1145 (December): 113–31.</a><br><a href="http://paperpile.com/b/iA68kr/b6RBh">Cook, M. 2004. “Universality in Elementary Cellular Automata.” <em>Complex Systems</em> 15 (1): 1–40.</a><br><a href="http://paperpile.com/b/iA68kr/n9NR">Corcoran, A. J., and W. Conner. 2016. “How Moths Escape Bats: Predicting Outcomes of Predator–prey Interactions.” <em>The Journal of Experimental Biology</em> 219 (September): 2704–15.</a><br><a href="http://paperpile.com/b/iA68kr/6M2w"><em>Cosmo the Funny Parrot</em>. n.d. Youtube. Accessed April 18, 2024.</a> <a href="https://www.youtube.com/channel/UClMJsMoWV1HRFsnfUgN19GA">https://www.youtube.com/channel/UClMJsMoWV1HRFsnfUgN19GA</a><a href="http://paperpile.com/b/iA68kr/6M2w">.</a><br><a href="http://paperpile.com/b/iA68kr/Xo5M">Cowan, N. 2001. “The Magical Number 4 in Short-Term Memory: A Reconsideration of Mental Storage Capacity.” <em>The Behavioral and Brain Sciences</em> 24 (1): 87–114; discussion 114–85.</a><br><a href="http://paperpile.com/b/iA68kr/IYwa">Craige, Betty Jean. 2010. <em>Conversations with Cosmo: At Home with an African Grey Parrot</em>. Sherman Asher Pub.</a><br><a href="http://paperpile.com/b/iA68kr/C8Te">Crook, Robyn J., and Edgar T. Walters. 2014. “Neuroethology: Self-Recognition Helps Octopuses Avoid Entanglement.” <em>Current Biology: CB</em> 24 (11): R520–21.</a><br><a href="http://paperpile.com/b/iA68kr/wa0Hc">Crosby, Alfred W. 2003. <em>The Columbian Exchange: Biological and Cultural Consequences of 1492, 30th Anniversary Edition</em>. New York: Praeger.</a> <a href="https://books.google.com/books?hl=en&amp;lr=&amp;id=SXvCEAAAQBAJ&amp;oi=fnd&amp;pg=PT15&amp;dq=The+Columbian+Exchange:+Biological+and+Cultural+Consequences+of+1492&amp;ots=tQcdcNH-ru&amp;sig=-tY3njlfbvWNcvjeKuhBCvBRnGc">https://books.google.com/books?hl=en&amp;lr=&amp;id=SXvCEAAAQBAJ&amp;oi=fnd&amp;pg=PT15&amp;dq=The+Columbian+Exchange:+Biological+and+Cultural+Consequences+of+1492&amp;ots=tQcdcNH-ru&amp;sig=-tY3njlfbvWNcvjeKuhBCvBRnGc</a><a href="http://paperpile.com/b/iA68kr/wa0Hc">.</a><br><a href="http://paperpile.com/b/iA68kr/XLn6">Cruse, Holk, and David Hübner. 2008. “Selforganizing Memory: Active Learning of Landmarks Used for Navigation.” <em>Biological Cybernetics</em> 99 (3): 219–36.</a><br><a href="http://paperpile.com/b/iA68kr/IyAR">Cundy, Chris, and Stefano Ermon. 2023. “SequenceMatch: Imitation Learning for Autoregressive Sequence Modelling with Backtracking.” <em>arXiv [cs.LG]</em>. arXiv.</a> <a href="http://arxiv.org/abs/2306.05426">http://arxiv.org/abs/2306.05426</a><a href="http://paperpile.com/b/iA68kr/IyAR">.</a><br><a href="http://paperpile.com/b/iA68kr/MLoX">Ćwiek, Aleksandra, Susanne Fuchs, Christoph Draxler, Eva Liina Asu, Dan Dediu, Katri Hiovain, Shigeto Kawahara, et al. 2022. “The Bouba/kiki Effect Is Robust across Cultures and Writing Systems.” <em>Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences</em> 377 (1841): 20200390.</a><br><a href="http://paperpile.com/b/iA68kr/2dNU">Cybenko, G. 1989. “Approximation by Superpositions of a Sigmoidal Function.” <em>Mathematics of Control, Signals, and Systems</em> 2 (4): 303–14.</a><br><a href="http://paperpile.com/b/iA68kr/Jwwd">Damasio, Antonio R. 1999. <em>The Feeling of What Happens: Body and Emotion in the Making of Consciousness</em>. Houghton Mifflin Harcourt.</a><br><a href="http://paperpile.com/b/iA68kr/F6RI">Damasio, A. R., H. Damasio, and H. C. Chui. 1980. “Neglect Following Damage to Frontal Lobe or Basal Ganglia.” <em>Neuropsychologia</em> 18 (2): 123–32.</a><br><a href="http://paperpile.com/b/iA68kr/lqYa">Dattani, Saloni, Lucas Rodés-Guirao, Hannah Ritchie, Esteban Ortiz-Ospina, and Max Roser. 2023. “Life Expectancy.” <em>Our World in Data</em>.</a><br><a href="http://paperpile.com/b/iA68kr/INjD">Daubechies, I., R. DeVore, S. Foucart, B. Hanin, and G. Petrova. 2019. “Nonlinear Approximation and (Deep) ReLU Networks.” <em>arXiv [cs.LG]</em>. arXiv. https://doi.org/</a><a href="http://dx.doi.org/10.1007/s00365-021-09548-z">10.1007/s00365-021-09548-z</a><a href="http://paperpile.com/b/iA68kr/INjD">.</a> <a href="http://paperpile.com/b/iA68kr/WrWZ">Dauphin, Yann N., Angela Fan, Michael Auli, and David Grangier. 2017. “Language Modeling with Gated Convolutional Networks.” In <em>Proceedings of the 34th International Conference on Machine Learning</em>, edited by Doina Precup and Yee Whye Teh, 70:933–41. Proceedings of Machine Learning Research. PMLR.</a><br><a href="http://paperpile.com/b/iA68kr/lJery">Dawkins, Richard. 1986. <em>The Blind Watchmaker</em>. New York: W.W. Norton.</a><br><a href="http://paperpile.com/b/iA68kr/2Jxj">Dax, E. C., and R. K. Freudenberg. 1948. “Prefrontal Leucotomy; a Review.” <em>Postgraduate Medical Journal</em> 24 (274): 415–26.</a><br><a href="http://paperpile.com/b/iA68kr/I2eS">Dayan, P., G. E. Hinton, R. M. Neal, and R. S. Zemel. 1995. “The Helmholtz Machine.” <em>Neural Computation</em> 7 (5): 889–904.</a><br><a href="http://paperpile.com/b/iA68kr/yDcd">Deacon, Terrence W. 2012. <em>Incomplete Nature: How Mind Emerged from Matter</em>. W. W. Norton &amp; Company.</a><br><a href="http://paperpile.com/b/iA68kr/Ym5N">Dean, Jeffrey. 2022. “A Golden Decade of Deep Learning: Computing Systems &amp; Applications.” <em>Daedalus</em> 151 (2): 58–74.</a><br><a href="http://paperpile.com/b/iA68kr/ETXV">“Declaration of Independence: A Transcription.” n.d. Accessed April 15, 2024.</a> <a href="https://www.archives.gov/founding-docs/declaration-transcript">https://www.archives.gov/founding-docs/declaration-transcript</a><a href="http://paperpile.com/b/iA68kr/ETXV">.</a><br><a href="http://paperpile.com/b/iA68kr/aHXw">Dein, Simon, and Abdool Samad Illaiee. 2013. “Jinn and Mental Health: Looking at Jinn Possession in Modern Psychiatric Practice.” <em>The Psychiatrist</em> 37 (9): 290–93.</a><br><a href="http://paperpile.com/b/iA68kr/Ewn95">DeLong, J. Bradford. 2022. <em>Slouching Towards Utopia: An Economic History of the Twentieth Century</em>. Basic Books.</a><br><a href="http://paperpile.com/b/iA68kr/A3uP">De Monchaux, Nicholas. 2011. <em>Spacesuit: Fashioning Apollo</em>. MIT Press.</a><br><a href="http://paperpile.com/b/iA68kr/Q0ucZ">De Morgan, Augustus, and Sophia Elizabeth De Morgan. 1872. <em>A Budget of Paradoxes</em>. London: Longmans, Green.</a><br><a href="http://paperpile.com/b/iA68kr/XKLq">Dennett, Daniel Clement. 1984. <em>Elbow Room: The Varieties of Free Will Worth Wanting</em>. Clarendon Press.</a></p></div><div class="indicators"><div class="fixed-indicator"></div><div class="figure-indicators"></div></div></section><div id="footnote-popup" class="footnote-text"></div></article></main></body></html>